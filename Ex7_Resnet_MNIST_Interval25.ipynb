{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mar_25_2021_thesis_proj_OnGoing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgoqGX9tOBUd"
      },
      "source": [
        "# IMPORT LIBRARIES\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import urllib\n",
        "from torch.optim import *\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR-sUkT321Gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453cadce-3bb4-4852-b155-1366966d801a"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "data_file_location = \"/content/gdrive/MyDrive/MNIST/\"\n",
        "# data_file_location = \"data_bn\"\n",
        "os.chdir(data_file_location)\n",
        "# # sys.path.append(os.path.abspath(py_file_location))\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/MyDrive/MNIST\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCRZ-12hgpyc"
      },
      "source": [
        "mnist_data = torchvision.datasets.MNIST('/content/gdrive/MyDrive/MNIST/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GuyNJ56hfeb"
      },
      "source": [
        "\n",
        "dl = torch.utils.data.DataLoader(mnist_data, batch_size=16, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DedR7G7UZGcr"
      },
      "source": [
        "#Pre-processing of Dataset\n",
        "tensor = dl.dataset.data\n",
        "tr = tensor.reshape(tensor.size(0), -1)  # reshaped\n",
        "targets = dl.dataset.targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Am1B-BLWWwi"
      },
      "source": [
        "#---------------------------------Unseen Data : 5000-----------------------\n",
        "#Unseen Data : 5000\n",
        "\n",
        "mnist_unseen_data = tr[0:5000]\n",
        "mnist_unseen_data_final = mnist_unseen_data.view(-1, 1,28,28).float()\n",
        "mnist_unseen_label = targets[0:5000]\n",
        "\n",
        "prob_ds = TensorDataset(mnist_unseen_data_final, mnist_unseen_label)\n",
        "\n",
        "prob_dl = torch.utils.data.DataLoader(prob_ds, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm-Vx10IWwMu"
      },
      "source": [
        "#Training Data: 44000\n",
        "\n",
        "trainset_data = tr[5000: 49000]\n",
        "trainset_target = targets[5000: 49000]\n",
        "\n",
        "trainset_data_numpy = np.array(trainset_data)\n",
        "trainset_target_numpy = np.array(trainset_target)\n",
        "\n",
        "train_with_target = np.c_[trainset_data_numpy, trainset_target_numpy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u5zd5ZWW1jN"
      },
      "source": [
        "# Test Data: 11000\n",
        "\n",
        "test_data = tr[49000:]\n",
        "test_data_final = test_data.view(-1, 1,28,28).float()\n",
        "test_target = targets[49000:]\n",
        "\n",
        "#Test Set\n",
        "test_ds = TensorDataset(test_data_final, test_target)\n",
        "\n",
        "#Test Loader\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUgBW-OdXqzE"
      },
      "source": [
        "#Trainset A:\n",
        "\n",
        "#A: Data\n",
        "trainset_a = train_with_target[0: 17500]\n",
        "trainset_a_pd = pd.DataFrame(trainset_a)\n",
        "\n",
        "#Common Data of 25%, 50% and 75%\n",
        "chunk_a1 = trainset_a_pd.sample(4375) #25% Common data\n",
        "chunk_a2 = trainset_a_pd.sample(8750) #50% Common data\n",
        "chunk_a3 = trainset_a_pd.sample(13125) #75% Common data\n",
        "\n",
        "\n",
        "chunk_a1 = pd.DataFrame(np.array(chunk_a1))\n",
        "chunk_a2 = pd.DataFrame(np.array(chunk_a2))\n",
        "chunk_a3 = pd.DataFrame(np.array(chunk_a3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlT2XdDkXnyU"
      },
      "source": [
        "#Trainset B: 25% Common of A\n",
        "\n",
        "#B: Data\n",
        "trainset_b = train_with_target[17500: 30625] #13125 data\n",
        "trainset_b_pd = pd.DataFrame(trainset_b)\n",
        "trainset_b_pd = pd.DataFrame(np.array(trainset_b_pd))\n",
        "trainset_b_pd = trainset_b_pd.append(chunk_a1) #4375\n",
        "trainset_b_pd = pd.DataFrame(np.array(trainset_b_pd))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBofrMepXkmE"
      },
      "source": [
        "#Trainset C: 50% common from A\n",
        "\n",
        "#C: Data\n",
        "trainset_c = train_with_target[30625: 39375] #8750 data\n",
        "trainset_c_pd = pd.DataFrame(trainset_c)\n",
        "trainset_c_pd = pd.DataFrame(np.array(trainset_c_pd))\n",
        "trainset_c_pd = trainset_c_pd.append(chunk_a2) #8750\n",
        "trainset_c_pd = pd.DataFrame(np.array(trainset_c_pd))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXWmydStXhlE"
      },
      "source": [
        "#Trainset d: 75% common from A\n",
        "\n",
        "#D: Data\n",
        "trainset_d = train_with_target[39375: 43750] #4375 data\n",
        "trainset_d_pd = pd.DataFrame(trainset_d)\n",
        "trainset_d_pd = pd.DataFrame(np.array(trainset_d_pd))\n",
        "trainset_d_pd = trainset_d_pd.append(chunk_a3)\n",
        "trainset_d_pd = pd.DataFrame(np.array(trainset_d_pd))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3TUq6OqSesp"
      },
      "source": [
        "#Trainset E: 100% common from A\n",
        "\n",
        "#E: Data\n",
        "trainset_e = train_with_target[0: 17500]\n",
        "trainset_e_pd = pd.DataFrame(trainset_e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aowSU04fX7jb"
      },
      "source": [
        "#Batch size\n",
        "bs = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3DWRN3iUesX"
      },
      "source": [
        "#Trainset A Data and Target to Tensor\n",
        "init_train_a = trainset_a_pd.iloc[:, : 784].values\n",
        "train_a = torch.tensor(init_train_a)\n",
        "train_a_final = train_a.view(-1, 1,28,28).float()\n",
        "\n",
        "init_train_a_target = trainset_a_pd.iloc[:, -1].values\n",
        "train_a_target = torch.tensor(init_train_a_target)\n",
        "\n",
        "\n",
        "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
        "train_v_ds = TensorDataset(train_a_final, train_a_target)\n",
        "#Tensor Dataset train v to Dataloader\n",
        "# Trainset 1: train_v_dl\n",
        "train_v_dl = torch.utils.data.DataLoader(train_v_ds, batch_size=bs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb0DK5t7Ua_C"
      },
      "source": [
        "#Trainset B Data and Target to Tensor\n",
        "init_train_b = trainset_b_pd.iloc[:, : 784].values\n",
        "train_b = torch.tensor(init_train_b)\n",
        "train_b_final = train_b.view(-1, 1,28,28).float()\n",
        "\n",
        "init_train_b_target = trainset_b_pd.iloc[:, -1].values\n",
        "train_b_target = torch.tensor(init_train_b_target)\n",
        "\n",
        "\n",
        "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
        "train_w_ds = TensorDataset(train_b_final, train_b_target)\n",
        "#Tensor Dataset train v to Dataloader\n",
        "# Trainset 2: train_w_dl\n",
        "train_w_dl = torch.utils.data.DataLoader(train_w_ds, batch_size=bs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7RhsbfvUJPx"
      },
      "source": [
        "#Trainset C Data and Target to Tensor\n",
        "init_train_c = trainset_c_pd.iloc[:, : 784].values\n",
        "train_c = torch.tensor(init_train_c)\n",
        "train_c_final = train_c.view(-1, 1,28,28).float()\n",
        "\n",
        "init_train_c_target = trainset_c_pd.iloc[:, -1].values\n",
        "train_c_target = torch.tensor(init_train_c_target)\n",
        "\n",
        "\n",
        "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
        "train_x_ds = TensorDataset(train_c_final, train_c_target)\n",
        "#Tensor Dataset train x to Dataloader\n",
        "# Trainset 3: train_x_dl\n",
        "train_x_dl = torch.utils.data.DataLoader(train_x_ds, batch_size=bs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT6a9994UGmI"
      },
      "source": [
        "#Trainset D Data and Target to Tensor\n",
        "init_train_d = trainset_d_pd.iloc[:, : 784].values\n",
        "train_d = torch.tensor(init_train_d)\n",
        "train_d_final = train_d.view(-1, 1,28,28).float()\n",
        "\n",
        "init_train_d_target = trainset_d_pd.iloc[:, -1].values\n",
        "train_d_target = torch.tensor(init_train_d_target)\n",
        "\n",
        "\n",
        "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
        "train_y_ds = TensorDataset(train_d_final, train_d_target)\n",
        "#Tensor Dataset train y to Dataloader\n",
        "# Trainset 4: train_y_dl\n",
        "train_y_dl = torch.utils.data.DataLoader(train_y_ds, batch_size=bs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyYmXyChSuMw"
      },
      "source": [
        "#Trainset E Data and Target to Tensor\n",
        "init_train_e = trainset_e_pd.iloc[:, : 784].values\n",
        "train_e = torch.tensor(init_train_e)\n",
        "train_e_final = train_e.view(-1, 1,28,28).float()\n",
        "\n",
        "init_train_e_target = trainset_e_pd.iloc[:, -1].values\n",
        "train_e_target = torch.tensor(init_train_e_target)\n",
        "\n",
        "\n",
        "#Trainset E Data and Target Tensor to Dataset then Dataloader\n",
        "train_z_ds = TensorDataset(train_e_final, train_e_target)\n",
        "#Tensor Dataset train z to Dataloader\n",
        "# Trainset 4: train_z_dl\n",
        "train_z_dl = torch.utils.data.DataLoader(train_z_ds, batch_size=bs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIjOfIc-SrZU"
      },
      "source": [
        "###-------------- Define a Convolutional Neural Network ---------------###\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA8cQN6VNSoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff200bc-86b1-4db4-d817-ee68c6f0a77d"
      },
      "source": [
        "train_size = len(trainset_a)\n",
        "test_size = len(test_ds)\n",
        "\n",
        "print(train_size, test_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17500 11000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT1jFrGlFIsj"
      },
      "source": [
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=20):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                \n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "                \n",
        "                for (idx, (inputs, labels)) in enumerate(train_loader):\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    \n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(True):\n",
        "                        outputs = model(inputs)\n",
        "                        \n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        # print(preds, labels)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    \n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                    \n",
        "                    \n",
        "                scheduler.step()\n",
        "                print(running_corrects)\n",
        "                epoch_loss = running_loss / train_size\n",
        "                epoch_acc = running_corrects.double() / train_size\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Train', epoch_loss, epoch_acc))\n",
        "                    \n",
        "            else:\n",
        "                \n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                \n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "                \n",
        "                for data in test_loader:\n",
        "                    inputs, labels = data\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(False):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        \n",
        "                        loss = criterion(outputs, labels)\n",
        "                \n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "                epoch_loss = running_loss / test_size\n",
        "                epoch_acc = running_corrects.double() / test_size\n",
        "                \n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\n",
        "                if epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                last_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, best_acc, last_model_wts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt4T9iQXc7K0"
      },
      "source": [
        "net1 = Net()\n",
        "net2 = Net()\n",
        "net3 = Net()\n",
        "net4 = Net()\n",
        "net5 = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttTlD3SVSWZj"
      },
      "source": [
        "#---------------- Define a Loss function and optimizer -------------------\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjZhhZUUFOwq"
      },
      "source": [
        "# Observe that all parameters are being optimized\n",
        "optimizer1 = optim.Adam(net1.parameters(), lr=0.001, weight_decay=1e-07)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler_1 = lr_scheduler.StepLR(optimizer1, step_size=20, gamma=0.1)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer2 = optim.Adam(net2.parameters(), lr=0.001, weight_decay=1e-07)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler_2 = lr_scheduler.StepLR(optimizer2, step_size=20, gamma=0.1)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer3 = optim.Adam(net3.parameters(), lr=0.001, weight_decay=1e-07)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler_3 = lr_scheduler.StepLR(optimizer3, step_size=20, gamma=0.1)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer4 = optim.Adam(net4.parameters(), lr=0.001, weight_decay=1e-07)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler_4 = lr_scheduler.StepLR(optimizer4, step_size=20, gamma=0.1)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer5 = optim.Adam(net5.parameters(), lr=0.001, weight_decay=1e-07)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler_5 = lr_scheduler.StepLR(optimizer5, step_size=20, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK4gcNUxsiCL"
      },
      "source": [
        "num_epochs = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUdFOk4LLNIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39eb916f-b244-4140-fde6-7470a6386dd5"
      },
      "source": [
        "best_net1, best_acc1, last_net1 = train_model(net1, train_v_dl, test_dl, criterion, optimizer1, exp_lr_scheduler_1,\n",
        "                        num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "tensor(15451)\n",
            "Train Loss: 0.7302 Acc: 0.8829\n",
            "Val Loss: 0.1163 Acc: 0.9634\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(17016)\n",
            "Train Loss: 0.0902 Acc: 0.9723\n",
            "Val Loss: 0.0920 Acc: 0.9696\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(17171)\n",
            "Train Loss: 0.0586 Acc: 0.9812\n",
            "Val Loss: 0.0953 Acc: 0.9763\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(17275)\n",
            "Train Loss: 0.0408 Acc: 0.9871\n",
            "Val Loss: 0.1006 Acc: 0.9746\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(17300)\n",
            "Train Loss: 0.0360 Acc: 0.9886\n",
            "Val Loss: 0.1089 Acc: 0.9756\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(17254)\n",
            "Train Loss: 0.0417 Acc: 0.9859\n",
            "Val Loss: 0.1023 Acc: 0.9760\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(17350)\n",
            "Train Loss: 0.0265 Acc: 0.9914\n",
            "Val Loss: 0.0976 Acc: 0.9796\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(17312)\n",
            "Train Loss: 0.0310 Acc: 0.9893\n",
            "Val Loss: 0.0927 Acc: 0.9785\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(17437)\n",
            "Train Loss: 0.0108 Acc: 0.9964\n",
            "Val Loss: 0.1065 Acc: 0.9794\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(17454)\n",
            "Train Loss: 0.0079 Acc: 0.9974\n",
            "Val Loss: 0.1235 Acc: 0.9771\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(17333)\n",
            "Train Loss: 0.0349 Acc: 0.9905\n",
            "Val Loss: 0.1078 Acc: 0.9772\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(17400)\n",
            "Train Loss: 0.0185 Acc: 0.9943\n",
            "Val Loss: 0.1075 Acc: 0.9795\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(17374)\n",
            "Train Loss: 0.0247 Acc: 0.9928\n",
            "Val Loss: 0.1625 Acc: 0.9725\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(17346)\n",
            "Train Loss: 0.0281 Acc: 0.9912\n",
            "Val Loss: 0.1259 Acc: 0.9757\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(17392)\n",
            "Train Loss: 0.0211 Acc: 0.9938\n",
            "Val Loss: 0.1431 Acc: 0.9767\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(17395)\n",
            "Train Loss: 0.0215 Acc: 0.9940\n",
            "Val Loss: 0.1203 Acc: 0.9797\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(17395)\n",
            "Train Loss: 0.0201 Acc: 0.9940\n",
            "Val Loss: 0.1233 Acc: 0.9794\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(17426)\n",
            "Train Loss: 0.0190 Acc: 0.9958\n",
            "Val Loss: 0.1245 Acc: 0.9817\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(17401)\n",
            "Train Loss: 0.0215 Acc: 0.9943\n",
            "Val Loss: 0.1275 Acc: 0.9774\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(17368)\n",
            "Train Loss: 0.0292 Acc: 0.9925\n",
            "Val Loss: 0.1610 Acc: 0.9795\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(17455)\n",
            "Train Loss: 0.0107 Acc: 0.9974\n",
            "Val Loss: 0.1241 Acc: 0.9844\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0003 Acc: 1.0000\n",
            "Val Loss: 0.1245 Acc: 0.9845\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0002 Acc: 1.0000\n",
            "Val Loss: 0.1247 Acc: 0.9846\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1248 Acc: 0.9845\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1250 Acc: 0.9846\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1252 Acc: 0.9845\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1254 Acc: 0.9845\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1255 Acc: 0.9845\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1257 Acc: 0.9845\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0000 Acc: 1.0000\n",
            "Val Loss: 0.1259 Acc: 0.9845\n",
            "\n",
            "Training complete in 11m 16s\n",
            "Best val Acc: 0.984636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIYJegwxK7m9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad20e897-e5fd-4e50-b6a7-0f678a7d4c26"
      },
      "source": [
        "best_net2, best_acc2, last_net2 = train_model(net2, train_w_dl, test_dl, criterion, optimizer2, exp_lr_scheduler_2,\n",
        "                        num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "tensor(15561)\n",
            "Train Loss: 0.7084 Acc: 0.8892\n",
            "Val Loss: 0.1069 Acc: 0.9683\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(17009)\n",
            "Train Loss: 0.0915 Acc: 0.9719\n",
            "Val Loss: 0.1584 Acc: 0.9554\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(17117)\n",
            "Train Loss: 0.0693 Acc: 0.9781\n",
            "Val Loss: 0.1028 Acc: 0.9703\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(17269)\n",
            "Train Loss: 0.0392 Acc: 0.9868\n",
            "Val Loss: 0.1095 Acc: 0.9723\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(17274)\n",
            "Train Loss: 0.0366 Acc: 0.9871\n",
            "Val Loss: 0.0881 Acc: 0.9781\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(17363)\n",
            "Train Loss: 0.0236 Acc: 0.9922\n",
            "Val Loss: 0.0885 Acc: 0.9779\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(17330)\n",
            "Train Loss: 0.0304 Acc: 0.9903\n",
            "Val Loss: 0.1079 Acc: 0.9748\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(17355)\n",
            "Train Loss: 0.0274 Acc: 0.9917\n",
            "Val Loss: 0.1117 Acc: 0.9745\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(17345)\n",
            "Train Loss: 0.0289 Acc: 0.9911\n",
            "Val Loss: 0.1095 Acc: 0.9781\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(17363)\n",
            "Train Loss: 0.0238 Acc: 0.9922\n",
            "Val Loss: 0.1779 Acc: 0.9643\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(17372)\n",
            "Train Loss: 0.0256 Acc: 0.9927\n",
            "Val Loss: 0.1063 Acc: 0.9786\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(17377)\n",
            "Train Loss: 0.0241 Acc: 0.9930\n",
            "Val Loss: 0.0979 Acc: 0.9793\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(17373)\n",
            "Train Loss: 0.0252 Acc: 0.9927\n",
            "Val Loss: 0.0985 Acc: 0.9795\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(17387)\n",
            "Train Loss: 0.0212 Acc: 0.9935\n",
            "Val Loss: 0.1071 Acc: 0.9830\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(17390)\n",
            "Train Loss: 0.0225 Acc: 0.9937\n",
            "Val Loss: 0.1065 Acc: 0.9805\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(17417)\n",
            "Train Loss: 0.0159 Acc: 0.9953\n",
            "Val Loss: 0.1605 Acc: 0.9754\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(17396)\n",
            "Train Loss: 0.0221 Acc: 0.9941\n",
            "Val Loss: 0.1715 Acc: 0.9750\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(17360)\n",
            "Train Loss: 0.0297 Acc: 0.9920\n",
            "Val Loss: 0.1313 Acc: 0.9797\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(17321)\n",
            "Train Loss: 0.0399 Acc: 0.9898\n",
            "Val Loss: 0.1317 Acc: 0.9773\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(17430)\n",
            "Train Loss: 0.0148 Acc: 0.9960\n",
            "Val Loss: 0.1420 Acc: 0.9791\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(17473)\n",
            "Train Loss: 0.0058 Acc: 0.9985\n",
            "Val Loss: 0.1042 Acc: 0.9844\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(17498)\n",
            "Train Loss: 0.0006 Acc: 0.9999\n",
            "Val Loss: 0.1029 Acc: 0.9844\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0002 Acc: 1.0000\n",
            "Val Loss: 0.1027 Acc: 0.9846\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0002 Acc: 1.0000\n",
            "Val Loss: 0.1027 Acc: 0.9847\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1027 Acc: 0.9846\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1026 Acc: 0.9846\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1027 Acc: 0.9845\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1027 Acc: 0.9846\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1027 Acc: 0.9845\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1028 Acc: 0.9845\n",
            "\n",
            "Training complete in 11m 15s\n",
            "Best val Acc: 0.984727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAQEREI2W5me",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ca9b3a-346e-4029-adb2-694b4172261d"
      },
      "source": [
        "best_net5, best_acc5, last_net5 = train_model(net5, train_z_dl, test_dl, criterion, optimizer5, exp_lr_scheduler_5,\n",
        "                        num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "tensor(15709)\n",
            "Train Loss: 0.6780 Acc: 0.8977\n",
            "Val Loss: 0.1199 Acc: 0.9650\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(17000)\n",
            "Train Loss: 0.0912 Acc: 0.9714\n",
            "Val Loss: 0.1085 Acc: 0.9673\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(17185)\n",
            "Train Loss: 0.0547 Acc: 0.9820\n",
            "Val Loss: 0.0970 Acc: 0.9734\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(17271)\n",
            "Train Loss: 0.0387 Acc: 0.9869\n",
            "Val Loss: 0.1148 Acc: 0.9697\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(17313)\n",
            "Train Loss: 0.0307 Acc: 0.9893\n",
            "Val Loss: 0.0901 Acc: 0.9777\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(17270)\n",
            "Train Loss: 0.0402 Acc: 0.9869\n",
            "Val Loss: 0.1126 Acc: 0.9747\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(17361)\n",
            "Train Loss: 0.0245 Acc: 0.9921\n",
            "Val Loss: 0.1118 Acc: 0.9773\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(17394)\n",
            "Train Loss: 0.0203 Acc: 0.9939\n",
            "Val Loss: 0.1169 Acc: 0.9772\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(17330)\n",
            "Train Loss: 0.0324 Acc: 0.9903\n",
            "Val Loss: 0.1013 Acc: 0.9766\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(17391)\n",
            "Train Loss: 0.0202 Acc: 0.9938\n",
            "Val Loss: 0.1124 Acc: 0.9786\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(17390)\n",
            "Train Loss: 0.0209 Acc: 0.9937\n",
            "Val Loss: 0.1273 Acc: 0.9785\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(17379)\n",
            "Train Loss: 0.0229 Acc: 0.9931\n",
            "Val Loss: 0.1432 Acc: 0.9765\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(17379)\n",
            "Train Loss: 0.0243 Acc: 0.9931\n",
            "Val Loss: 0.1159 Acc: 0.9804\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(17365)\n",
            "Train Loss: 0.0335 Acc: 0.9923\n",
            "Val Loss: 0.1002 Acc: 0.9803\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(17435)\n",
            "Train Loss: 0.0129 Acc: 0.9963\n",
            "Val Loss: 0.1365 Acc: 0.9757\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(17432)\n",
            "Train Loss: 0.0130 Acc: 0.9961\n",
            "Val Loss: 0.1385 Acc: 0.9783\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(17373)\n",
            "Train Loss: 0.0305 Acc: 0.9927\n",
            "Val Loss: 0.1311 Acc: 0.9760\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(17420)\n",
            "Train Loss: 0.0152 Acc: 0.9954\n",
            "Val Loss: 0.1212 Acc: 0.9810\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(17412)\n",
            "Train Loss: 0.0172 Acc: 0.9950\n",
            "Val Loss: 0.1538 Acc: 0.9782\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(17394)\n",
            "Train Loss: 0.0245 Acc: 0.9939\n",
            "Val Loss: 0.1287 Acc: 0.9802\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(17462)\n",
            "Train Loss: 0.0065 Acc: 0.9978\n",
            "Val Loss: 0.1012 Acc: 0.9830\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(17499)\n",
            "Train Loss: 0.0005 Acc: 0.9999\n",
            "Val Loss: 0.1003 Acc: 0.9836\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0003 Acc: 1.0000\n",
            "Val Loss: 0.1000 Acc: 0.9839\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0002 Acc: 1.0000\n",
            "Val Loss: 0.1000 Acc: 0.9840\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0002 Acc: 1.0000\n",
            "Val Loss: 0.1002 Acc: 0.9841\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1004 Acc: 0.9844\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1005 Acc: 0.9846\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1008 Acc: 0.9846\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1011 Acc: 0.9847\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1014 Acc: 0.9848\n",
            "\n",
            "Training complete in 11m 9s\n",
            "Best val Acc: 0.984818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lb20TeNWobi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dacaf5ea-3588-4512-ee90-3deaf229cfe2"
      },
      "source": [
        "best_net3, best_acc3, last_net3 = train_model(net3, train_x_dl, test_dl, criterion, optimizer3, exp_lr_scheduler_3,\n",
        "                        num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "tensor(15679)\n",
            "Train Loss: 0.6320 Acc: 0.8959\n",
            "Val Loss: 0.1536 Acc: 0.9547\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(16983)\n",
            "Train Loss: 0.0924 Acc: 0.9705\n",
            "Val Loss: 0.1067 Acc: 0.9697\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(17176)\n",
            "Train Loss: 0.0569 Acc: 0.9815\n",
            "Val Loss: 0.0751 Acc: 0.9781\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(17274)\n",
            "Train Loss: 0.0410 Acc: 0.9871\n",
            "Val Loss: 0.1119 Acc: 0.9698\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(17273)\n",
            "Train Loss: 0.0365 Acc: 0.9870\n",
            "Val Loss: 0.1023 Acc: 0.9727\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(17327)\n",
            "Train Loss: 0.0289 Acc: 0.9901\n",
            "Val Loss: 0.1006 Acc: 0.9749\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(17368)\n",
            "Train Loss: 0.0243 Acc: 0.9925\n",
            "Val Loss: 0.1120 Acc: 0.9766\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(17374)\n",
            "Train Loss: 0.0230 Acc: 0.9928\n",
            "Val Loss: 0.1290 Acc: 0.9730\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(17354)\n",
            "Train Loss: 0.0247 Acc: 0.9917\n",
            "Val Loss: 0.1466 Acc: 0.9707\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(17338)\n",
            "Train Loss: 0.0300 Acc: 0.9907\n",
            "Val Loss: 0.1523 Acc: 0.9719\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(17361)\n",
            "Train Loss: 0.0258 Acc: 0.9921\n",
            "Val Loss: 0.1390 Acc: 0.9758\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(17374)\n",
            "Train Loss: 0.0239 Acc: 0.9928\n",
            "Val Loss: 0.1656 Acc: 0.9727\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(17300)\n",
            "Train Loss: 0.0428 Acc: 0.9886\n",
            "Val Loss: 0.1124 Acc: 0.9775\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(17425)\n",
            "Train Loss: 0.0138 Acc: 0.9957\n",
            "Val Loss: 0.1075 Acc: 0.9799\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(17463)\n",
            "Train Loss: 0.0064 Acc: 0.9979\n",
            "Val Loss: 0.1382 Acc: 0.9817\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(17400)\n",
            "Train Loss: 0.0238 Acc: 0.9943\n",
            "Val Loss: 0.1629 Acc: 0.9770\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(17401)\n",
            "Train Loss: 0.0248 Acc: 0.9943\n",
            "Val Loss: 0.1283 Acc: 0.9781\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(17421)\n",
            "Train Loss: 0.0186 Acc: 0.9955\n",
            "Val Loss: 0.1533 Acc: 0.9771\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(17388)\n",
            "Train Loss: 0.0229 Acc: 0.9936\n",
            "Val Loss: 0.1711 Acc: 0.9774\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(17428)\n",
            "Train Loss: 0.0160 Acc: 0.9959\n",
            "Val Loss: 0.1563 Acc: 0.9795\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(17478)\n",
            "Train Loss: 0.0041 Acc: 0.9987\n",
            "Val Loss: 0.1292 Acc: 0.9815\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(17499)\n",
            "Train Loss: 0.0003 Acc: 0.9999\n",
            "Val Loss: 0.1276 Acc: 0.9817\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1275 Acc: 0.9815\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1275 Acc: 0.9815\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1276 Acc: 0.9814\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1278 Acc: 0.9814\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1279 Acc: 0.9815\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0000 Acc: 1.0000\n",
            "Val Loss: 0.1281 Acc: 0.9815\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0000 Acc: 1.0000\n",
            "Val Loss: 0.1283 Acc: 0.9815\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0000 Acc: 1.0000\n",
            "Val Loss: 0.1285 Acc: 0.9815\n",
            "\n",
            "Training complete in 11m 18s\n",
            "Best val Acc: 0.981727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEqZ1Eg3Wz3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0f1f4e-f402-4acc-d4cf-2620b63b6c1e"
      },
      "source": [
        "best_net4, best_acc4, last_net4 = train_model(net4, train_y_dl, test_dl, criterion, optimizer4, exp_lr_scheduler_4,\n",
        "                        num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "tensor(15392)\n",
            "Train Loss: 0.7295 Acc: 0.8795\n",
            "Val Loss: 0.1514 Acc: 0.9509\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "tensor(16872)\n",
            "Train Loss: 0.1127 Acc: 0.9641\n",
            "Val Loss: 0.1160 Acc: 0.9669\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "tensor(17091)\n",
            "Train Loss: 0.0755 Acc: 0.9766\n",
            "Val Loss: 0.1120 Acc: 0.9647\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "tensor(17165)\n",
            "Train Loss: 0.0566 Acc: 0.9809\n",
            "Val Loss: 0.1122 Acc: 0.9683\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "tensor(17238)\n",
            "Train Loss: 0.0478 Acc: 0.9850\n",
            "Val Loss: 0.1031 Acc: 0.9709\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "tensor(17253)\n",
            "Train Loss: 0.0409 Acc: 0.9859\n",
            "Val Loss: 0.1236 Acc: 0.9703\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "tensor(17322)\n",
            "Train Loss: 0.0305 Acc: 0.9898\n",
            "Val Loss: 0.1174 Acc: 0.9735\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "tensor(17292)\n",
            "Train Loss: 0.0324 Acc: 0.9881\n",
            "Val Loss: 0.1434 Acc: 0.9694\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "tensor(17325)\n",
            "Train Loss: 0.0298 Acc: 0.9900\n",
            "Val Loss: 0.1189 Acc: 0.9747\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "tensor(17363)\n",
            "Train Loss: 0.0247 Acc: 0.9922\n",
            "Val Loss: 0.1039 Acc: 0.9804\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "tensor(17352)\n",
            "Train Loss: 0.0284 Acc: 0.9915\n",
            "Val Loss: 0.1331 Acc: 0.9739\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "tensor(17290)\n",
            "Train Loss: 0.0403 Acc: 0.9880\n",
            "Val Loss: 0.1433 Acc: 0.9712\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "tensor(17381)\n",
            "Train Loss: 0.0206 Acc: 0.9932\n",
            "Val Loss: 0.1236 Acc: 0.9758\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "tensor(17420)\n",
            "Train Loss: 0.0143 Acc: 0.9954\n",
            "Val Loss: 0.1429 Acc: 0.9754\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "tensor(17392)\n",
            "Train Loss: 0.0185 Acc: 0.9938\n",
            "Val Loss: 0.1301 Acc: 0.9777\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "tensor(17377)\n",
            "Train Loss: 0.0251 Acc: 0.9930\n",
            "Val Loss: 0.1852 Acc: 0.9729\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "tensor(17299)\n",
            "Train Loss: 0.0426 Acc: 0.9885\n",
            "Val Loss: 0.1368 Acc: 0.9737\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "tensor(17358)\n",
            "Train Loss: 0.0278 Acc: 0.9919\n",
            "Val Loss: 0.1311 Acc: 0.9762\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "tensor(17423)\n",
            "Train Loss: 0.0141 Acc: 0.9956\n",
            "Val Loss: 0.1431 Acc: 0.9767\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "tensor(17410)\n",
            "Train Loss: 0.0194 Acc: 0.9949\n",
            "Val Loss: 0.1831 Acc: 0.9743\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "tensor(17449)\n",
            "Train Loss: 0.0087 Acc: 0.9971\n",
            "Val Loss: 0.1277 Acc: 0.9806\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "tensor(17499)\n",
            "Train Loss: 0.0005 Acc: 0.9999\n",
            "Val Loss: 0.1271 Acc: 0.9810\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0003 Acc: 1.0000\n",
            "Val Loss: 0.1267 Acc: 0.9811\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0002 Acc: 1.0000\n",
            "Val Loss: 0.1266 Acc: 0.9812\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0002 Acc: 1.0000\n",
            "Val Loss: 0.1268 Acc: 0.9815\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0002 Acc: 1.0000\n",
            "Val Loss: 0.1269 Acc: 0.9815\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1272 Acc: 0.9817\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1274 Acc: 0.9818\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1277 Acc: 0.9821\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "tensor(17500)\n",
            "Train Loss: 0.0001 Acc: 1.0000\n",
            "Val Loss: 0.1280 Acc: 0.9820\n",
            "\n",
            "Training complete in 11m 23s\n",
            "Best val Acc: 0.982091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wdOueSbyprw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7408f9-1a10-457a-a6d4-260512e4ec9a"
      },
      "source": [
        "correct_prob_1 = 0\n",
        "total_prob_1 = 0\n",
        "post_prob_1 = []\n",
        "pred_prob_1 = []\n",
        "\n",
        "epochs = 10\n",
        "post_probs_1 = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with torch.no_grad():\n",
        "        best_net1.eval()\n",
        "        for data in prob_dl:\n",
        "            images_prob_1, labels_prob_1 = data\n",
        "            outputs_prob_1 = best_net1(images_prob_1)\n",
        "\n",
        "            sm1 = torch.nn.Softmax()\n",
        "            probabilities_prob_1 = sm1(outputs_prob_1)\n",
        "            post_prob_1.append(probabilities_prob_1)\n",
        "            _, predicted_prob_1 = torch.max(outputs_prob_1.data, 1)\n",
        "            pred_prob_1.append(predicted_prob_1.item())\n",
        "            \n",
        "\n",
        "            total_prob_1 += labels_prob_1.size(0)\n",
        "            correct_prob_1 += (predicted_prob_1== labels_prob_1).sum().item()\n",
        "    accuracy = 100 * (correct_prob_1 / total_prob_1)\n",
        "    post_probs_1.append(post_prob_1)\n",
        "\n",
        "print('Probabilities', probabilities_prob_1)\n",
        "print('length of Probabilities', len(post_prob_1))\n",
        "print('Total Images: ', total_prob_1)\n",
        "print('Accuracy of the network on the 11000 test images:',  accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Probabilities tensor([[2.1290e-25, 2.4396e-17, 1.0000e+00, 5.3378e-24, 2.9019e-23, 1.5574e-27,\n",
            "         1.4317e-34, 3.2980e-25, 5.7248e-23, 4.6112e-25]])\n",
            "length of Probabilities 50000\n",
            "Total Images:  50000\n",
            "Accuracy of the network on the 11000 test images: 98.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my0BjWtU0nid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6110a1-1289-4e4a-d5c4-27f3cc56f808"
      },
      "source": [
        "len(post_probs_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTDuPVZhx3il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143a41ca-dc82-4975-a712-2caab7ad537f"
      },
      "source": [
        "correct_prob_2 = 0\n",
        "total_prob_2 = 0\n",
        "post_prob_2 = []\n",
        "pred_prob_2 = []\n",
        "\n",
        "epochs = 10\n",
        "post_probs_2 = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with torch.no_grad():\n",
        "        best_net2.eval()\n",
        "        for data in prob_dl:\n",
        "            images_prob_2, labels_prob_2 = data\n",
        "            outputs_prob_2 = best_net2(images_prob_2)\n",
        "\n",
        "            sm2 = torch.nn.Softmax()\n",
        "            probabilities_prob_2 = sm2(outputs_prob_2)\n",
        "            post_prob_2.append(probabilities_prob_2)\n",
        "            _, predicted_prob_2 = torch.max(outputs_prob_2.data, 1)\n",
        "            pred_prob_2.append(predicted_prob_2.item())\n",
        "            \n",
        "\n",
        "            total_prob_2 += labels_prob_2.size(0)\n",
        "            correct_prob_2 += (predicted_prob_2== labels_prob_2).sum().item()\n",
        "    accuracy2 = 100 * (correct_prob_2 / total_prob_2)\n",
        "    post_probs_2.append(post_prob_2)\n",
        "\n",
        "print('Probabilities', probabilities_prob_2)\n",
        "print('length of Probabilities', len(post_prob_2))\n",
        "print('Total Images: ', total_prob_2)\n",
        "print('Accuracy of the network on the 11000 test images:',  accuracy2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Probabilities tensor([[1.4172e-15, 2.9050e-13, 1.0000e+00, 1.9719e-11, 2.3312e-13, 5.0118e-17,\n",
            "         7.3261e-20, 6.4468e-13, 4.0697e-06, 2.3454e-12]])\n",
            "length of Probabilities 50000\n",
            "Total Images:  50000\n",
            "Accuracy of the network on the 11000 test images: 98.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBtVK7DEyZcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55b5e736-957d-4ebc-f918-dc3f6fbe7f26"
      },
      "source": [
        "len(post_probs_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Z3Ndpq2hh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2299aac-3848-453d-f892-cbcadd147aa8"
      },
      "source": [
        "correct_prob_3 = 0\n",
        "total_prob_3 = 0\n",
        "post_prob_3 = []\n",
        "pred_prob_3 = []\n",
        "\n",
        "epochs = 10\n",
        "post_probs_3 = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with torch.no_grad():\n",
        "        best_net3.eval()\n",
        "        for data in prob_dl:\n",
        "            images_prob_3, labels_prob_3 = data\n",
        "            outputs_prob_3 = best_net3(images_prob_3)\n",
        "\n",
        "            sm3 = torch.nn.Softmax()\n",
        "            probabilities_prob_3 = sm3(outputs_prob_3)\n",
        "            post_prob_3.append(probabilities_prob_3)\n",
        "            _, predicted_prob_3 = torch.max(outputs_prob_3.data, 1)\n",
        "            pred_prob_3.append(predicted_prob_3.item())\n",
        "            \n",
        "\n",
        "            total_prob_3 += labels_prob_3.size(0)\n",
        "            correct_prob_3 += (predicted_prob_3 == labels_prob_3).sum().item()\n",
        "    accuracy3 = 100 * (correct_prob_3 / total_prob_3)\n",
        "    post_probs_3.append(post_prob_3)\n",
        "\n",
        "print('Probabilities', probabilities_prob_3)\n",
        "print('length of Probabilities', len(post_prob_3))\n",
        "print('Total Images: ', total_prob_3)\n",
        "print('Accuracy of the network on the 11000 test images:',  accuracy3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Probabilities tensor([[2.2834e-17, 4.8617e-14, 1.0000e+00, 1.6915e-12, 4.1438e-22, 5.4676e-20,\n",
            "         5.6909e-19, 2.3004e-17, 7.4926e-12, 3.8881e-13]])\n",
            "length of Probabilities 50000\n",
            "Total Images:  50000\n",
            "Accuracy of the network on the 11000 test images: 98.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN2K3I362_XH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4c17c8-8427-4c18-fbc3-9f4d40b1ed93"
      },
      "source": [
        "len(post_probs_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXjJmsdC3X0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47108068-3553-40ce-f30a-4e3c19eeb24c"
      },
      "source": [
        "correct_prob_4 = 0\n",
        "total_prob_4 = 0\n",
        "post_prob_4 = []\n",
        "pred_prob_4 = []\n",
        "\n",
        "epochs = 10\n",
        "post_probs_4 = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with torch.no_grad():\n",
        "        best_net4.eval()\n",
        "        for data in prob_dl:\n",
        "            images_prob_4, labels_prob_4 = data\n",
        "            outputs_prob_4 = best_net4(images_prob_4)\n",
        "\n",
        "            sm4 = torch.nn.Softmax()\n",
        "            probabilities_prob_4 = sm4(outputs_prob_4)\n",
        "            post_prob_4.append(probabilities_prob_4)\n",
        "            _, predicted_prob_4 = torch.max(outputs_prob_4.data, 1)\n",
        "            pred_prob_4.append(predicted_prob_4.item())\n",
        "            \n",
        "\n",
        "            total_prob_4 += labels_prob_4.size(0)\n",
        "            correct_prob_4 += (predicted_prob_4 == labels_prob_4).sum().item()\n",
        "    accuracy4 = 100 * (correct_prob_4 / total_prob_4)\n",
        "    post_probs_4.append(post_prob_4)\n",
        "\n",
        "print('Probabilities', probabilities_prob_4)\n",
        "print('length of Probabilities', len(post_prob_4))\n",
        "print('Total Images: ', total_prob_4)\n",
        "print('Accuracy of the network on the 11000 test images:',  accuracy4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Probabilities tensor([[4.0795e-16, 1.5751e-07, 1.0000e+00, 3.5783e-12, 2.7458e-17, 1.4462e-19,\n",
            "         7.5041e-17, 1.2362e-13, 5.7614e-13, 1.3550e-12]])\n",
            "length of Probabilities 50000\n",
            "Total Images:  50000\n",
            "Accuracy of the network on the 11000 test images: 98.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MEEyTBK39aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e7691c-72fb-446e-d5f5-619ef5aa366e"
      },
      "source": [
        "len(post_probs_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeIWv22R4Rf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce559e0f-d9c7-4523-c373-f0683cbadebb"
      },
      "source": [
        "correct_prob_5 = 0\n",
        "total_prob_5 = 0\n",
        "post_prob_5 = []\n",
        "pred_prob_5 = []\n",
        "\n",
        "epochs = 10\n",
        "post_probs_5 = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with torch.no_grad():\n",
        "        best_net5.eval()\n",
        "        for data in prob_dl:\n",
        "            images_prob_5, labels_prob_5 = data\n",
        "            outputs_prob_5 = best_net5(images_prob_5)\n",
        "\n",
        "            sm5 = torch.nn.Softmax()\n",
        "            probabilities_prob_5 = sm5(outputs_prob_5)\n",
        "            post_prob_5.append(probabilities_prob_5)\n",
        "            _, predicted_prob_5 = torch.max(outputs_prob_5.data, 1)\n",
        "            pred_prob_5.append(predicted_prob_5.item())\n",
        "            \n",
        "\n",
        "            total_prob_5 += labels_prob_5.size(0)\n",
        "            correct_prob_5 += (predicted_prob_5 == labels_prob_5).sum().item()\n",
        "        accuracy5 = 100 * (correct_prob_5 / total_prob_5)\n",
        "        post_probs_5.append(post_prob_5)\n",
        "\n",
        "print('Probabilities', probabilities_prob_5)\n",
        "print('length of Probabilities', len(post_prob_5))\n",
        "print('Total Images: ', total_prob_5)\n",
        "print('Accuracy of the network on the 11000 test images:',  accuracy5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Probabilities tensor([[1.7856e-22, 2.6034e-11, 1.0000e+00, 5.5756e-12, 6.2356e-19, 1.5053e-21,\n",
            "         3.2385e-20, 5.4753e-18, 3.5653e-18, 2.8973e-18]])\n",
            "length of Probabilities 50000\n",
            "Total Images:  50000\n",
            "Accuracy of the network on the 11000 test images: 98.46000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xTt4gxA5qSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043bbe06-0832-42b0-8e30-57d66050b5ef"
      },
      "source": [
        "len(post_probs_5)\n",
        "post_probs_5[0][2] == post_probs_5[1][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmZa6JCLFxMS"
      },
      "source": [
        "# Calculate MSE for any two set of posterior probabilities that observed from two different models\n",
        "\n",
        "def nn_mse_loss(post_1, post_2):\n",
        "  mse_loss_meth = nn.MSELoss()\n",
        "  mse_loss = mse_loss_meth(torch.stack(post_1), torch.stack(post_2))\n",
        "  return mse_loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTkbpmY91Qjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd89fcd2-4dd8-4f6c-b272-6495bbe3ad1c"
      },
      "source": [
        "mse_losses_1_2 = []\n",
        "\n",
        "for l1, l2 in zip(post_probs_1, post_probs_2):\n",
        "    mse_losses_1_2.append(nn_mse_loss(l1, l2))\n",
        "print(mse_losses_1_2)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0029438864439725876, 0.0029438864439725876, 0.0029438864439725876, 0.0029438864439725876, 0.0029438864439725876, 0.0029438864439725876, 0.0029438864439725876, 0.0029438864439725876, 0.0029438864439725876, 0.0029438864439725876]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZzVeo0-5zyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67664de8-765a-4181-cee9-d153a56d686e"
      },
      "source": [
        "mse_losses_1_3 = []\n",
        "\n",
        "for l1, l3 in zip(post_probs_1, post_probs_3):\n",
        "    mse_losses_1_3.append(nn_mse_loss(l1, l3))\n",
        "print(mse_losses_1_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.002516572130843997, 0.002516572130843997, 0.002516572130843997, 0.002516572130843997, 0.002516572130843997, 0.002516572130843997, 0.002516572130843997, 0.002516572130843997, 0.002516572130843997, 0.002516572130843997]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUkYKS_d56kQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3f199a-ad3e-4900-cb69-e3348cf0b431"
      },
      "source": [
        "mse_losses_1_4 = []\n",
        "\n",
        "for l1, l4 in zip(post_probs_1, post_probs_4):\n",
        "    mse_losses_1_4.append(nn_mse_loss(l1, l4))\n",
        "print(mse_losses_1_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0029750007670372725, 0.0029750007670372725, 0.0029750007670372725, 0.0029750007670372725, 0.0029750007670372725, 0.0029750007670372725, 0.0029750007670372725, 0.0029750007670372725, 0.0029750007670372725, 0.0029750007670372725]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnGXksxI6A_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9615216c-cc0c-44ed-883e-21aa29abd63c"
      },
      "source": [
        "mse_losses_1_5 = []\n",
        "\n",
        "for l1, l5 in zip(post_probs_1, post_probs_5):\n",
        "    mse_losses_1_5.append(nn_mse_loss(l1, l5))\n",
        "print(mse_losses_1_5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0024781536776572466, 0.0024781536776572466, 0.0024781536776572466, 0.0024781536776572466, 0.0024781536776572466, 0.0024781536776572466, 0.0024781536776572466, 0.0024781536776572466, 0.0024781536776572466, 0.0024781536776572466]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv2KI-ECVo9O"
      },
      "source": [
        "#Calculate Model Similarity\n",
        "\n",
        "def model_similarity(mod_1, mod_2):\n",
        "  zip_lists = zip(mod_1, mod_2)\n",
        "  corr = 0\n",
        "  total = 0\n",
        "  for list_t, list_p in zip_lists:\n",
        "    total += 1\n",
        "    if list_t-list_p == 0:\n",
        "      corr += 1\n",
        "\n",
        "  accuracy = (corr / total) * 100\n",
        "\n",
        "  print(\"Model Similarity: \", accuracy, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgXrtcSoXUc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "106428a0-bdea-4faa-ebf7-23083972d545"
      },
      "source": [
        "# Print the model similarity\n",
        "\n",
        "model_similarity(pred_prob_1, pred_prob_2)\n",
        "model_similarity(pred_prob_1, pred_prob_3)\n",
        "model_similarity(pred_prob_1, pred_prob_4)\n",
        "model_similarity(pred_prob_1, pred_prob_5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Similarity:  98.16 %\n",
            "Model Similarity:  98.5 %\n",
            "Model Similarity:  98.26 %\n",
            "Model Similarity:  98.34 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1U0G--kCCpA"
      },
      "source": [
        "from sklearn.metrics import *\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUv8CwpG91oQ"
      },
      "source": [
        "\n",
        "def arrange_mses(all_mses):\n",
        "    count_mse = 0\n",
        "    mse_data = []\n",
        "    mse_target = []\n",
        "\n",
        "    for mse_l in all_mses:\n",
        "        for mse in mse_l:\n",
        "            count_mse += 1\n",
        "            if count_mse <= 10:\n",
        "                mse_data.append(mse)\n",
        "                mse_target.append(1)\n",
        "            else:\n",
        "                mse_data.append(mse)\n",
        "                mse_target.append(0)\n",
        "    \n",
        "    mse_dict = {'data': mse_data,\n",
        "                'target': mse_target\n",
        "                }\n",
        "\n",
        "    return mse_dict\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG1exT09_TxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccc9f75-51a9-49af-e1ca-d7e41010212c"
      },
      "source": [
        "all_mses1 = [mse_losses_1_2, mse_losses_1_3, mse_losses_1_4, mse_losses_1_5]\n",
        "\n",
        "mses1 = arrange_mses(all_mses1)\n",
        "\n",
        "mse_df1 = pd.DataFrame(mses1, columns = ['data','target'], index=['mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5'])\n",
        "\n",
        "mse_df1 = mse_df1.sort_values(by=['data'])\n",
        "\n",
        "#print the labeled mses\n",
        "print (mse_df1.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             data  target\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4IkO1AQ_bv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9002be2-1614-4aed-d175-11d1a09f0785"
      },
      "source": [
        "all_mses2 = [mse_losses_1_3, mse_losses_1_2, mse_losses_1_4, mse_losses_1_5]\n",
        "\n",
        "mses2 = arrange_mses(all_mses2)\n",
        "\n",
        "mse_df2 = pd.DataFrame(mses2, columns = ['data','target'], index=['mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2',  'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5'])\n",
        "\n",
        "mse_df2 = mse_df2.sort_values(by=['data'])\n",
        "\n",
        "#print the labeled mses\n",
        "print (mse_df2.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             data  target\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfrb5lqCEDFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b402a0a3-0076-44e3-e669-0c37c911d16f"
      },
      "source": [
        "all_mses3 = [mse_losses_1_4, mse_losses_1_2, mse_losses_1_3, mse_losses_1_5]\n",
        "\n",
        "mses3 = arrange_mses(all_mses3)\n",
        "\n",
        "mse_df3 = pd.DataFrame(mses3, columns = ['data','target'], index=['mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5'])\n",
        "\n",
        "mse_df3 = mse_df3.sort_values(by=['data'])\n",
        "\n",
        "#print the labeled mses\n",
        "print (mse_df3.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             data  target\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n",
            "mse_1_5  0.002478       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TKnu_6FEe-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1e1830-fb94-47fd-8ca3-9fa6a07ce370"
      },
      "source": [
        "all_mses4 = [mse_losses_1_5, mse_losses_1_2, mse_losses_1_3, mse_losses_1_4]\n",
        "\n",
        "mses4 = arrange_mses(all_mses4)\n",
        "\n",
        "mse_df4 = pd.DataFrame(mses4, columns = ['data','target'], index=['mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_5', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_2', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_3', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_4', 'mse_1_5'])\n",
        "\n",
        "mse_df4 = mse_df4.sort_values(by=['data'])\n",
        "\n",
        "#print the labeled mses\n",
        "print (mse_df4.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             data  target\n",
            "mse_1_5  0.002478       1\n",
            "mse_1_5  0.002478       1\n",
            "mse_1_5  0.002478       1\n",
            "mse_1_5  0.002478       1\n",
            "mse_1_5  0.002478       1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR44RbWSmdqD"
      },
      "source": [
        "#calculate the auc\n",
        "\n",
        "mses_auc1 = auc(mse_df1.data, mse_df1.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74yG0WCt9Jn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084bc1ca-2c78-4817-bd46-aa241d9361c6"
      },
      "source": [
        "mses_auc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00022921431809663773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD4tM-KSRzka"
      },
      "source": [
        "#calculate the auc\n",
        "\n",
        "mses_auc2 = auc(mse_df2.data, mse_df2.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ1vAHJgR3h_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8f1ebd-3d2e-44a8-f9e6-d833802c5af3"
      },
      "source": [
        "mses_auc2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0002328663831576705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWBGj2smSDQ4"
      },
      "source": [
        "#calculate the auc\n",
        "\n",
        "mses_auc3 = auc(mse_df3.data, mse_df3.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q_GTaq9SE32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa667db-9a05-46c6-c42e-c9bda2d51baf"
      },
      "source": [
        "mses_auc3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5557161532342434e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XczoRnvUSUTY"
      },
      "source": [
        "#calculate the auc\n",
        "\n",
        "mses_auc4 = auc(mse_df4.data, mse_df4.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilNrZiRXSYCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfc7bb5-ee0b-47cf-f579-233c4d63a3b0"
      },
      "source": [
        "mses_auc4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9209226593375206e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA1UqQrmrqXX"
      },
      "source": [
        "MSE_AUC1 = 1 - mses_auc1\n",
        "MSE_AUC2 = 1 - mses_auc2\n",
        "MSE_AUC3 = 1 - mses_auc3\n",
        "MSE_AUC4 = 1 - mses_auc4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApnKiM91r-1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9723dafd-58c1-4ce6-f6ee-26dbebfddde6"
      },
      "source": [
        "print(\"MSE_AUC1: \", MSE_AUC1)\n",
        "print(\"MSE_AUC2: \", MSE_AUC2)\n",
        "print(\"MSE_AUC3: \", MSE_AUC3)\n",
        "print(\"MSE_AUC4: \", MSE_AUC4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE_AUC1:  0.9997707856819034\n",
            "MSE_AUC2:  0.9997671336168423\n",
            "MSE_AUC3:  0.9999844428384677\n",
            "MSE_AUC4:  0.9999807907734066\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}