{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HeDpjiKS-A4"
   },
   "source": [
    "Starts from the last file: Apr_18_2021_thesis_proj_OnGoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "id": "NgoqGX9tOBUd"
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import urllib\n",
    "from torch.optim import *\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "id": "QCRZ-12hgpyc"
   },
   "outputs": [],
   "source": [
    "mnist_data = torchvision.datasets.MNIST(root=\"./data/\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "id": "2GuyNJ56hfeb"
   },
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(mnist_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "tensor = dl.dataset.data\n",
    "\n",
    "print(type(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "id": "DedR7G7UZGcr"
   },
   "outputs": [],
   "source": [
    "#Pre-processing of Dataset\n",
    "tensor = dl.dataset.data\n",
    "tr = tensor.reshape(tensor.size(0), -1)  # reshaped\n",
    "targets = dl.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3Am1B-BLWWwi"
   },
   "outputs": [],
   "source": [
    "#---------------------------------Unseen Data : 5000-----------------------\n",
    "#Unseen Data : 5000\n",
    "\n",
    "mnist_unseen_data = tr[0:5000]\n",
    "mnist_unseen_data_final = mnist_unseen_data.view(-1, 1,28,28).float()\n",
    "mnist_unseen_label = targets[0:5000]\n",
    "\n",
    "prob_ds = TensorDataset(mnist_unseen_data_final, mnist_unseen_label)\n",
    "\n",
    "prob_dl = torch.utils.data.DataLoader(prob_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist_unseen_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cm-Vx10IWwMu"
   },
   "outputs": [],
   "source": [
    "#Training Data: 44000\n",
    "\n",
    "trainset_data = tr[5000: 49001]\n",
    "trainset_target = targets[5000: 49001]\n",
    "\n",
    "trainset_data_numpy = np.array(trainset_data)\n",
    "trainset_target_numpy = np.array(trainset_target)\n",
    "\n",
    "train_with_target = np.c_[trainset_data_numpy, trainset_target_numpy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7u5zd5ZWW1jN"
   },
   "outputs": [],
   "source": [
    "# Test Data: 11000\n",
    "\n",
    "test_data = tr[49001:]\n",
    "test_data_final = test_data.view(-1, 1,28,28).float()\n",
    "test_target = targets[49001:]\n",
    "\n",
    "#Test Set\n",
    "test_ds = TensorDataset(test_data_final, test_target)\n",
    "\n",
    "#Test Loader\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10999"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr[49001:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PUgBW-OdXqzE"
   },
   "outputs": [],
   "source": [
    "#Trainset A:\n",
    "\n",
    "#A: Data\n",
    "trainset_a = train_with_target[0: 8000]\n",
    "trainset_a_pd = pd.DataFrame(trainset_a)\n",
    "\n",
    "#Common Data of 25%, 50% and 75%\n",
    "# chunk_a1 = trainset_a_pd.sample(4375) #25% Common data\n",
    "# chunk_a2 = trainset_a_pd.sample(8750) #50% Common data\n",
    "# chunk_a3 = trainset_a_pd.sample(13125) #75% Common data\n",
    "\n",
    "# chunk_a1 = pd.DataFrame(np.array(chunk_a1))\n",
    "# chunk_a2 = pd.DataFrame(np.array(chunk_a2))\n",
    "# chunk_a3 = pd.DataFrame(np.array(chunk_a3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DXE90Pbg6SXQ"
   },
   "outputs": [],
   "source": [
    "chunk_a11 = trainset_a_pd.sample(800)\n",
    "chunk_a11 = pd.DataFrame(np.array(chunk_a11))\n",
    "\n",
    "chunk_a12 = trainset_a_pd.sample(800)\n",
    "chunk_a12 = pd.DataFrame(np.array(chunk_a12))\n",
    "\n",
    "chunk_a13 = trainset_a_pd.sample(800)\n",
    "chunk_a13 = pd.DataFrame(np.array(chunk_a13))\n",
    "\n",
    "chunk_a14 = trainset_a_pd.sample(800)\n",
    "chunk_a14 = pd.DataFrame(np.array(chunk_a14))\n",
    "\n",
    "chunk_a15 = trainset_a_pd.sample(800)\n",
    "chunk_a15 = pd.DataFrame(np.array(chunk_a15))\n",
    "\n",
    "chunk_a16 = trainset_a_pd.sample(800)\n",
    "chunk_a16 = pd.DataFrame(np.array(chunk_a16))\n",
    "\n",
    "chunk_a17 = trainset_a_pd.sample(800)\n",
    "chunk_a17 = pd.DataFrame(np.array(chunk_a17))\n",
    "\n",
    "chunk_a18 = trainset_a_pd.sample(800)\n",
    "chunk_a18 = pd.DataFrame(np.array(chunk_a18))\n",
    "\n",
    "chunk_a19 = trainset_a_pd.sample(800)\n",
    "chunk_a19 = pd.DataFrame(np.array(chunk_a19))\n",
    "\n",
    "chunk_a110 = trainset_a_pd.sample(800)\n",
    "chunk_a110 = pd.DataFrame(np.array(chunk_a110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "meWqGJBA931W"
   },
   "outputs": [],
   "source": [
    "chunk_a21 = trainset_a_pd.sample(1600)\n",
    "chunk_a21 = pd.DataFrame(np.array(chunk_a21))\n",
    "\n",
    "chunk_a22 = trainset_a_pd.sample(1600)\n",
    "chunk_a22 = pd.DataFrame(np.array(chunk_a22))\n",
    "\n",
    "chunk_a23 = trainset_a_pd.sample(1600)\n",
    "chunk_a23 = pd.DataFrame(np.array(chunk_a23))\n",
    "\n",
    "chunk_a24 = trainset_a_pd.sample(1600)\n",
    "chunk_a24 = pd.DataFrame(np.array(chunk_a24))\n",
    "\n",
    "chunk_a25 = trainset_a_pd.sample(1600)\n",
    "chunk_a25 = pd.DataFrame(np.array(chunk_a25))\n",
    "\n",
    "chunk_a26 = trainset_a_pd.sample(1600)\n",
    "chunk_a26 = pd.DataFrame(np.array(chunk_a26))\n",
    "\n",
    "chunk_a27 = trainset_a_pd.sample(1600)\n",
    "chunk_a27 = pd.DataFrame(np.array(chunk_a27))\n",
    "\n",
    "chunk_a28 = trainset_a_pd.sample(1600)\n",
    "chunk_a28 = pd.DataFrame(np.array(chunk_a28))\n",
    "\n",
    "chunk_a29 = trainset_a_pd.sample(1600)\n",
    "chunk_a29 = pd.DataFrame(np.array(chunk_a29))\n",
    "\n",
    "chunk_a210 = trainset_a_pd.sample(1600)\n",
    "chunk_a210 = pd.DataFrame(np.array(chunk_a210))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3RdR_c4f-YMw"
   },
   "outputs": [],
   "source": [
    "chunk_a31 = trainset_a_pd.sample(2400)\n",
    "chunk_a31 = pd.DataFrame(np.array(chunk_a31))\n",
    "\n",
    "chunk_a32 = trainset_a_pd.sample(2400)\n",
    "chunk_a32 = pd.DataFrame(np.array(chunk_a32))\n",
    "\n",
    "chunk_a33 = trainset_a_pd.sample(2400)\n",
    "chunk_a33 = pd.DataFrame(np.array(chunk_a33))\n",
    "\n",
    "chunk_a34 = trainset_a_pd.sample(2400)\n",
    "chunk_a34 = pd.DataFrame(np.array(chunk_a34))\n",
    "\n",
    "chunk_a35 = trainset_a_pd.sample(2400)\n",
    "chunk_a35 = pd.DataFrame(np.array(chunk_a35))\n",
    "\n",
    "chunk_a36 = trainset_a_pd.sample(2400)\n",
    "chunk_a36 = pd.DataFrame(np.array(chunk_a36))\n",
    "\n",
    "chunk_a37 = trainset_a_pd.sample(2400)\n",
    "chunk_a37 = pd.DataFrame(np.array(chunk_a37))\n",
    "\n",
    "chunk_a38 = trainset_a_pd.sample(2400)\n",
    "chunk_a38 = pd.DataFrame(np.array(chunk_a38))\n",
    "\n",
    "chunk_a39 = trainset_a_pd.sample(2400)\n",
    "chunk_a39 = pd.DataFrame(np.array(chunk_a39))\n",
    "\n",
    "chunk_a310 = trainset_a_pd.sample(2400)\n",
    "chunk_a310 = pd.DataFrame(np.array(chunk_a310))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "26pw0T3uYWiW"
   },
   "outputs": [],
   "source": [
    "chunk_a41 = trainset_a_pd.sample(3200)\n",
    "chunk_a41 = pd.DataFrame(np.array(chunk_a41))\n",
    "\n",
    "chunk_a42 = trainset_a_pd.sample(3200)\n",
    "chunk_a42 = pd.DataFrame(np.array(chunk_a42))\n",
    "\n",
    "chunk_a43 = trainset_a_pd.sample(3200)\n",
    "chunk_a43 = pd.DataFrame(np.array(chunk_a43))\n",
    "\n",
    "chunk_a44 = trainset_a_pd.sample(3200)\n",
    "chunk_a44 = pd.DataFrame(np.array(chunk_a44))\n",
    "\n",
    "chunk_a45 = trainset_a_pd.sample(3200)\n",
    "chunk_a45 = pd.DataFrame(np.array(chunk_a45))\n",
    "\n",
    "chunk_a46 = trainset_a_pd.sample(3200)\n",
    "chunk_a46 = pd.DataFrame(np.array(chunk_a46))\n",
    "\n",
    "chunk_a47 = trainset_a_pd.sample(3200)\n",
    "chunk_a47 = pd.DataFrame(np.array(chunk_a47))\n",
    "\n",
    "chunk_a48 = trainset_a_pd.sample(3200)\n",
    "chunk_a48 = pd.DataFrame(np.array(chunk_a48))\n",
    "\n",
    "chunk_a49 = trainset_a_pd.sample(3200)\n",
    "chunk_a49 = pd.DataFrame(np.array(chunk_a49))\n",
    "\n",
    "chunk_a410 = trainset_a_pd.sample(3200)\n",
    "chunk_a410 = pd.DataFrame(np.array(chunk_a410))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TKVyAWEBY16T"
   },
   "outputs": [],
   "source": [
    "chunk_a51 = trainset_a_pd.sample(4000)\n",
    "chunk_a51 = pd.DataFrame(np.array(chunk_a51))\n",
    "\n",
    "chunk_a52 = trainset_a_pd.sample(4000)\n",
    "chunk_a52 = pd.DataFrame(np.array(chunk_a52))\n",
    "\n",
    "chunk_a53 = trainset_a_pd.sample(4000)\n",
    "chunk_a53 = pd.DataFrame(np.array(chunk_a53))\n",
    "\n",
    "chunk_a54 = trainset_a_pd.sample(4000)\n",
    "chunk_a54 = pd.DataFrame(np.array(chunk_a54))\n",
    "\n",
    "chunk_a55 = trainset_a_pd.sample(4000)\n",
    "chunk_a55 = pd.DataFrame(np.array(chunk_a55))\n",
    "\n",
    "chunk_a56 = trainset_a_pd.sample(4000)\n",
    "chunk_a56 = pd.DataFrame(np.array(chunk_a56))\n",
    "\n",
    "chunk_a57 = trainset_a_pd.sample(4000)\n",
    "chunk_a57 = pd.DataFrame(np.array(chunk_a57))\n",
    "\n",
    "chunk_a58 = trainset_a_pd.sample(4000)\n",
    "chunk_a58 = pd.DataFrame(np.array(chunk_a58))\n",
    "\n",
    "chunk_a59 = trainset_a_pd.sample(4000)\n",
    "chunk_a59 = pd.DataFrame(np.array(chunk_a59))\n",
    "\n",
    "chunk_a510 = trainset_a_pd.sample(4000)\n",
    "chunk_a510 = pd.DataFrame(np.array(chunk_a510))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4jzNgtFWZaxx"
   },
   "outputs": [],
   "source": [
    "chunk_a61 = trainset_a_pd.sample(4800)\n",
    "chunk_a61 = pd.DataFrame(np.array(chunk_a61))\n",
    "\n",
    "chunk_a62 = trainset_a_pd.sample(4800)\n",
    "chunk_a62 = pd.DataFrame(np.array(chunk_a62))\n",
    "\n",
    "chunk_a63 = trainset_a_pd.sample(4800)\n",
    "chunk_a63 = pd.DataFrame(np.array(chunk_a63))\n",
    "\n",
    "chunk_a64 = trainset_a_pd.sample(4800)\n",
    "chunk_a64 = pd.DataFrame(np.array(chunk_a64))\n",
    "\n",
    "chunk_a65 = trainset_a_pd.sample(4800)\n",
    "chunk_a65 = pd.DataFrame(np.array(chunk_a65))\n",
    "\n",
    "chunk_a66 = trainset_a_pd.sample(4800)\n",
    "chunk_a66 = pd.DataFrame(np.array(chunk_a66))\n",
    "\n",
    "chunk_a67 = trainset_a_pd.sample(4800)\n",
    "chunk_a67 = pd.DataFrame(np.array(chunk_a67))\n",
    "\n",
    "chunk_a68 = trainset_a_pd.sample(4800)\n",
    "chunk_a68 = pd.DataFrame(np.array(chunk_a68))\n",
    "\n",
    "chunk_a69 = trainset_a_pd.sample(4800)\n",
    "chunk_a69 = pd.DataFrame(np.array(chunk_a69))\n",
    "\n",
    "chunk_a610 = trainset_a_pd.sample(4800)\n",
    "chunk_a610 = pd.DataFrame(np.array(chunk_a610))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ob4fcMojZ62P"
   },
   "outputs": [],
   "source": [
    "chunk_a71 = trainset_a_pd.sample(5600)\n",
    "chunk_a71 = pd.DataFrame(np.array(chunk_a71))\n",
    "\n",
    "chunk_a72 = trainset_a_pd.sample(5600)\n",
    "chunk_a72 = pd.DataFrame(np.array(chunk_a72))\n",
    "\n",
    "chunk_a73 = trainset_a_pd.sample(5600)\n",
    "chunk_a73 = pd.DataFrame(np.array(chunk_a73))\n",
    "\n",
    "chunk_a74 = trainset_a_pd.sample(5600)\n",
    "chunk_a74 = pd.DataFrame(np.array(chunk_a74))\n",
    "\n",
    "chunk_a75 = trainset_a_pd.sample(5600)\n",
    "chunk_a75 = pd.DataFrame(np.array(chunk_a75))\n",
    "\n",
    "chunk_a76 = trainset_a_pd.sample(5600)\n",
    "chunk_a76 = pd.DataFrame(np.array(chunk_a76))\n",
    "\n",
    "chunk_a77 = trainset_a_pd.sample(5600)\n",
    "chunk_a77 = pd.DataFrame(np.array(chunk_a77))\n",
    "\n",
    "chunk_a78 = trainset_a_pd.sample(5600)\n",
    "chunk_a78 = pd.DataFrame(np.array(chunk_a78))\n",
    "\n",
    "chunk_a79 = trainset_a_pd.sample(5600)\n",
    "chunk_a79 = pd.DataFrame(np.array(chunk_a79))\n",
    "\n",
    "chunk_a710 = trainset_a_pd.sample(5600)\n",
    "chunk_a710 = pd.DataFrame(np.array(chunk_a710))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "n-MbYNJjikNR"
   },
   "outputs": [],
   "source": [
    "chunk_a81 = trainset_a_pd.sample(6400)\n",
    "chunk_a81 = pd.DataFrame(np.array(chunk_a81))\n",
    "\n",
    "chunk_a82 = trainset_a_pd.sample(6400)\n",
    "chunk_a82 = pd.DataFrame(np.array(chunk_a82))\n",
    "\n",
    "chunk_a83 = trainset_a_pd.sample(6400)\n",
    "chunk_a83 = pd.DataFrame(np.array(chunk_a83))\n",
    "\n",
    "chunk_a84 = trainset_a_pd.sample(6400)\n",
    "chunk_a84 = pd.DataFrame(np.array(chunk_a84))\n",
    "\n",
    "chunk_a85 = trainset_a_pd.sample(6400)\n",
    "chunk_a85 = pd.DataFrame(np.array(chunk_a85))\n",
    "\n",
    "chunk_a86 = trainset_a_pd.sample(6400)\n",
    "chunk_a86 = pd.DataFrame(np.array(chunk_a86))\n",
    "\n",
    "chunk_a87 = trainset_a_pd.sample(6400)\n",
    "chunk_a87 = pd.DataFrame(np.array(chunk_a87))\n",
    "\n",
    "chunk_a88 = trainset_a_pd.sample(6400)\n",
    "chunk_a88 = pd.DataFrame(np.array(chunk_a88))\n",
    "\n",
    "chunk_a89 = trainset_a_pd.sample(6400)\n",
    "chunk_a89 = pd.DataFrame(np.array(chunk_a89))\n",
    "\n",
    "chunk_a810 = trainset_a_pd.sample(6400)\n",
    "chunk_a810 = pd.DataFrame(np.array(chunk_a810))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "G6e8E9ghllLp"
   },
   "outputs": [],
   "source": [
    "chunk_a91 = trainset_a_pd.sample(7200)\n",
    "chunk_a91 = pd.DataFrame(np.array(chunk_a91))\n",
    "\n",
    "chunk_a92 = trainset_a_pd.sample(7200)\n",
    "chunk_a92 = pd.DataFrame(np.array(chunk_a92))\n",
    "\n",
    "chunk_a93 = trainset_a_pd.sample(7200)\n",
    "chunk_a93 = pd.DataFrame(np.array(chunk_a93))\n",
    "\n",
    "chunk_a94 = trainset_a_pd.sample(7200)\n",
    "chunk_a94 = pd.DataFrame(np.array(chunk_a94))\n",
    "\n",
    "chunk_a95 = trainset_a_pd.sample(7200)\n",
    "chunk_a95 = pd.DataFrame(np.array(chunk_a95))\n",
    "\n",
    "chunk_a96 = trainset_a_pd.sample(7200)\n",
    "chunk_a96 = pd.DataFrame(np.array(chunk_a96))\n",
    "\n",
    "chunk_a97 = trainset_a_pd.sample(7200)\n",
    "chunk_a97 = pd.DataFrame(np.array(chunk_a97))\n",
    "\n",
    "chunk_a98 = trainset_a_pd.sample(7200)\n",
    "chunk_a98 = pd.DataFrame(np.array(chunk_a98))\n",
    "\n",
    "chunk_a99 = trainset_a_pd.sample(7200)\n",
    "chunk_a99 = pd.DataFrame(np.array(chunk_a99))\n",
    "\n",
    "chunk_a910 = trainset_a_pd.sample(7200)\n",
    "chunk_a910 = pd.DataFrame(np.array(chunk_a910))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UlT2XdDkXnyU"
   },
   "outputs": [],
   "source": [
    "#Trainset B: 10% Common of A\n",
    "\n",
    "#B: Data\n",
    "trainset_b1 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b1_pd = pd.DataFrame(trainset_b1)\n",
    "trainset_b1_pd = pd.DataFrame(np.array(trainset_b1_pd))\n",
    "trainset_b1_pd = trainset_b1_pd.append(chunk_a11) #4375\n",
    "trainset_b1_pd = pd.DataFrame(np.array(trainset_b1_pd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ak6-QZDkfg64"
   },
   "outputs": [],
   "source": [
    "trainset_b2 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b2_pd = pd.DataFrame(trainset_b2)\n",
    "trainset_b2_pd = pd.DataFrame(np.array(trainset_b2_pd))\n",
    "trainset_b2_pd = trainset_b2_pd.append(chunk_a12) #4375\n",
    "trainset_b2_pd = pd.DataFrame(np.array(trainset_b2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "jFq8ASXsGTsw"
   },
   "outputs": [],
   "source": [
    "trainset_b3 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b3_pd = pd.DataFrame(trainset_b3)\n",
    "trainset_b3_pd = pd.DataFrame(np.array(trainset_b3_pd))\n",
    "trainset_b3_pd = trainset_b3_pd.append(chunk_a13) #4375\n",
    "trainset_b3_pd = pd.DataFrame(np.array(trainset_b3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HCc6f06WlLXJ"
   },
   "outputs": [],
   "source": [
    "trainset_b4 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b4_pd = pd.DataFrame(trainset_b4)\n",
    "trainset_b4_pd = pd.DataFrame(np.array(trainset_b4_pd))\n",
    "trainset_b4_pd = trainset_b4_pd.append(chunk_a14) #4375\n",
    "trainset_b4_pd = pd.DataFrame(np.array(trainset_b4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qIjEPAoTlkmS"
   },
   "outputs": [],
   "source": [
    "trainset_b5 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b5_pd = pd.DataFrame(trainset_b5)\n",
    "trainset_b5_pd = pd.DataFrame(np.array(trainset_b5_pd))\n",
    "trainset_b5_pd = trainset_b5_pd.append(chunk_a15) #4375\n",
    "trainset_b5_pd = pd.DataFrame(np.array(trainset_b5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kql2ato5lr3Y"
   },
   "outputs": [],
   "source": [
    "trainset_b6 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b6_pd = pd.DataFrame(trainset_b6)\n",
    "trainset_b6_pd = pd.DataFrame(np.array(trainset_b6_pd))\n",
    "trainset_b6_pd = trainset_b6_pd.append(chunk_a16) #4375\n",
    "trainset_b6_pd = pd.DataFrame(np.array(trainset_b6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "W7F2qLmMl0UY"
   },
   "outputs": [],
   "source": [
    "trainset_b7 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b7_pd = pd.DataFrame(trainset_b7)\n",
    "trainset_b7_pd = pd.DataFrame(np.array(trainset_b7_pd))\n",
    "trainset_b7_pd = trainset_b7_pd.append(chunk_a17) #4375\n",
    "trainset_b7_pd = pd.DataFrame(np.array(trainset_b7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Qj0PcddBl8eC"
   },
   "outputs": [],
   "source": [
    "trainset_b8 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b8_pd = pd.DataFrame(trainset_b8)\n",
    "trainset_b8_pd = pd.DataFrame(np.array(trainset_b8_pd))\n",
    "trainset_b8_pd = trainset_b8_pd.append(chunk_a18) #4375\n",
    "trainset_b8_pd = pd.DataFrame(np.array(trainset_b8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Wi0hhLcimDQ4"
   },
   "outputs": [],
   "source": [
    "trainset_b9 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b9_pd = pd.DataFrame(trainset_b9)\n",
    "trainset_b9_pd = pd.DataFrame(np.array(trainset_b9_pd))\n",
    "trainset_b9_pd = trainset_b9_pd.append(chunk_a19) #4375\n",
    "trainset_b9_pd = pd.DataFrame(np.array(trainset_b9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "RQMecCtzmLF_"
   },
   "outputs": [],
   "source": [
    "trainset_b10 = train_with_target[8001: 15201] #13125 data\n",
    "trainset_b10_pd = pd.DataFrame(trainset_b10)\n",
    "trainset_b10_pd = pd.DataFrame(np.array(trainset_b10_pd))\n",
    "trainset_b10_pd = trainset_b10_pd.append(chunk_a110) #4375\n",
    "trainset_b10_pd = pd.DataFrame(np.array(trainset_b10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lBofrMepXkmE"
   },
   "outputs": [],
   "source": [
    "#Trainset C: 20% common from A\n",
    "\n",
    "#C: Data\n",
    "trainset_c1 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c1_pd = pd.DataFrame(trainset_c1)\n",
    "trainset_c1_pd = pd.DataFrame(np.array(trainset_c1_pd))\n",
    "trainset_c1_pd = trainset_c1_pd.append(chunk_a21) #8750\n",
    "trainset_c1_pd = pd.DataFrame(np.array(trainset_c1_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qv2nV30JmmCf"
   },
   "outputs": [],
   "source": [
    "trainset_c2 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c2_pd = pd.DataFrame(trainset_c2)\n",
    "trainset_c2_pd = pd.DataFrame(np.array(trainset_c2_pd))\n",
    "trainset_c2_pd = trainset_c2_pd.append(chunk_a22) #8750\n",
    "trainset_c2_pd = pd.DataFrame(np.array(trainset_c2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rTvbEnLmpfRu"
   },
   "outputs": [],
   "source": [
    "trainset_c3 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c3_pd = pd.DataFrame(trainset_c3)\n",
    "trainset_c3_pd = pd.DataFrame(np.array(trainset_c3_pd))\n",
    "trainset_c3_pd = trainset_c3_pd.append(chunk_a23) #8750\n",
    "trainset_c3_pd = pd.DataFrame(np.array(trainset_c3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Ousy4UsxplzT"
   },
   "outputs": [],
   "source": [
    "trainset_c4 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c4_pd = pd.DataFrame(trainset_c4)\n",
    "trainset_c4_pd = pd.DataFrame(np.array(trainset_c4_pd))\n",
    "trainset_c4_pd = trainset_c4_pd.append(chunk_a24) #8750\n",
    "trainset_c4_pd = pd.DataFrame(np.array(trainset_c4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "_H1GraC-psZz"
   },
   "outputs": [],
   "source": [
    "trainset_c5 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c5_pd = pd.DataFrame(trainset_c5)\n",
    "trainset_c5_pd = pd.DataFrame(np.array(trainset_c5_pd))\n",
    "trainset_c5_pd = trainset_c5_pd.append(chunk_a25) #8750\n",
    "trainset_c5_pd = pd.DataFrame(np.array(trainset_c5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7CebMSWG012v"
   },
   "outputs": [],
   "source": [
    "trainset_c6 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c6_pd = pd.DataFrame(trainset_c6)\n",
    "trainset_c6_pd = pd.DataFrame(np.array(trainset_c6_pd))\n",
    "trainset_c6_pd = trainset_c6_pd.append(chunk_a26) #8750\n",
    "trainset_c6_pd = pd.DataFrame(np.array(trainset_c6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "t5tUfthI08dV"
   },
   "outputs": [],
   "source": [
    "trainset_c7 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c7_pd = pd.DataFrame(trainset_c7)\n",
    "trainset_c7_pd = pd.DataFrame(np.array(trainset_c7_pd))\n",
    "trainset_c7_pd = trainset_c7_pd.append(chunk_a27) #8750\n",
    "trainset_c7_pd = pd.DataFrame(np.array(trainset_c7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "w3UbuwPd1Dmd"
   },
   "outputs": [],
   "source": [
    "trainset_c8 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c8_pd = pd.DataFrame(trainset_c8)\n",
    "trainset_c8_pd = pd.DataFrame(np.array(trainset_c8_pd))\n",
    "trainset_c8_pd = trainset_c8_pd.append(chunk_a28) #8750\n",
    "trainset_c8_pd = pd.DataFrame(np.array(trainset_c8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "nBQKSxfQ1POk"
   },
   "outputs": [],
   "source": [
    "trainset_c9 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c9_pd = pd.DataFrame(trainset_c9)\n",
    "trainset_c9_pd = pd.DataFrame(np.array(trainset_c9_pd))\n",
    "trainset_c9_pd = trainset_c9_pd.append(chunk_a29) #8750\n",
    "trainset_c9_pd = pd.DataFrame(np.array(trainset_c9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "HBdwtpOa1V1P"
   },
   "outputs": [],
   "source": [
    "trainset_c10 = train_with_target[15201: 21601] #8750 data\n",
    "trainset_c10_pd = pd.DataFrame(trainset_c10)\n",
    "trainset_c10_pd = pd.DataFrame(np.array(trainset_c10_pd))\n",
    "trainset_c10_pd = trainset_c10_pd.append(chunk_a210) #8750\n",
    "trainset_c10_pd = pd.DataFrame(np.array(trainset_c10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "SXWmydStXhlE"
   },
   "outputs": [],
   "source": [
    "#Trainset d: 30% common from A\n",
    "\n",
    "#D: Data\n",
    "trainset_d1 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d1_pd = pd.DataFrame(trainset_d1)\n",
    "trainset_d1_pd = pd.DataFrame(np.array(trainset_d1_pd))\n",
    "trainset_d1_pd = trainset_d1_pd.append(chunk_a31)\n",
    "trainset_d1_pd = pd.DataFrame(np.array(trainset_d1_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "u4xJGyur1pWc"
   },
   "outputs": [],
   "source": [
    "trainset_d2 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d2_pd = pd.DataFrame(trainset_d2)\n",
    "trainset_d2_pd = pd.DataFrame(np.array(trainset_d2_pd))\n",
    "trainset_d2_pd = trainset_d2_pd.append(chunk_a32)\n",
    "trainset_d2_pd = pd.DataFrame(np.array(trainset_d2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "bQsaGKGW1w4k"
   },
   "outputs": [],
   "source": [
    "trainset_d3 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d3_pd = pd.DataFrame(trainset_d3)\n",
    "trainset_d3_pd = pd.DataFrame(np.array(trainset_d3_pd))\n",
    "trainset_d3_pd = trainset_d3_pd.append(chunk_a33)\n",
    "trainset_d3_pd = pd.DataFrame(np.array(trainset_d3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "lSbIsmgO2ImR"
   },
   "outputs": [],
   "source": [
    "trainset_d4 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d4_pd = pd.DataFrame(trainset_d4)\n",
    "trainset_d4_pd = pd.DataFrame(np.array(trainset_d4_pd))\n",
    "trainset_d4_pd = trainset_d4_pd.append(chunk_a34)\n",
    "trainset_d4_pd = pd.DataFrame(np.array(trainset_d4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "jr9cwLeC2QJD"
   },
   "outputs": [],
   "source": [
    "trainset_d5 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d5_pd = pd.DataFrame(trainset_d5)\n",
    "trainset_d5_pd = pd.DataFrame(np.array(trainset_d5_pd))\n",
    "trainset_d5_pd = trainset_d5_pd.append(chunk_a35)\n",
    "trainset_d5_pd = pd.DataFrame(np.array(trainset_d5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "EQqKuBpk2e5F"
   },
   "outputs": [],
   "source": [
    "trainset_d6 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d6_pd = pd.DataFrame(trainset_d6)\n",
    "trainset_d6_pd = pd.DataFrame(np.array(trainset_d6_pd))\n",
    "trainset_d6_pd = trainset_d6_pd.append(chunk_a36)\n",
    "trainset_d6_pd = pd.DataFrame(np.array(trainset_d6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ZM_92kU-2lqa"
   },
   "outputs": [],
   "source": [
    "trainset_d7 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d7_pd = pd.DataFrame(trainset_d7)\n",
    "trainset_d7_pd = pd.DataFrame(np.array(trainset_d7_pd))\n",
    "trainset_d7_pd = trainset_d7_pd.append(chunk_a37)\n",
    "trainset_d7_pd = pd.DataFrame(np.array(trainset_d7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "M_vPK3-M5Fno"
   },
   "outputs": [],
   "source": [
    "trainset_d8 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d8_pd = pd.DataFrame(trainset_d8)\n",
    "trainset_d8_pd = pd.DataFrame(np.array(trainset_d8_pd))\n",
    "trainset_d8_pd = trainset_d8_pd.append(chunk_a38)\n",
    "trainset_d8_pd = pd.DataFrame(np.array(trainset_d8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "F_4RDx5t5Opo"
   },
   "outputs": [],
   "source": [
    "trainset_d9 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d9_pd = pd.DataFrame(trainset_d9)\n",
    "trainset_d9_pd = pd.DataFrame(np.array(trainset_d9_pd))\n",
    "trainset_d9_pd = trainset_d9_pd.append(chunk_a39)\n",
    "trainset_d9_pd = pd.DataFrame(np.array(trainset_d9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "tHpXK0FT5YXo"
   },
   "outputs": [],
   "source": [
    "trainset_d10 = train_with_target[21601: 27201] #4375 data\n",
    "trainset_d10_pd = pd.DataFrame(trainset_d10)\n",
    "trainset_d10_pd = pd.DataFrame(np.array(trainset_d10_pd))\n",
    "trainset_d10_pd = trainset_d10_pd.append(chunk_a310)\n",
    "trainset_d10_pd = pd.DataFrame(np.array(trainset_d10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "UmjV84cNiddc"
   },
   "outputs": [],
   "source": [
    "#Trainset e: 40% common from A\n",
    "\n",
    "#E: Data\n",
    "trainset_e1 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e1_pd = pd.DataFrame(trainset_e1)\n",
    "trainset_e1_pd = pd.DataFrame(np.array(trainset_e1_pd))\n",
    "trainset_e1_pd = trainset_e1_pd.append(chunk_a41)\n",
    "trainset_e1_pd = pd.DataFrame(np.array(trainset_e1_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "wV7-jfJxkk0I"
   },
   "outputs": [],
   "source": [
    "trainset_e2 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e2_pd = pd.DataFrame(trainset_e2)\n",
    "trainset_e2_pd = pd.DataFrame(np.array(trainset_e2_pd))\n",
    "trainset_e2_pd = trainset_e2_pd.append(chunk_a42)\n",
    "trainset_e2_pd = pd.DataFrame(np.array(trainset_e2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "s9o7yCZWkrXK"
   },
   "outputs": [],
   "source": [
    "trainset_e3 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e3_pd = pd.DataFrame(trainset_e3)\n",
    "trainset_e3_pd = pd.DataFrame(np.array(trainset_e3_pd))\n",
    "trainset_e3_pd = trainset_e3_pd.append(chunk_a43)\n",
    "trainset_e3_pd = pd.DataFrame(np.array(trainset_e3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "pyFfYQTxkwWI"
   },
   "outputs": [],
   "source": [
    "trainset_e4 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e4_pd = pd.DataFrame(trainset_e4)\n",
    "trainset_e4_pd = pd.DataFrame(np.array(trainset_e4_pd))\n",
    "trainset_e4_pd = trainset_e4_pd.append(chunk_a44)\n",
    "trainset_e4_pd = pd.DataFrame(np.array(trainset_e4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "D8UhtwILlDro"
   },
   "outputs": [],
   "source": [
    "trainset_e5 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e5_pd = pd.DataFrame(trainset_e5)\n",
    "trainset_e5_pd = pd.DataFrame(np.array(trainset_e5_pd))\n",
    "trainset_e5_pd = trainset_e5_pd.append(chunk_a45)\n",
    "trainset_e5_pd = pd.DataFrame(np.array(trainset_e5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "NloTCSjPrXLP"
   },
   "outputs": [],
   "source": [
    "trainset_e6 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e6_pd = pd.DataFrame(trainset_e6)\n",
    "trainset_e6_pd = pd.DataFrame(np.array(trainset_e6_pd))\n",
    "trainset_e6_pd = trainset_e6_pd.append(chunk_a46)\n",
    "trainset_e6_pd = pd.DataFrame(np.array(trainset_e6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "hk0y98d9rki7"
   },
   "outputs": [],
   "source": [
    "trainset_e7 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e7_pd = pd.DataFrame(trainset_e7)\n",
    "trainset_e7_pd = pd.DataFrame(np.array(trainset_e7_pd))\n",
    "trainset_e7_pd = trainset_e7_pd.append(chunk_a47)\n",
    "trainset_e7_pd = pd.DataFrame(np.array(trainset_e7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "Jnwbn-LHrtME"
   },
   "outputs": [],
   "source": [
    "trainset_e8 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e8_pd = pd.DataFrame(trainset_e8)\n",
    "trainset_e8_pd = pd.DataFrame(np.array(trainset_e8_pd))\n",
    "trainset_e8_pd = trainset_e8_pd.append(chunk_a48)\n",
    "trainset_e8_pd = pd.DataFrame(np.array(trainset_e8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "490dL7QDr0O3"
   },
   "outputs": [],
   "source": [
    "trainset_e9 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e9_pd = pd.DataFrame(trainset_e9)\n",
    "trainset_e9_pd = pd.DataFrame(np.array(trainset_e9_pd))\n",
    "trainset_e9_pd = trainset_e9_pd.append(chunk_a49)\n",
    "trainset_e9_pd = pd.DataFrame(np.array(trainset_e9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "XbUjQQd3syCH"
   },
   "outputs": [],
   "source": [
    "trainset_e10 = train_with_target[27201: 32001] #4375 data\n",
    "trainset_e10_pd = pd.DataFrame(trainset_e10)\n",
    "trainset_e10_pd = pd.DataFrame(np.array(trainset_e10_pd))\n",
    "trainset_e10_pd = trainset_e10_pd.append(chunk_a410)\n",
    "trainset_e10_pd = pd.DataFrame(np.array(trainset_e10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "sxNO86FgtkJE"
   },
   "outputs": [],
   "source": [
    "#Trainset f: 50% common from A\n",
    "\n",
    "#F: Data\n",
    "trainset_f1 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f1_pd = pd.DataFrame(trainset_f1)\n",
    "trainset_f1_pd = pd.DataFrame(np.array(trainset_f1_pd))\n",
    "trainset_f1_pd = trainset_f1_pd.append(chunk_a51)\n",
    "trainset_f1_pd = pd.DataFrame(np.array(trainset_f1_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "E5Q-Ryd2t8xH"
   },
   "outputs": [],
   "source": [
    "trainset_f2 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f2_pd = pd.DataFrame(trainset_f2)\n",
    "trainset_f2_pd = pd.DataFrame(np.array(trainset_f2_pd))\n",
    "trainset_f2_pd = trainset_f2_pd.append(chunk_a52)\n",
    "trainset_f2_pd = pd.DataFrame(np.array(trainset_f2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "LCFzpRYHxnIC"
   },
   "outputs": [],
   "source": [
    "trainset_f3 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f3_pd = pd.DataFrame(trainset_f3)\n",
    "trainset_f3_pd = pd.DataFrame(np.array(trainset_f3_pd))\n",
    "trainset_f3_pd = trainset_f3_pd.append(chunk_a53)\n",
    "trainset_f3_pd = pd.DataFrame(np.array(trainset_f3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "bmlT4TwfyNVW"
   },
   "outputs": [],
   "source": [
    "trainset_f4 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f4_pd = pd.DataFrame(trainset_f4)\n",
    "trainset_f4_pd = pd.DataFrame(np.array(trainset_f4_pd))\n",
    "trainset_f4_pd = trainset_f4_pd.append(chunk_a54)\n",
    "trainset_f4_pd = pd.DataFrame(np.array(trainset_f4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Wlb0S5uPzGCb"
   },
   "outputs": [],
   "source": [
    "trainset_f5 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f5_pd = pd.DataFrame(trainset_f5)\n",
    "trainset_f5_pd = pd.DataFrame(np.array(trainset_f5_pd))\n",
    "trainset_f5_pd = trainset_f5_pd.append(chunk_a55)\n",
    "trainset_f5_pd = pd.DataFrame(np.array(trainset_f5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Iqdmh0U0zL1D"
   },
   "outputs": [],
   "source": [
    "trainset_f6 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f6_pd = pd.DataFrame(trainset_f6)\n",
    "trainset_f6_pd = pd.DataFrame(np.array(trainset_f6_pd))\n",
    "trainset_f6_pd = trainset_f6_pd.append(chunk_a56)\n",
    "trainset_f6_pd = pd.DataFrame(np.array(trainset_f6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "apqDZoKQzSYP"
   },
   "outputs": [],
   "source": [
    "trainset_f7 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f7_pd = pd.DataFrame(trainset_f7)\n",
    "trainset_f7_pd = pd.DataFrame(np.array(trainset_f7_pd))\n",
    "trainset_f7_pd = trainset_f7_pd.append(chunk_a57)\n",
    "trainset_f7_pd = pd.DataFrame(np.array(trainset_f7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "hZIBHr43za47"
   },
   "outputs": [],
   "source": [
    "trainset_f8 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f8_pd = pd.DataFrame(trainset_f8)\n",
    "trainset_f8_pd = pd.DataFrame(np.array(trainset_f8_pd))\n",
    "trainset_f8_pd = trainset_f8_pd.append(chunk_a58)\n",
    "trainset_f8_pd = pd.DataFrame(np.array(trainset_f8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "mFqQ8RBTzh_i"
   },
   "outputs": [],
   "source": [
    "trainset_f9 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f9_pd = pd.DataFrame(trainset_f9)\n",
    "trainset_f9_pd = pd.DataFrame(np.array(trainset_f9_pd))\n",
    "trainset_f9_pd = trainset_f9_pd.append(chunk_a59)\n",
    "trainset_f9_pd = pd.DataFrame(np.array(trainset_f9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "fAwVist4zoot"
   },
   "outputs": [],
   "source": [
    "trainset_f10 = train_with_target[32001: 36001] #4375 data\n",
    "trainset_f10_pd = pd.DataFrame(trainset_f10)\n",
    "trainset_f10_pd = pd.DataFrame(np.array(trainset_f10_pd))\n",
    "trainset_f10_pd = trainset_f10_pd.append(chunk_a510)\n",
    "trainset_f10_pd = pd.DataFrame(np.array(trainset_f10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "kIoyGLHt1hGq"
   },
   "outputs": [],
   "source": [
    "#Trainset g: 60% common from A\n",
    "\n",
    "#G: Data\n",
    "trainset_g1 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g1_pd = pd.DataFrame(trainset_g1)\n",
    "trainset_g1_pd = pd.DataFrame(np.array(trainset_g1_pd))\n",
    "trainset_g1_pd = trainset_g1_pd.append(chunk_a61)\n",
    "trainset_g1_pd = pd.DataFrame(np.array(trainset_g1_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "1YajN1hn2B-_"
   },
   "outputs": [],
   "source": [
    "trainset_g2 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g2_pd = pd.DataFrame(trainset_g2)\n",
    "trainset_g2_pd = pd.DataFrame(np.array(trainset_g2_pd))\n",
    "trainset_g2_pd = trainset_g2_pd.append(chunk_a62)\n",
    "trainset_g2_pd = pd.DataFrame(np.array(trainset_g2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Dn2XjTkX2NMR"
   },
   "outputs": [],
   "source": [
    "trainset_g3 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g3_pd = pd.DataFrame(trainset_g3)\n",
    "trainset_g3_pd = pd.DataFrame(np.array(trainset_g3_pd))\n",
    "trainset_g3_pd = trainset_g3_pd.append(chunk_a63)\n",
    "trainset_g3_pd = pd.DataFrame(np.array(trainset_g3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "oaEEVSaC29cc"
   },
   "outputs": [],
   "source": [
    "trainset_g4 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g4_pd = pd.DataFrame(trainset_g4)\n",
    "trainset_g4_pd = pd.DataFrame(np.array(trainset_g4_pd))\n",
    "trainset_g4_pd = trainset_g4_pd.append(chunk_a64)\n",
    "trainset_g4_pd = pd.DataFrame(np.array(trainset_g4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "mNJS9C8i3FHy"
   },
   "outputs": [],
   "source": [
    "trainset_g5 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g5_pd = pd.DataFrame(trainset_g5)\n",
    "trainset_g5_pd = pd.DataFrame(np.array(trainset_g5_pd))\n",
    "trainset_g5_pd = trainset_g5_pd.append(chunk_a65)\n",
    "trainset_g5_pd = pd.DataFrame(np.array(trainset_g5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "CzYF-4d16src"
   },
   "outputs": [],
   "source": [
    "trainset_g6 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g6_pd = pd.DataFrame(trainset_g6)\n",
    "trainset_g6_pd = pd.DataFrame(np.array(trainset_g6_pd))\n",
    "trainset_g6_pd = trainset_g6_pd.append(chunk_a66)\n",
    "trainset_g6_pd = pd.DataFrame(np.array(trainset_g6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "7gyX5NeB_JcZ"
   },
   "outputs": [],
   "source": [
    "trainset_g7 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g7_pd = pd.DataFrame(trainset_g7)\n",
    "trainset_g7_pd = pd.DataFrame(np.array(trainset_g7_pd))\n",
    "trainset_g7_pd = trainset_g7_pd.append(chunk_a67)\n",
    "trainset_g7_pd = pd.DataFrame(np.array(trainset_g7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "5bsgYD4n_qMt"
   },
   "outputs": [],
   "source": [
    "trainset_g8 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g8_pd = pd.DataFrame(trainset_g8)\n",
    "trainset_g8_pd = pd.DataFrame(np.array(trainset_g8_pd))\n",
    "trainset_g8_pd = trainset_g8_pd.append(chunk_a68)\n",
    "trainset_g8_pd = pd.DataFrame(np.array(trainset_g8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "urJjT02X_-c2"
   },
   "outputs": [],
   "source": [
    "trainset_g9 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g9_pd = pd.DataFrame(trainset_g9)\n",
    "trainset_g9_pd = pd.DataFrame(np.array(trainset_g9_pd))\n",
    "trainset_g9_pd = trainset_g9_pd.append(chunk_a69)\n",
    "trainset_g9_pd = pd.DataFrame(np.array(trainset_g9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "eeu_A0zRAX8v"
   },
   "outputs": [],
   "source": [
    "trainset_g10 = train_with_target[36001: 39201] #4375 data\n",
    "trainset_g10_pd = pd.DataFrame(trainset_g10)\n",
    "trainset_g10_pd = pd.DataFrame(np.array(trainset_g10_pd))\n",
    "trainset_g10_pd = trainset_g10_pd.append(chunk_a610)\n",
    "trainset_g10_pd = pd.DataFrame(np.array(trainset_g10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "mua_6yIgBCIC"
   },
   "outputs": [],
   "source": [
    "#Trainset h: 70% common from A\n",
    "\n",
    "#H: Data\n",
    "trainset_h1 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h1_pd = pd.DataFrame(trainset_h1)\n",
    "trainset_h1_pd = pd.DataFrame(np.array(trainset_h1_pd))\n",
    "trainset_h1_pd = trainset_h1_pd.append(chunk_a71)\n",
    "trainset_h1_pd = pd.DataFrame(np.array(trainset_h1_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "qvLGWJ9ACEm5"
   },
   "outputs": [],
   "source": [
    "trainset_h2 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h2_pd = pd.DataFrame(trainset_h2)\n",
    "trainset_h2_pd = pd.DataFrame(np.array(trainset_h2_pd))\n",
    "trainset_h2_pd = trainset_h2_pd.append(chunk_a72)\n",
    "trainset_h2_pd = pd.DataFrame(np.array(trainset_h2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "b0x_Fd2iCMdB"
   },
   "outputs": [],
   "source": [
    "trainset_h3 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h3_pd = pd.DataFrame(trainset_h3)\n",
    "trainset_h3_pd = pd.DataFrame(np.array(trainset_h3_pd))\n",
    "trainset_h3_pd = trainset_h3_pd.append(chunk_a73)\n",
    "trainset_h3_pd = pd.DataFrame(np.array(trainset_h3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "Au5r3IZlCTsa"
   },
   "outputs": [],
   "source": [
    "trainset_h4 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h4_pd = pd.DataFrame(trainset_h4)\n",
    "trainset_h4_pd = pd.DataFrame(np.array(trainset_h4_pd))\n",
    "trainset_h4_pd = trainset_h4_pd.append(chunk_a74)\n",
    "trainset_h4_pd = pd.DataFrame(np.array(trainset_h4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "1xhe1i_SCabS"
   },
   "outputs": [],
   "source": [
    "trainset_h5 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h5_pd = pd.DataFrame(trainset_h5)\n",
    "trainset_h5_pd = pd.DataFrame(np.array(trainset_h5_pd))\n",
    "trainset_h5_pd = trainset_h5_pd.append(chunk_a75)\n",
    "trainset_h5_pd = pd.DataFrame(np.array(trainset_h5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "D0TwmsGLCp8E"
   },
   "outputs": [],
   "source": [
    "trainset_h6 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h6_pd = pd.DataFrame(trainset_h6)\n",
    "trainset_h6_pd = pd.DataFrame(np.array(trainset_h6_pd))\n",
    "trainset_h6_pd = trainset_h6_pd.append(chunk_a76)\n",
    "trainset_h6_pd = pd.DataFrame(np.array(trainset_h6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "GQx5kv5wCwqz"
   },
   "outputs": [],
   "source": [
    "trainset_h7 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h7_pd = pd.DataFrame(trainset_h7)\n",
    "trainset_h7_pd = pd.DataFrame(np.array(trainset_h7_pd))\n",
    "trainset_h7_pd = trainset_h7_pd.append(chunk_a77)\n",
    "trainset_h7_pd = pd.DataFrame(np.array(trainset_h7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "KdgGslGdC2w3"
   },
   "outputs": [],
   "source": [
    "trainset_h8 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h8_pd = pd.DataFrame(trainset_h8)\n",
    "trainset_h8_pd = pd.DataFrame(np.array(trainset_h8_pd))\n",
    "trainset_h8_pd = trainset_h8_pd.append(chunk_a78)\n",
    "trainset_h8_pd = pd.DataFrame(np.array(trainset_h8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "UlN2XJDcEHiF"
   },
   "outputs": [],
   "source": [
    "trainset_h9 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h9_pd = pd.DataFrame(trainset_h9)\n",
    "trainset_h9_pd = pd.DataFrame(np.array(trainset_h9_pd))\n",
    "trainset_h9_pd = trainset_h9_pd.append(chunk_a79)\n",
    "trainset_h9_pd = pd.DataFrame(np.array(trainset_h9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "3rcuJDCSERT6"
   },
   "outputs": [],
   "source": [
    "trainset_h10 = train_with_target[39201: 41601] #4375 data\n",
    "trainset_h10_pd = pd.DataFrame(trainset_h10)\n",
    "trainset_h10_pd = pd.DataFrame(np.array(trainset_h10_pd))\n",
    "trainset_h10_pd = trainset_h10_pd.append(chunk_a710)\n",
    "trainset_h10_pd = pd.DataFrame(np.array(trainset_h10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "0mFQZA-6EfDP"
   },
   "outputs": [],
   "source": [
    "#Trainset i: 80% common from A\n",
    "\n",
    "#I: Data\n",
    "trainset_i1 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i1_pd = pd.DataFrame(trainset_i1)\n",
    "trainset_i1_pd = pd.DataFrame(np.array(trainset_i1_pd))\n",
    "trainset_i1_pd = trainset_i1_pd.append(chunk_a81)\n",
    "trainset_i1_pd = pd.DataFrame(np.array(trainset_i1_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "oiv9CzjLE4Cf"
   },
   "outputs": [],
   "source": [
    "trainset_i2 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i2_pd = pd.DataFrame(trainset_i2)\n",
    "trainset_i2_pd = pd.DataFrame(np.array(trainset_i2_pd))\n",
    "trainset_i2_pd = trainset_i2_pd.append(chunk_a82)\n",
    "trainset_i2_pd = pd.DataFrame(np.array(trainset_i2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "61CHtoWCE-L8"
   },
   "outputs": [],
   "source": [
    "trainset_i3 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i3_pd = pd.DataFrame(trainset_i3)\n",
    "trainset_i3_pd = pd.DataFrame(np.array(trainset_i3_pd))\n",
    "trainset_i3_pd = trainset_i3_pd.append(chunk_a83)\n",
    "trainset_i3_pd = pd.DataFrame(np.array(trainset_i3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "UJnbsnbpFEQU"
   },
   "outputs": [],
   "source": [
    "trainset_i4 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i4_pd = pd.DataFrame(trainset_i4)\n",
    "trainset_i4_pd = pd.DataFrame(np.array(trainset_i4_pd))\n",
    "trainset_i4_pd = trainset_i4_pd.append(chunk_a84)\n",
    "trainset_i4_pd = pd.DataFrame(np.array(trainset_i4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "SgrMNNmpFKsw"
   },
   "outputs": [],
   "source": [
    "trainset_i5 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i5_pd = pd.DataFrame(trainset_i5)\n",
    "trainset_i5_pd = pd.DataFrame(np.array(trainset_i5_pd))\n",
    "trainset_i5_pd = trainset_i5_pd.append(chunk_a85)\n",
    "trainset_i5_pd = pd.DataFrame(np.array(trainset_i5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "CYVKvKUFFQMJ"
   },
   "outputs": [],
   "source": [
    "trainset_i6 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i6_pd = pd.DataFrame(trainset_i6)\n",
    "trainset_i6_pd = pd.DataFrame(np.array(trainset_i6_pd))\n",
    "trainset_i6_pd = trainset_i6_pd.append(chunk_a86)\n",
    "trainset_i6_pd = pd.DataFrame(np.array(trainset_i6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "QYIwvE0NFWMs"
   },
   "outputs": [],
   "source": [
    "trainset_i7 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i7_pd = pd.DataFrame(trainset_i7)\n",
    "trainset_i7_pd = pd.DataFrame(np.array(trainset_i7_pd))\n",
    "trainset_i7_pd = trainset_i7_pd.append(chunk_a87)\n",
    "trainset_i7_pd = pd.DataFrame(np.array(trainset_i7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "fbhZ2YyiFbzk"
   },
   "outputs": [],
   "source": [
    "trainset_i8 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i8_pd = pd.DataFrame(trainset_i8)\n",
    "trainset_i8_pd = pd.DataFrame(np.array(trainset_i8_pd))\n",
    "trainset_i8_pd = trainset_i8_pd.append(chunk_a88)\n",
    "trainset_i8_pd = pd.DataFrame(np.array(trainset_i8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "Kh5u6E6fFhi4"
   },
   "outputs": [],
   "source": [
    "trainset_i9 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i9_pd = pd.DataFrame(trainset_i9)\n",
    "trainset_i9_pd = pd.DataFrame(np.array(trainset_i9_pd))\n",
    "trainset_i9_pd = trainset_i9_pd.append(chunk_a89)\n",
    "trainset_i9_pd = pd.DataFrame(np.array(trainset_i9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "uyDM7xosFum9"
   },
   "outputs": [],
   "source": [
    "trainset_i10 = train_with_target[41601: 43201] #4375 data\n",
    "trainset_i10_pd = pd.DataFrame(trainset_i10)\n",
    "trainset_i10_pd = pd.DataFrame(np.array(trainset_i10_pd))\n",
    "trainset_i10_pd = trainset_i10_pd.append(chunk_a810)\n",
    "trainset_i10_pd = pd.DataFrame(np.array(trainset_i10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "CnCdqAOoF5SZ"
   },
   "outputs": [],
   "source": [
    "#Trainset j: 90% common from A\n",
    "\n",
    "#J: Data\n",
    "trainset_j1 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j1_pd = pd.DataFrame(trainset_j1)\n",
    "trainset_j1_pd = pd.DataFrame(np.array(trainset_j1_pd))\n",
    "trainset_j1_pd = trainset_j1_pd.append(chunk_a91)\n",
    "trainset_j1_pd = pd.DataFrame(np.array(trainset_j1_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "cvm8bz2zIRR-"
   },
   "outputs": [],
   "source": [
    "trainset_j2 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j2_pd = pd.DataFrame(trainset_j2)\n",
    "trainset_j2_pd = pd.DataFrame(np.array(trainset_j2_pd))\n",
    "trainset_j2_pd = trainset_j2_pd.append(chunk_a92)\n",
    "trainset_j2_pd = pd.DataFrame(np.array(trainset_j2_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "T_7rGRxYJeO-"
   },
   "outputs": [],
   "source": [
    "trainset_j3 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j3_pd = pd.DataFrame(trainset_j3)\n",
    "trainset_j3_pd = pd.DataFrame(np.array(trainset_j3_pd))\n",
    "trainset_j3_pd = trainset_j3_pd.append(chunk_a93)\n",
    "trainset_j3_pd = pd.DataFrame(np.array(trainset_j3_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "ki8GSo_oJq0-"
   },
   "outputs": [],
   "source": [
    "trainset_j4 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j4_pd = pd.DataFrame(trainset_j4)\n",
    "trainset_j4_pd = pd.DataFrame(np.array(trainset_j4_pd))\n",
    "trainset_j4_pd = trainset_j4_pd.append(chunk_a94)\n",
    "trainset_j4_pd = pd.DataFrame(np.array(trainset_j4_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "q4L3LT26Jwdh"
   },
   "outputs": [],
   "source": [
    "trainset_j5 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j5_pd = pd.DataFrame(trainset_j5)\n",
    "trainset_j5_pd = pd.DataFrame(np.array(trainset_j5_pd))\n",
    "trainset_j5_pd = trainset_j5_pd.append(chunk_a95)\n",
    "trainset_j5_pd = pd.DataFrame(np.array(trainset_j5_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "ACtZ9ssiJ7-r"
   },
   "outputs": [],
   "source": [
    "trainset_j6 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j6_pd = pd.DataFrame(trainset_j6)\n",
    "trainset_j6_pd = pd.DataFrame(np.array(trainset_j6_pd))\n",
    "trainset_j6_pd = trainset_j6_pd.append(chunk_a96)\n",
    "trainset_j6_pd = pd.DataFrame(np.array(trainset_j6_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "K250Sf6CKCtV"
   },
   "outputs": [],
   "source": [
    "trainset_j7 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j7_pd = pd.DataFrame(trainset_j7)\n",
    "trainset_j7_pd = pd.DataFrame(np.array(trainset_j7_pd))\n",
    "trainset_j7_pd = trainset_j7_pd.append(chunk_a97)\n",
    "trainset_j7_pd = pd.DataFrame(np.array(trainset_j7_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "reZekSuhKJpl"
   },
   "outputs": [],
   "source": [
    "trainset_j8 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j8_pd = pd.DataFrame(trainset_j8)\n",
    "trainset_j8_pd = pd.DataFrame(np.array(trainset_j8_pd))\n",
    "trainset_j8_pd = trainset_j8_pd.append(chunk_a98)\n",
    "trainset_j8_pd = pd.DataFrame(np.array(trainset_j8_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "Sy4Dab-EKRLP"
   },
   "outputs": [],
   "source": [
    "trainset_j9 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j9_pd = pd.DataFrame(trainset_j9)\n",
    "trainset_j9_pd = pd.DataFrame(np.array(trainset_j9_pd))\n",
    "trainset_j9_pd = trainset_j9_pd.append(chunk_a99)\n",
    "trainset_j9_pd = pd.DataFrame(np.array(trainset_j9_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "COnC9Qp8KYx7"
   },
   "outputs": [],
   "source": [
    "trainset_j10 = train_with_target[43201:44001] #4375 data\n",
    "trainset_j10_pd = pd.DataFrame(trainset_j10)\n",
    "trainset_j10_pd = pd.DataFrame(np.array(trainset_j10_pd))\n",
    "trainset_j10_pd = trainset_j10_pd.append(chunk_a910)\n",
    "trainset_j10_pd = pd.DataFrame(np.array(trainset_j10_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "y3TUq6OqSesp"
   },
   "outputs": [],
   "source": [
    "#Trainset K: 100% common from A\n",
    "\n",
    "#K: Data\n",
    "trainset_k = train_with_target[0: 8000]\n",
    "trainset_k_pd = pd.DataFrame(trainset_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "aowSU04fX7jb"
   },
   "outputs": [],
   "source": [
    "#Batch size\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "M3DWRN3iUesX"
   },
   "outputs": [],
   "source": [
    "#Trainset A Data and Target to Tensor\n",
    "init_train_a = trainset_a_pd.iloc[:, : 784].values\n",
    "train_a = torch.tensor(init_train_a)\n",
    "train_a_final = train_a.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_a_target = trainset_a_pd.iloc[:, -1].values\n",
    "train_a_target = torch.tensor(init_train_a_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_q_ds = TensorDataset(train_a_final, train_a_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 1: train_v_dl\n",
    "train_q_dl = torch.utils.data.DataLoader(train_q_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "sb0DK5t7Ua_C"
   },
   "outputs": [],
   "source": [
    "#Trainset B Data and Target to Tensor\n",
    "init_train_b1 = trainset_b1_pd.iloc[:, : 784].values\n",
    "train_b1 = torch.tensor(init_train_b1)\n",
    "train_b1_final = train_b1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b1_target = trainset_b1_pd.iloc[:, -1].values\n",
    "train_b1_target = torch.tensor(init_train_b1_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r1_ds = TensorDataset(train_b1_final, train_b1_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r1_dl = torch.utils.data.DataLoader(train_r1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "4_tcDcSd9vYD"
   },
   "outputs": [],
   "source": [
    "init_train_b2 = trainset_b2_pd.iloc[:, : 784].values\n",
    "train_b2 = torch.tensor(init_train_b2)\n",
    "train_b2_final = train_b2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b2_target = trainset_b2_pd.iloc[:, -1].values\n",
    "train_b2_target = torch.tensor(init_train_b2_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r2_ds = TensorDataset(train_b2_final, train_b2_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r2_dl = torch.utils.data.DataLoader(train_r2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "k_Kglsb0-UEV"
   },
   "outputs": [],
   "source": [
    "init_train_b3 = trainset_b3_pd.iloc[:, : 784].values\n",
    "train_b3 = torch.tensor(init_train_b3)\n",
    "train_b3_final = train_b3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b3_target = trainset_b3_pd.iloc[:, -1].values\n",
    "train_b3_target = torch.tensor(init_train_b3_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r3_ds = TensorDataset(train_b3_final, train_b3_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r3_dl = torch.utils.data.DataLoader(train_r3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "lmrFaO39-fup"
   },
   "outputs": [],
   "source": [
    "init_train_b4 = trainset_b4_pd.iloc[:, : 784].values\n",
    "train_b4 = torch.tensor(init_train_b4)\n",
    "train_b4_final = train_b4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b4_target = trainset_b4_pd.iloc[:, -1].values\n",
    "train_b4_target = torch.tensor(init_train_b4_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r4_ds = TensorDataset(train_b4_final, train_b4_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r4_dl = torch.utils.data.DataLoader(train_r4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "-4J3L4x-E_vK"
   },
   "outputs": [],
   "source": [
    "init_train_b5 = trainset_b5_pd.iloc[:, : 784].values\n",
    "train_b5 = torch.tensor(init_train_b5)\n",
    "train_b5_final = train_b5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b5_target = trainset_b5_pd.iloc[:, -1].values\n",
    "train_b5_target = torch.tensor(init_train_b5_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r5_ds = TensorDataset(train_b5_final, train_b5_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r5_dl = torch.utils.data.DataLoader(train_r5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "WGBZIdZ7FPCx"
   },
   "outputs": [],
   "source": [
    "init_train_b6 = trainset_b6_pd.iloc[:, : 784].values\n",
    "train_b6 = torch.tensor(init_train_b6)\n",
    "train_b6_final = train_b6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b6_target = trainset_b6_pd.iloc[:, -1].values\n",
    "train_b6_target = torch.tensor(init_train_b6_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r6_ds = TensorDataset(train_b6_final, train_b6_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r6_dl = torch.utils.data.DataLoader(train_r6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "mpulFtBWFdRc"
   },
   "outputs": [],
   "source": [
    "init_train_b7 = trainset_b7_pd.iloc[:, : 784].values\n",
    "train_b7 = torch.tensor(init_train_b7)\n",
    "train_b7_final = train_b7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b7_target = trainset_b7_pd.iloc[:, -1].values\n",
    "train_b7_target = torch.tensor(init_train_b7_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r7_ds = TensorDataset(train_b7_final, train_b7_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r7_dl = torch.utils.data.DataLoader(train_r7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "Rk1D2J24Frwx"
   },
   "outputs": [],
   "source": [
    "init_train_b8 = trainset_b8_pd.iloc[:, : 784].values\n",
    "train_b8 = torch.tensor(init_train_b8)\n",
    "train_b8_final = train_b8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b8_target = trainset_b8_pd.iloc[:, -1].values\n",
    "train_b8_target = torch.tensor(init_train_b8_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r8_ds = TensorDataset(train_b8_final, train_b8_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r8_dl = torch.utils.data.DataLoader(train_r8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "hfKpetkIHSzq"
   },
   "outputs": [],
   "source": [
    "init_train_b9 = trainset_b9_pd.iloc[:, : 784].values\n",
    "train_b9 = torch.tensor(init_train_b9)\n",
    "train_b9_final = train_b9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b9_target = trainset_b9_pd.iloc[:, -1].values\n",
    "train_b9_target = torch.tensor(init_train_b9_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r9_ds = TensorDataset(train_b9_final, train_b9_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r9_dl = torch.utils.data.DataLoader(train_r9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "-BcbP8MuHhp5"
   },
   "outputs": [],
   "source": [
    "init_train_b10 = trainset_b10_pd.iloc[:, : 784].values\n",
    "train_b10 = torch.tensor(init_train_b10)\n",
    "train_b10_final = train_b10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_b10_target = trainset_b10_pd.iloc[:, -1].values\n",
    "train_b10_target = torch.tensor(init_train_b10_target)\n",
    "\n",
    "\n",
    "#Trainset A Data and Target Tensor to Dataset then Dataloader\n",
    "train_r10_ds = TensorDataset(train_b10_final, train_b10_target)\n",
    "#Tensor Dataset train v to Dataloader\n",
    "# Trainset 2: train_w_dl\n",
    "train_r10_dl = torch.utils.data.DataLoader(train_r10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "X7RhsbfvUJPx"
   },
   "outputs": [],
   "source": [
    "#Trainset C Data and Target to Tensor\n",
    "init_train_c1 = trainset_c1_pd.iloc[:, : 784].values\n",
    "train_c1 = torch.tensor(init_train_c1)\n",
    "train_c1_final = train_c1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c1_target = trainset_c1_pd.iloc[:, -1].values\n",
    "train_c1_target = torch.tensor(init_train_c1_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s1_ds = TensorDataset(train_c1_final, train_c1_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s1_dl = torch.utils.data.DataLoader(train_s1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "JZaSDid7IsHs"
   },
   "outputs": [],
   "source": [
    "init_train_c2 = trainset_c2_pd.iloc[:, : 784].values\n",
    "train_c2 = torch.tensor(init_train_c2)\n",
    "train_c2_final = train_c2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c2_target = trainset_c2_pd.iloc[:, -1].values\n",
    "train_c2_target = torch.tensor(init_train_c2_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s2_ds = TensorDataset(train_c2_final, train_c2_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s2_dl = torch.utils.data.DataLoader(train_s2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "AlQ8c90HI8a9"
   },
   "outputs": [],
   "source": [
    "init_train_c3 = trainset_c3_pd.iloc[:, : 784].values\n",
    "train_c3 = torch.tensor(init_train_c3)\n",
    "train_c3_final = train_c3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c3_target = trainset_c3_pd.iloc[:, -1].values\n",
    "train_c3_target = torch.tensor(init_train_c3_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s3_ds = TensorDataset(train_c3_final, train_c3_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s3_dl = torch.utils.data.DataLoader(train_s3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "W8JAVN2kJXg9"
   },
   "outputs": [],
   "source": [
    "init_train_c4 = trainset_c4_pd.iloc[:, : 784].values\n",
    "train_c4 = torch.tensor(init_train_c4)\n",
    "train_c4_final = train_c4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c4_target = trainset_c4_pd.iloc[:, -1].values\n",
    "train_c4_target = torch.tensor(init_train_c4_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s4_ds = TensorDataset(train_c4_final, train_c4_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s4_dl = torch.utils.data.DataLoader(train_s4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "ZQOSqYQUJqIc"
   },
   "outputs": [],
   "source": [
    "init_train_c5 = trainset_c5_pd.iloc[:, : 784].values\n",
    "train_c5 = torch.tensor(init_train_c5)\n",
    "train_c5_final = train_c5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c5_target = trainset_c5_pd.iloc[:, -1].values\n",
    "train_c5_target = torch.tensor(init_train_c5_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s5_ds = TensorDataset(train_c5_final, train_c5_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s5_dl = torch.utils.data.DataLoader(train_s5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "VSyGTzutJ9l7"
   },
   "outputs": [],
   "source": [
    "init_train_c6 = trainset_c6_pd.iloc[:, : 784].values\n",
    "train_c6 = torch.tensor(init_train_c6)\n",
    "train_c6_final = train_c6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c6_target = trainset_c6_pd.iloc[:, -1].values\n",
    "train_c6_target = torch.tensor(init_train_c6_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s6_ds = TensorDataset(train_c6_final, train_c6_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s6_dl = torch.utils.data.DataLoader(train_s6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "KY71FpsRKTtU"
   },
   "outputs": [],
   "source": [
    "init_train_c7 = trainset_c7_pd.iloc[:, : 784].values\n",
    "train_c7 = torch.tensor(init_train_c7)\n",
    "train_c7_final = train_c7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c7_target = trainset_c7_pd.iloc[:, -1].values\n",
    "train_c7_target = torch.tensor(init_train_c7_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s7_ds = TensorDataset(train_c7_final, train_c7_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s7_dl = torch.utils.data.DataLoader(train_s7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "VQePVE5ZKkG2"
   },
   "outputs": [],
   "source": [
    "init_train_c8 = trainset_c8_pd.iloc[:, : 784].values\n",
    "train_c8 = torch.tensor(init_train_c8)\n",
    "train_c8_final = train_c8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c8_target = trainset_c8_pd.iloc[:, -1].values\n",
    "train_c8_target = torch.tensor(init_train_c8_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s8_ds = TensorDataset(train_c8_final, train_c8_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s8_dl = torch.utils.data.DataLoader(train_s8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "CzR6D3_xLA5Z"
   },
   "outputs": [],
   "source": [
    "init_train_c9 = trainset_c9_pd.iloc[:, : 784].values\n",
    "train_c9 = torch.tensor(init_train_c9)\n",
    "train_c9_final = train_c9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c9_target = trainset_c9_pd.iloc[:, -1].values\n",
    "train_c9_target = torch.tensor(init_train_c9_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s9_ds = TensorDataset(train_c9_final, train_c9_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s9_dl = torch.utils.data.DataLoader(train_s9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "ERGf50_zLQER"
   },
   "outputs": [],
   "source": [
    "init_train_c10 = trainset_c10_pd.iloc[:, : 784].values\n",
    "train_c10 = torch.tensor(init_train_c10)\n",
    "train_c10_final = train_c10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_c10_target = trainset_c10_pd.iloc[:, -1].values\n",
    "train_c10_target = torch.tensor(init_train_c10_target)\n",
    "\n",
    "\n",
    "#Trainset C Data and Target Tensor to Dataset then Dataloader\n",
    "train_s10_ds = TensorDataset(train_c10_final, train_c10_target)\n",
    "#Tensor Dataset train x to Dataloader\n",
    "# Trainset 3: train_x_dl\n",
    "train_s10_dl = torch.utils.data.DataLoader(train_s10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "QT6a9994UGmI"
   },
   "outputs": [],
   "source": [
    "#Trainset D Data and Target to Tensor\n",
    "init_train_d1 = trainset_d1_pd.iloc[:, : 784].values\n",
    "train_d1 = torch.tensor(init_train_d1)\n",
    "train_d1_final = train_d1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d1_target = trainset_d1_pd.iloc[:, -1].values\n",
    "train_d1_target = torch.tensor(init_train_d1_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t1_ds = TensorDataset(train_d1_final, train_d1_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t1_dl = torch.utils.data.DataLoader(train_t1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "WtogDV16MBbU"
   },
   "outputs": [],
   "source": [
    "init_train_d2 = trainset_d2_pd.iloc[:, : 784].values\n",
    "train_d2 = torch.tensor(init_train_d2)\n",
    "train_d2_final = train_d2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d2_target = trainset_d2_pd.iloc[:, -1].values\n",
    "train_d2_target = torch.tensor(init_train_d2_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t2_ds = TensorDataset(train_d2_final, train_d2_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t2_dl = torch.utils.data.DataLoader(train_t2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "ryywn1ZKMODy"
   },
   "outputs": [],
   "source": [
    "init_train_d3 = trainset_d3_pd.iloc[:, : 784].values\n",
    "train_d3 = torch.tensor(init_train_d3)\n",
    "train_d3_final = train_d3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d3_target = trainset_d3_pd.iloc[:, -1].values\n",
    "train_d3_target = torch.tensor(init_train_d3_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t3_ds = TensorDataset(train_d3_final, train_d3_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t3_dl = torch.utils.data.DataLoader(train_t3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "RXFy4GlqMdoo"
   },
   "outputs": [],
   "source": [
    "init_train_d4 = trainset_d4_pd.iloc[:, : 784].values\n",
    "train_d4 = torch.tensor(init_train_d4)\n",
    "train_d4_final = train_d4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d4_target = trainset_d4_pd.iloc[:, -1].values\n",
    "train_d4_target = torch.tensor(init_train_d4_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t4_ds = TensorDataset(train_d4_final, train_d4_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t4_dl = torch.utils.data.DataLoader(train_t4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "mXZFXnHYMrsy"
   },
   "outputs": [],
   "source": [
    "init_train_d5 = trainset_d5_pd.iloc[:, : 784].values\n",
    "train_d5 = torch.tensor(init_train_d5)\n",
    "train_d5_final = train_d5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d5_target = trainset_d5_pd.iloc[:, -1].values\n",
    "train_d5_target = torch.tensor(init_train_d5_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t5_ds = TensorDataset(train_d5_final, train_d5_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t5_dl = torch.utils.data.DataLoader(train_t5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "Ccpyrl9UM8DK"
   },
   "outputs": [],
   "source": [
    "init_train_d6 = trainset_d6_pd.iloc[:, : 784].values\n",
    "train_d6 = torch.tensor(init_train_d6)\n",
    "train_d6_final = train_d6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d6_target = trainset_d6_pd.iloc[:, -1].values\n",
    "train_d6_target = torch.tensor(init_train_d6_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t6_ds = TensorDataset(train_d6_final, train_d6_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t6_dl = torch.utils.data.DataLoader(train_t6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "hAqofHhONK1u"
   },
   "outputs": [],
   "source": [
    "init_train_d7 = trainset_d7_pd.iloc[:, : 784].values\n",
    "train_d7 = torch.tensor(init_train_d7)\n",
    "train_d7_final = train_d7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d7_target = trainset_d7_pd.iloc[:, -1].values\n",
    "train_d7_target = torch.tensor(init_train_d7_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t7_ds = TensorDataset(train_d7_final, train_d7_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t7_dl = torch.utils.data.DataLoader(train_t7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "f3cKeU5GNcl3"
   },
   "outputs": [],
   "source": [
    "init_train_d8 = trainset_d8_pd.iloc[:, : 784].values\n",
    "train_d8 = torch.tensor(init_train_d8)\n",
    "train_d8_final = train_d8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d8_target = trainset_d8_pd.iloc[:, -1].values\n",
    "train_d8_target = torch.tensor(init_train_d8_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t8_ds = TensorDataset(train_d8_final, train_d8_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t8_dl = torch.utils.data.DataLoader(train_t8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "lAW2yFAVN3se"
   },
   "outputs": [],
   "source": [
    "init_train_d9 = trainset_d9_pd.iloc[:, : 784].values\n",
    "train_d9 = torch.tensor(init_train_d9)\n",
    "train_d9_final = train_d9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d9_target = trainset_d9_pd.iloc[:, -1].values\n",
    "train_d9_target = torch.tensor(init_train_d9_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t9_ds = TensorDataset(train_d9_final, train_d9_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t9_dl = torch.utils.data.DataLoader(train_t9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "r_W2A4-SOKgX"
   },
   "outputs": [],
   "source": [
    "init_train_d10 = trainset_d1_pd.iloc[:, : 784].values\n",
    "train_d10 = torch.tensor(init_train_d10)\n",
    "train_d10_final = train_d10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_d10_target = trainset_d10_pd.iloc[:, -1].values\n",
    "train_d10_target = torch.tensor(init_train_d10_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_t10_ds = TensorDataset(train_d10_final, train_d10_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_t10_dl = torch.utils.data.DataLoader(train_t10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "rRctSuXUNCdB"
   },
   "outputs": [],
   "source": [
    "init_train_e1 = trainset_e1_pd.iloc[:, : 784].values\n",
    "train_e1 = torch.tensor(init_train_e1)\n",
    "train_e1_final = train_e1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e1_target = trainset_e1_pd.iloc[:, -1].values\n",
    "train_e1_target = torch.tensor(init_train_e1_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u1_ds = TensorDataset(train_e1_final, train_e1_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u1_dl = torch.utils.data.DataLoader(train_u1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "YjwhvI1sNCU6"
   },
   "outputs": [],
   "source": [
    "init_train_e2 = trainset_e2_pd.iloc[:, : 784].values\n",
    "train_e2 = torch.tensor(init_train_e2)\n",
    "train_e2_final = train_e2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e2_target = trainset_e2_pd.iloc[:, -1].values\n",
    "train_e2_target = torch.tensor(init_train_e2_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u2_ds = TensorDataset(train_e2_final, train_e2_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u2_dl = torch.utils.data.DataLoader(train_u2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "IMIuVr4DNCMq"
   },
   "outputs": [],
   "source": [
    "init_train_e3 = trainset_e3_pd.iloc[:, : 784].values\n",
    "train_e3 = torch.tensor(init_train_e3)\n",
    "train_e3_final = train_e3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e3_target = trainset_e3_pd.iloc[:, -1].values\n",
    "train_e3_target = torch.tensor(init_train_e3_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u3_ds = TensorDataset(train_e3_final, train_e3_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u3_dl = torch.utils.data.DataLoader(train_u3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "7kguA80GNCEt"
   },
   "outputs": [],
   "source": [
    "init_train_e4 = trainset_e4_pd.iloc[:, : 784].values\n",
    "train_e4 = torch.tensor(init_train_e4)\n",
    "train_e4_final = train_e4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e4_target = trainset_e4_pd.iloc[:, -1].values\n",
    "train_e4_target = torch.tensor(init_train_e4_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u4_ds = TensorDataset(train_e4_final, train_e4_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u4_dl = torch.utils.data.DataLoader(train_u4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "EsYuDqqlNB8h"
   },
   "outputs": [],
   "source": [
    "init_train_e5 = trainset_e5_pd.iloc[:, : 784].values\n",
    "train_e5 = torch.tensor(init_train_e5)\n",
    "train_e5_final = train_e5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e5_target = trainset_e5_pd.iloc[:, -1].values\n",
    "train_e5_target = torch.tensor(init_train_e5_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u5_ds = TensorDataset(train_e5_final, train_e5_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u5_dl = torch.utils.data.DataLoader(train_u5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "PbDovNp7NB0g"
   },
   "outputs": [],
   "source": [
    "init_train_e6 = trainset_e6_pd.iloc[:, : 784].values\n",
    "train_e6 = torch.tensor(init_train_e6)\n",
    "train_e6_final = train_e6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e6_target = trainset_e6_pd.iloc[:, -1].values\n",
    "train_e6_target = torch.tensor(init_train_e6_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u6_ds = TensorDataset(train_e6_final, train_e6_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u6_dl = torch.utils.data.DataLoader(train_u6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "icLlzNx3NBsa"
   },
   "outputs": [],
   "source": [
    "init_train_e7 = trainset_e7_pd.iloc[:, : 784].values\n",
    "train_e7 = torch.tensor(init_train_e7)\n",
    "train_e7_final = train_e7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e7_target = trainset_e7_pd.iloc[:, -1].values\n",
    "train_e7_target = torch.tensor(init_train_e7_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u7_ds = TensorDataset(train_e7_final, train_e7_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u7_dl = torch.utils.data.DataLoader(train_u7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "0MXyzPypNBlW"
   },
   "outputs": [],
   "source": [
    "init_train_e8 = trainset_e8_pd.iloc[:, : 784].values\n",
    "train_e8 = torch.tensor(init_train_e8)\n",
    "train_e8_final = train_e8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e8_target = trainset_e8_pd.iloc[:, -1].values\n",
    "train_e8_target = torch.tensor(init_train_e8_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u8_ds = TensorDataset(train_e8_final, train_e8_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u8_dl = torch.utils.data.DataLoader(train_u8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "b2BOqvFMNBdQ"
   },
   "outputs": [],
   "source": [
    "init_train_e9 = trainset_e9_pd.iloc[:, : 784].values\n",
    "train_e9 = torch.tensor(init_train_e9)\n",
    "train_e9_final = train_e9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e9_target = trainset_e9_pd.iloc[:, -1].values\n",
    "train_e9_target = torch.tensor(init_train_e9_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u9_ds = TensorDataset(train_e9_final, train_e9_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u9_dl = torch.utils.data.DataLoader(train_u9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "0EUVsfJlNBVY"
   },
   "outputs": [],
   "source": [
    "init_train_e10 = trainset_e10_pd.iloc[:, : 784].values\n",
    "train_e10 = torch.tensor(init_train_e10)\n",
    "train_e10_final = train_e10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_e10_target = trainset_e10_pd.iloc[:, -1].values\n",
    "train_e10_target = torch.tensor(init_train_e10_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_u10_ds = TensorDataset(train_e10_final, train_e10_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_u10_dl = torch.utils.data.DataLoader(train_u10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "Gzwe4nhZNBNS"
   },
   "outputs": [],
   "source": [
    "init_train_f1 = trainset_f1_pd.iloc[:, : 784].values\n",
    "train_f1 = torch.tensor(init_train_f1)\n",
    "train_f1_final = train_f1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f1_target = trainset_f1_pd.iloc[:, -1].values\n",
    "train_f1_target = torch.tensor(init_train_f1_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v1_ds = TensorDataset(train_f1_final, train_f1_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v1_dl = torch.utils.data.DataLoader(train_v1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "e9MIbJM5NBFX"
   },
   "outputs": [],
   "source": [
    "init_train_f2 = trainset_f2_pd.iloc[:, : 784].values\n",
    "train_f2 = torch.tensor(init_train_f2)\n",
    "train_f2_final = train_f2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f2_target = trainset_f2_pd.iloc[:, -1].values\n",
    "train_f2_target = torch.tensor(init_train_f2_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v2_ds = TensorDataset(train_f2_final, train_f2_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v2_dl = torch.utils.data.DataLoader(train_v2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "GGnOYqQxNA9b"
   },
   "outputs": [],
   "source": [
    "init_train_f3 = trainset_f3_pd.iloc[:, : 784].values\n",
    "train_f3 = torch.tensor(init_train_f3)\n",
    "train_f3_final = train_f3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f3_target = trainset_f3_pd.iloc[:, -1].values\n",
    "train_f3_target = torch.tensor(init_train_f3_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v3_ds = TensorDataset(train_f3_final, train_f3_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v3_dl = torch.utils.data.DataLoader(train_v3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "JO0l6nWbNA0F"
   },
   "outputs": [],
   "source": [
    "init_train_f4 = trainset_f4_pd.iloc[:, : 784].values\n",
    "train_f4 = torch.tensor(init_train_f4)\n",
    "train_f4_final = train_f4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f4_target = trainset_f4_pd.iloc[:, -1].values\n",
    "train_f4_target = torch.tensor(init_train_f4_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v4_ds = TensorDataset(train_f4_final, train_f4_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v4_dl = torch.utils.data.DataLoader(train_v4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "HGrJEbtONAqF"
   },
   "outputs": [],
   "source": [
    "init_train_f5 = trainset_f5_pd.iloc[:, : 784].values\n",
    "train_f5 = torch.tensor(init_train_f5)\n",
    "train_f5_final = train_f5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f5_target = trainset_f5_pd.iloc[:, -1].values\n",
    "train_f5_target = torch.tensor(init_train_f5_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v5_ds = TensorDataset(train_f5_final, train_f5_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v5_dl = torch.utils.data.DataLoader(train_v5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "63J6pzPXNAhy"
   },
   "outputs": [],
   "source": [
    "init_train_f6 = trainset_f6_pd.iloc[:, : 784].values\n",
    "train_f6 = torch.tensor(init_train_f6)\n",
    "train_f6_final = train_f6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f6_target = trainset_f6_pd.iloc[:, -1].values\n",
    "train_f6_target = torch.tensor(init_train_f6_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v6_ds = TensorDataset(train_f6_final, train_f6_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v6_dl = torch.utils.data.DataLoader(train_v6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "zA4dHCN3NAVS"
   },
   "outputs": [],
   "source": [
    "init_train_f7 = trainset_f7_pd.iloc[:, : 784].values\n",
    "train_f7 = torch.tensor(init_train_f7)\n",
    "train_f7_final = train_f7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f7_target = trainset_f7_pd.iloc[:, -1].values\n",
    "train_f7_target = torch.tensor(init_train_f7_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v7_ds = TensorDataset(train_f7_final, train_f7_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v7_dl = torch.utils.data.DataLoader(train_v7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "5cVh_R4BNAOh"
   },
   "outputs": [],
   "source": [
    "init_train_f8 = trainset_f8_pd.iloc[:, : 784].values\n",
    "train_f8 = torch.tensor(init_train_f8)\n",
    "train_f8_final = train_f8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f8_target = trainset_f8_pd.iloc[:, -1].values\n",
    "train_f8_target = torch.tensor(init_train_f8_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v8_ds = TensorDataset(train_f8_final, train_f8_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v8_dl = torch.utils.data.DataLoader(train_v8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "6KfvTuKSNAGZ"
   },
   "outputs": [],
   "source": [
    "init_train_f9 = trainset_f9_pd.iloc[:, : 784].values\n",
    "train_f9 = torch.tensor(init_train_f9)\n",
    "train_f9_final = train_f9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f9_target = trainset_f9_pd.iloc[:, -1].values\n",
    "train_f9_target = torch.tensor(init_train_f9_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v9_ds = TensorDataset(train_f9_final, train_f9_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v9_dl = torch.utils.data.DataLoader(train_v9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "uooZLZ9nM_9f"
   },
   "outputs": [],
   "source": [
    "init_train_f10 = trainset_f10_pd.iloc[:, : 784].values\n",
    "train_f10 = torch.tensor(init_train_f10)\n",
    "train_f10_final = train_f10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_f10_target = trainset_f10_pd.iloc[:, -1].values\n",
    "train_f10_target = torch.tensor(init_train_f10_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_v10_ds = TensorDataset(train_f10_final, train_f10_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_v10_dl = torch.utils.data.DataLoader(train_v10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "vLreIFm9M_1m"
   },
   "outputs": [],
   "source": [
    "init_train_g1 = trainset_g1_pd.iloc[:, : 784].values\n",
    "train_g1 = torch.tensor(init_train_g1)\n",
    "train_g1_final = train_g1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g1_target = trainset_g1_pd.iloc[:, -1].values\n",
    "train_g1_target = torch.tensor(init_train_g1_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w1_ds = TensorDataset(train_g1_final, train_g1_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w1_dl = torch.utils.data.DataLoader(train_w1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "IFaejD9BM_t8"
   },
   "outputs": [],
   "source": [
    "init_train_g2 = trainset_g2_pd.iloc[:, : 784].values\n",
    "train_g2 = torch.tensor(init_train_g2)\n",
    "train_g2_final = train_g2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g2_target = trainset_g2_pd.iloc[:, -1].values\n",
    "train_g2_target = torch.tensor(init_train_g2_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w2_ds = TensorDataset(train_g2_final, train_g2_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w2_dl = torch.utils.data.DataLoader(train_w2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "OTPCEcuKM_k9"
   },
   "outputs": [],
   "source": [
    "init_train_g3 = trainset_g3_pd.iloc[:, : 784].values\n",
    "train_g3 = torch.tensor(init_train_g3)\n",
    "train_g3_final = train_g3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g3_target = trainset_g3_pd.iloc[:, -1].values\n",
    "train_g3_target = torch.tensor(init_train_g3_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w3_ds = TensorDataset(train_g3_final, train_g3_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w3_dl = torch.utils.data.DataLoader(train_w3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "CPiX969vM_bn"
   },
   "outputs": [],
   "source": [
    "init_train_g4 = trainset_g4_pd.iloc[:, : 784].values\n",
    "train_g4 = torch.tensor(init_train_g4)\n",
    "train_g4_final = train_g4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g4_target = trainset_g4_pd.iloc[:, -1].values\n",
    "train_g4_target = torch.tensor(init_train_g4_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w4_ds = TensorDataset(train_g4_final, train_g4_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w4_dl = torch.utils.data.DataLoader(train_w4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "JL7UQSyBM_Pf"
   },
   "outputs": [],
   "source": [
    "init_train_g5 = trainset_g5_pd.iloc[:, : 784].values\n",
    "train_g5 = torch.tensor(init_train_g5)\n",
    "train_g5_final = train_g5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g5_target = trainset_g5_pd.iloc[:, -1].values\n",
    "train_g5_target = torch.tensor(init_train_g5_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w5_ds = TensorDataset(train_g5_final, train_g5_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w5_dl = torch.utils.data.DataLoader(train_w5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "pb155c7OM_HG"
   },
   "outputs": [],
   "source": [
    "init_train_g6 = trainset_g6_pd.iloc[:, : 784].values\n",
    "train_g6 = torch.tensor(init_train_g6)\n",
    "train_g6_final = train_g6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g6_target = trainset_g6_pd.iloc[:, -1].values\n",
    "train_g6_target = torch.tensor(init_train_g6_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w6_ds = TensorDataset(train_g6_final, train_g6_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w6_dl = torch.utils.data.DataLoader(train_w6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "YlY_iXJsM-_k"
   },
   "outputs": [],
   "source": [
    "init_train_g7 = trainset_g7_pd.iloc[:, : 784].values\n",
    "train_g7 = torch.tensor(init_train_g7)\n",
    "train_g7_final = train_g7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g7_target = trainset_g7_pd.iloc[:, -1].values\n",
    "train_g7_target = torch.tensor(init_train_g7_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w7_ds = TensorDataset(train_g7_final, train_g7_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w7_dl = torch.utils.data.DataLoader(train_w7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "jGLDq6aqM-30"
   },
   "outputs": [],
   "source": [
    "init_train_g8 = trainset_g8_pd.iloc[:, : 784].values\n",
    "train_g8 = torch.tensor(init_train_g8)\n",
    "train_g8_final = train_g8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g8_target = trainset_g8_pd.iloc[:, -1].values\n",
    "train_g8_target = torch.tensor(init_train_g8_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w8_ds = TensorDataset(train_g8_final, train_g8_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w8_dl = torch.utils.data.DataLoader(train_w8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "d73ka0dMM-vm"
   },
   "outputs": [],
   "source": [
    "init_train_g9 = trainset_g9_pd.iloc[:, : 784].values\n",
    "train_g9 = torch.tensor(init_train_g9)\n",
    "train_g9_final = train_g9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g9_target = trainset_g9_pd.iloc[:, -1].values\n",
    "train_g9_target = torch.tensor(init_train_g9_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w9_ds = TensorDataset(train_g9_final, train_g9_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w9_dl = torch.utils.data.DataLoader(train_w9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "uuWPxce_M-nI"
   },
   "outputs": [],
   "source": [
    "init_train_g10 = trainset_g10_pd.iloc[:, : 784].values\n",
    "train_g10 = torch.tensor(init_train_g10)\n",
    "train_g10_final = train_g10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_g10_target = trainset_g10_pd.iloc[:, -1].values\n",
    "train_g10_target = torch.tensor(init_train_g10_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_w10_ds = TensorDataset(train_g10_final, train_g10_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_w10_dl = torch.utils.data.DataLoader(train_w10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "QW4EmV35M-fK"
   },
   "outputs": [],
   "source": [
    "init_train_h1 = trainset_h1_pd.iloc[:, : 784].values\n",
    "train_h1 = torch.tensor(init_train_h1)\n",
    "train_h1_final = train_h1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h1_target = trainset_h1_pd.iloc[:, -1].values\n",
    "train_h1_target = torch.tensor(init_train_h1_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x1_ds = TensorDataset(train_h1_final, train_h1_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x1_dl = torch.utils.data.DataLoader(train_x1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "mljollsDM-W3"
   },
   "outputs": [],
   "source": [
    "init_train_h2 = trainset_h2_pd.iloc[:, : 784].values\n",
    "train_h2 = torch.tensor(init_train_h2)\n",
    "train_h2_final = train_h2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h2_target = trainset_h2_pd.iloc[:, -1].values\n",
    "train_h2_target = torch.tensor(init_train_h2_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x2_ds = TensorDataset(train_h2_final, train_h2_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x2_dl = torch.utils.data.DataLoader(train_x2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "RGY3oYXyM-N-"
   },
   "outputs": [],
   "source": [
    "init_train_h3 = trainset_h3_pd.iloc[:, : 784].values\n",
    "train_h3 = torch.tensor(init_train_h3)\n",
    "train_h3_final = train_h3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h3_target = trainset_h3_pd.iloc[:, -1].values\n",
    "train_h3_target = torch.tensor(init_train_h3_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x3_ds = TensorDataset(train_h3_final, train_h3_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x3_dl = torch.utils.data.DataLoader(train_x3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "EeYtQcGqM-E0"
   },
   "outputs": [],
   "source": [
    "init_train_h4 = trainset_h4_pd.iloc[:, : 784].values\n",
    "train_h4 = torch.tensor(init_train_h4)\n",
    "train_h4_final = train_h4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h4_target = trainset_h4_pd.iloc[:, -1].values\n",
    "train_h4_target = torch.tensor(init_train_h4_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x4_ds = TensorDataset(train_h4_final, train_h4_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x4_dl = torch.utils.data.DataLoader(train_x4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "IpUrDReSM97E"
   },
   "outputs": [],
   "source": [
    "init_train_h5 = trainset_h5_pd.iloc[:, : 784].values\n",
    "train_h5 = torch.tensor(init_train_h5)\n",
    "train_h5_final = train_h5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h5_target = trainset_h5_pd.iloc[:, -1].values\n",
    "train_h5_target = torch.tensor(init_train_h5_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x5_ds = TensorDataset(train_h5_final, train_h5_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x5_dl = torch.utils.data.DataLoader(train_x5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "o9h0vc6cM9yt"
   },
   "outputs": [],
   "source": [
    "init_train_h6 = trainset_h6_pd.iloc[:, : 784].values\n",
    "train_h6 = torch.tensor(init_train_h6)\n",
    "train_h6_final = train_h6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h6_target = trainset_h6_pd.iloc[:, -1].values\n",
    "train_h6_target = torch.tensor(init_train_h6_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x6_ds = TensorDataset(train_h6_final, train_h6_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x6_dl = torch.utils.data.DataLoader(train_x6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "IF4ii2urM9pT"
   },
   "outputs": [],
   "source": [
    "init_train_h7 = trainset_h7_pd.iloc[:, : 784].values\n",
    "train_h7 = torch.tensor(init_train_h7)\n",
    "train_h7_final = train_h7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h7_target = trainset_h7_pd.iloc[:, -1].values\n",
    "train_h7_target = torch.tensor(init_train_h7_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x7_ds = TensorDataset(train_h7_final, train_h7_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x7_dl = torch.utils.data.DataLoader(train_x7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "yJM8gKTlM9hB"
   },
   "outputs": [],
   "source": [
    "init_train_h8 = trainset_h8_pd.iloc[:, : 784].values\n",
    "train_h8 = torch.tensor(init_train_h8)\n",
    "train_h8_final = train_h8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h8_target = trainset_h8_pd.iloc[:, -1].values\n",
    "train_h8_target = torch.tensor(init_train_h8_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x8_ds = TensorDataset(train_h8_final, train_h8_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x8_dl = torch.utils.data.DataLoader(train_x8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "GjNrmEzVM9Xj"
   },
   "outputs": [],
   "source": [
    "init_train_h9 = trainset_h9_pd.iloc[:, : 784].values\n",
    "train_h9 = torch.tensor(init_train_h9)\n",
    "train_h9_final = train_h9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h9_target = trainset_h9_pd.iloc[:, -1].values\n",
    "train_h9_target = torch.tensor(init_train_h9_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x9_ds = TensorDataset(train_h9_final, train_h9_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x9_dl = torch.utils.data.DataLoader(train_x9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "LEqZOlrpM9OX"
   },
   "outputs": [],
   "source": [
    "init_train_h10 = trainset_h10_pd.iloc[:, : 784].values\n",
    "train_h10 = torch.tensor(init_train_h10)\n",
    "train_h10_final = train_h10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_h10_target = trainset_h10_pd.iloc[:, -1].values\n",
    "train_h10_target = torch.tensor(init_train_h10_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_x10_ds = TensorDataset(train_h10_final, train_h10_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_x10_dl = torch.utils.data.DataLoader(train_x10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "e1NR5JzpM9FT"
   },
   "outputs": [],
   "source": [
    "init_train_i1 = trainset_i1_pd.iloc[:, : 784].values\n",
    "train_i1 = torch.tensor(init_train_i1)\n",
    "train_i1_final = train_i1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i1_target = trainset_i1_pd.iloc[:, -1].values\n",
    "train_i1_target = torch.tensor(init_train_i1_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y1_ds = TensorDataset(train_i1_final, train_i1_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y1_dl = torch.utils.data.DataLoader(train_y1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "aQ6Ano6hM881"
   },
   "outputs": [],
   "source": [
    "init_train_i2 = trainset_i2_pd.iloc[:, : 784].values\n",
    "train_i2 = torch.tensor(init_train_i2)\n",
    "train_i2_final = train_i2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i2_target = trainset_i2_pd.iloc[:, -1].values\n",
    "train_i2_target = torch.tensor(init_train_i2_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y2_ds = TensorDataset(train_i2_final, train_i2_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y2_dl = torch.utils.data.DataLoader(train_y2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "qFnzqfy4M8ys"
   },
   "outputs": [],
   "source": [
    "init_train_i3 = trainset_i3_pd.iloc[:, : 784].values\n",
    "train_i3 = torch.tensor(init_train_i3)\n",
    "train_i3_final = train_i3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i3_target = trainset_i3_pd.iloc[:, -1].values\n",
    "train_i3_target = torch.tensor(init_train_i3_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y3_ds = TensorDataset(train_i3_final, train_i3_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y3_dl = torch.utils.data.DataLoader(train_y3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "R4iztoW4M8qR"
   },
   "outputs": [],
   "source": [
    "init_train_i4 = trainset_i4_pd.iloc[:, : 784].values\n",
    "train_i4 = torch.tensor(init_train_i4)\n",
    "train_i4_final = train_i4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i4_target = trainset_i4_pd.iloc[:, -1].values\n",
    "train_i4_target = torch.tensor(init_train_i4_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y4_ds = TensorDataset(train_i4_final, train_i4_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y4_dl = torch.utils.data.DataLoader(train_y4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "XhEbUHmRM8gk"
   },
   "outputs": [],
   "source": [
    "init_train_i5 = trainset_i5_pd.iloc[:, : 784].values\n",
    "train_i5 = torch.tensor(init_train_i5)\n",
    "train_i5_final = train_i5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i5_target = trainset_i5_pd.iloc[:, -1].values\n",
    "train_i5_target = torch.tensor(init_train_i5_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y5_ds = TensorDataset(train_i5_final, train_i5_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y5_dl = torch.utils.data.DataLoader(train_y5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "UagSixXGM8W6"
   },
   "outputs": [],
   "source": [
    "init_train_i6 = trainset_i6_pd.iloc[:, : 784].values\n",
    "train_i6 = torch.tensor(init_train_i6)\n",
    "train_i6_final = train_i6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i6_target = trainset_i6_pd.iloc[:, -1].values\n",
    "train_i6_target = torch.tensor(init_train_i6_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y6_ds = TensorDataset(train_i6_final, train_i6_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y6_dl = torch.utils.data.DataLoader(train_y6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "AFobNgUVM8M8"
   },
   "outputs": [],
   "source": [
    "init_train_i7 = trainset_i7_pd.iloc[:, : 784].values\n",
    "train_i7 = torch.tensor(init_train_i7)\n",
    "train_i7_final = train_i7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i7_target = trainset_i7_pd.iloc[:, -1].values\n",
    "train_i7_target = torch.tensor(init_train_i7_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y7_ds = TensorDataset(train_i7_final, train_i7_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y7_dl = torch.utils.data.DataLoader(train_y7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "PCHWvnSHM8Ef"
   },
   "outputs": [],
   "source": [
    "init_train_i8 = trainset_i8_pd.iloc[:, : 784].values\n",
    "train_i8 = torch.tensor(init_train_i8)\n",
    "train_i8_final = train_i8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i8_target = trainset_i8_pd.iloc[:, -1].values\n",
    "train_i8_target = torch.tensor(init_train_i8_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y8_ds = TensorDataset(train_i8_final, train_i8_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y8_dl = torch.utils.data.DataLoader(train_y8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "w_LhkOK3M76r"
   },
   "outputs": [],
   "source": [
    "init_train_i9 = trainset_i9_pd.iloc[:, : 784].values\n",
    "train_i9 = torch.tensor(init_train_i9)\n",
    "train_i9_final = train_i9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i9_target = trainset_i9_pd.iloc[:, -1].values\n",
    "train_i9_target = torch.tensor(init_train_i9_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y9_ds = TensorDataset(train_i9_final, train_i9_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y9_dl = torch.utils.data.DataLoader(train_y9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "4XIxyzVcM7xB"
   },
   "outputs": [],
   "source": [
    "init_train_i10 = trainset_i10_pd.iloc[:, : 784].values\n",
    "train_i10 = torch.tensor(init_train_i10)\n",
    "train_i10_final = train_i10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_i10_target = trainset_i10_pd.iloc[:, -1].values\n",
    "train_i10_target = torch.tensor(init_train_i10_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_y10_ds = TensorDataset(train_i10_final, train_i10_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_y10_dl = torch.utils.data.DataLoader(train_y10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "ZUEsBJTGM7oG"
   },
   "outputs": [],
   "source": [
    "init_train_j1 = trainset_j1_pd.iloc[:, : 784].values\n",
    "train_j1 = torch.tensor(init_train_j1)\n",
    "train_j1_final = train_j1.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j1_target = trainset_j1_pd.iloc[:, -1].values\n",
    "train_j1_target = torch.tensor(init_train_j1_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z1_ds = TensorDataset(train_j1_final, train_j1_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z1_dl = torch.utils.data.DataLoader(train_z1_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "kc4Hd_DZM7de"
   },
   "outputs": [],
   "source": [
    "init_train_j2 = trainset_j2_pd.iloc[:, : 784].values\n",
    "train_j2 = torch.tensor(init_train_j2)\n",
    "train_j2_final = train_j2.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j2_target = trainset_j2_pd.iloc[:, -1].values\n",
    "train_j2_target = torch.tensor(init_train_j2_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z2_ds = TensorDataset(train_j2_final, train_j2_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z2_dl = torch.utils.data.DataLoader(train_z2_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "bShh5iA-M7TR"
   },
   "outputs": [],
   "source": [
    "init_train_j3 = trainset_j3_pd.iloc[:, : 784].values\n",
    "train_j3 = torch.tensor(init_train_j3)\n",
    "train_j3_final = train_j3.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j3_target = trainset_j3_pd.iloc[:, -1].values\n",
    "train_j3_target = torch.tensor(init_train_j3_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z3_ds = TensorDataset(train_j3_final, train_j3_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z3_dl = torch.utils.data.DataLoader(train_z3_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "1PSaD6MYM7JU"
   },
   "outputs": [],
   "source": [
    "init_train_j4 = trainset_j4_pd.iloc[:, : 784].values\n",
    "train_j4 = torch.tensor(init_train_j4)\n",
    "train_j4_final = train_j4.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j4_target = trainset_j4_pd.iloc[:, -1].values\n",
    "train_j4_target = torch.tensor(init_train_j4_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z4_ds = TensorDataset(train_j4_final, train_j4_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z4_dl = torch.utils.data.DataLoader(train_z4_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "4oYX97FLM69e"
   },
   "outputs": [],
   "source": [
    "init_train_j5 = trainset_j5_pd.iloc[:, : 784].values\n",
    "train_j5 = torch.tensor(init_train_j5)\n",
    "train_j5_final = train_j5.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j5_target = trainset_j5_pd.iloc[:, -1].values\n",
    "train_j5_target = torch.tensor(init_train_j5_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z5_ds = TensorDataset(train_j5_final, train_j5_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z5_dl = torch.utils.data.DataLoader(train_z5_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "YpdmQNiEM60a"
   },
   "outputs": [],
   "source": [
    "init_train_j6 = trainset_j6_pd.iloc[:, : 784].values\n",
    "train_j6 = torch.tensor(init_train_j6)\n",
    "train_j6_final = train_j6.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j6_target = trainset_j6_pd.iloc[:, -1].values\n",
    "train_j6_target = torch.tensor(init_train_j6_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z6_ds = TensorDataset(train_j6_final, train_j6_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z6_dl = torch.utils.data.DataLoader(train_z6_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "u66-Jcg_M6oR"
   },
   "outputs": [],
   "source": [
    "init_train_j7 = trainset_j7_pd.iloc[:, : 784].values\n",
    "train_j7 = torch.tensor(init_train_j7)\n",
    "train_j7_final = train_j7.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j7_target = trainset_j7_pd.iloc[:, -1].values\n",
    "train_j7_target = torch.tensor(init_train_j7_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z7_ds = TensorDataset(train_j7_final, train_j7_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z7_dl = torch.utils.data.DataLoader(train_z7_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "rCAstDacM6go"
   },
   "outputs": [],
   "source": [
    "init_train_j8 = trainset_j8_pd.iloc[:, : 784].values\n",
    "train_j8 = torch.tensor(init_train_j8)\n",
    "train_j8_final = train_j8.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j8_target = trainset_j8_pd.iloc[:, -1].values\n",
    "train_j8_target = torch.tensor(init_train_j8_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z8_ds = TensorDataset(train_j8_final, train_j8_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z8_dl = torch.utils.data.DataLoader(train_z8_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "3qowojqIM6Ub"
   },
   "outputs": [],
   "source": [
    "init_train_j9 = trainset_j9_pd.iloc[:, : 784].values\n",
    "train_j9 = torch.tensor(init_train_j9)\n",
    "train_j9_final = train_j9.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j9_target = trainset_j9_pd.iloc[:, -1].values\n",
    "train_j9_target = torch.tensor(init_train_j9_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z9_ds = TensorDataset(train_j9_final, train_j9_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z9_dl = torch.utils.data.DataLoader(train_z9_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "bL9jKhYQM5tG"
   },
   "outputs": [],
   "source": [
    "init_train_j10 = trainset_j10_pd.iloc[:, : 784].values\n",
    "train_j10 = torch.tensor(init_train_j10)\n",
    "train_j10_final = train_j10.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_j10_target = trainset_j10_pd.iloc[:, -1].values\n",
    "train_j10_target = torch.tensor(init_train_j10_target)\n",
    "\n",
    "\n",
    "#Trainset D Data and Target Tensor to Dataset then Dataloader\n",
    "train_z10_ds = TensorDataset(train_j10_final, train_j10_target)\n",
    "#Tensor Dataset train y to Dataloader\n",
    "# Trainset 4: train_y_dl\n",
    "train_z10_dl = torch.utils.data.DataLoader(train_z10_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "QyYmXyChSuMw"
   },
   "outputs": [],
   "source": [
    "#Trainset E Data and Target to Tensor\n",
    "init_train_k = trainset_k_pd.iloc[:, : 784].values\n",
    "train_k = torch.tensor(init_train_k)\n",
    "train_k_final = train_k.view(-1, 1,28,28).float()\n",
    "\n",
    "init_train_k_target = trainset_k_pd.iloc[:, -1].values\n",
    "train_k_target = torch.tensor(init_train_k_target)\n",
    "\n",
    "\n",
    "#Trainset E Data and Target Tensor to Dataset then Dataloader\n",
    "train_zz_ds = TensorDataset(train_k_final, train_k_target)\n",
    "#Tensor Dataset train z to Dataloader\n",
    "# Trainset 4: train_z_dl\n",
    "train_zz_dl = torch.utils.data.DataLoader(train_zz_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "BIjOfIc-SrZU"
   },
   "outputs": [],
   "source": [
    "###-------------- Define a Convolutional Neural Network ---------------###\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "WA8cQN6VNSoL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 10999\n"
     ]
    }
   ],
   "source": [
    "train_size = len(trainset_a)\n",
    "test_size = len(test_ds)\n",
    "\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "oT1jFrGlFIsj"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                \n",
    "                for (idx, (inputs, labels)) in enumerate(train_loader):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        outputs = model(inputs)\n",
    "                        \n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        # print(preds, labels)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "                    \n",
    "                scheduler.step()\n",
    "                print(running_corrects)\n",
    "                epoch_loss = running_loss / train_size\n",
    "                epoch_acc = running_corrects.double() / train_size\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Train', epoch_loss, epoch_acc))\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                \n",
    "                for data in test_loader:\n",
    "                    inputs, labels = data\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        \n",
    "                        loss = criterion(outputs, labels)\n",
    "                \n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                epoch_loss = running_loss / test_size\n",
    "                epoch_acc = running_corrects.double() / test_size\n",
    "                \n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                last_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, best_acc, last_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "Mt4T9iQXc7K0"
   },
   "outputs": [],
   "source": [
    "net1 = Net()\n",
    "net2 = Net()\n",
    "net3 = Net()\n",
    "net4 = Net()\n",
    "net5 = Net()\n",
    "net6 = Net()\n",
    "net7 = Net()\n",
    "net8 = Net()\n",
    "net9 = Net()\n",
    "net10 = Net()\n",
    "\n",
    "net11 = Net()\n",
    "net12 = Net()\n",
    "net13 = Net()\n",
    "net14 = Net()\n",
    "net15 = Net()\n",
    "net16 = Net()\n",
    "net17 = Net()\n",
    "net18 = Net()\n",
    "net19 = Net()\n",
    "net20 = Net()\n",
    "\n",
    "net21 = Net()\n",
    "net22 = Net()\n",
    "net23 = Net()\n",
    "net24 = Net()\n",
    "net25 = Net()\n",
    "net26 = Net()\n",
    "net27 = Net()\n",
    "net28 = Net()\n",
    "net29 = Net()\n",
    "net30 = Net()\n",
    "\n",
    "net31 = Net()\n",
    "net32 = Net()\n",
    "net33 = Net()\n",
    "net34 = Net()\n",
    "net35 = Net()\n",
    "net36 = Net()\n",
    "net37 = Net()\n",
    "net38 = Net()\n",
    "net39 = Net()\n",
    "net40 = Net()\n",
    "\n",
    "net41 = Net()\n",
    "net42 = Net()\n",
    "net43 = Net()\n",
    "net44 = Net()\n",
    "net45 = Net()\n",
    "net46 = Net()\n",
    "net47 = Net()\n",
    "net48 = Net()\n",
    "net49 = Net()\n",
    "net50 = Net()\n",
    "\n",
    "net51 = Net()\n",
    "net52 = Net()\n",
    "net53 = Net()\n",
    "net54 = Net()\n",
    "net55 = Net()\n",
    "net56 = Net()\n",
    "net57 = Net()\n",
    "net58 = Net()\n",
    "net59 = Net()\n",
    "net60 = Net()\n",
    "\n",
    "net61 = Net()\n",
    "net62 = Net()\n",
    "net63 = Net()\n",
    "net64 = Net()\n",
    "net65 = Net()\n",
    "net66 = Net()\n",
    "net67 = Net()\n",
    "net68 = Net()\n",
    "net69 = Net()\n",
    "net70 = Net()\n",
    "\n",
    "net71 = Net()\n",
    "net72 = Net()\n",
    "net73 = Net()\n",
    "net74 = Net()\n",
    "net75 = Net()\n",
    "net76 = Net()\n",
    "net77 = Net()\n",
    "net78 = Net()\n",
    "net79 = Net()\n",
    "net80 = Net()\n",
    "\n",
    "net81 = Net()\n",
    "net82 = Net()\n",
    "net83 = Net()\n",
    "net84 = Net()\n",
    "net85 = Net()\n",
    "net86 = Net()\n",
    "net87 = Net()\n",
    "net88 = Net()\n",
    "net89 = Net()\n",
    "net90 = Net()\n",
    "\n",
    "net91 = Net()\n",
    "net92 = Net()\n",
    "net93 = Net()\n",
    "net94 = Net()\n",
    "net95 = Net()\n",
    "net96 = Net()\n",
    "net97 = Net()\n",
    "net98 = Net()\n",
    "net99 = Net()\n",
    "net100 = Net()\n",
    "\n",
    "net101 = Net()\n",
    "net102 = Net()\n",
    "net103 = Net()\n",
    "net104 = Net()\n",
    "net105 = Net()\n",
    "net106 = Net()\n",
    "net107 = Net()\n",
    "net108 = Net()\n",
    "net109 = Net()\n",
    "net110 = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "net90 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "ttTlD3SVSWZj"
   },
   "outputs": [],
   "source": [
    "#---------------- Define a Loss function and optimizer -------------------\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "vjZhhZUUFOwq"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer1 = optim.Adam(net1.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_1 = lr_scheduler.StepLR(optimizer1, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer2 = optim.Adam(net2.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_2 = lr_scheduler.StepLR(optimizer2, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer3 = optim.Adam(net3.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_3 = lr_scheduler.StepLR(optimizer3, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer4 = optim.Adam(net4.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_4 = lr_scheduler.StepLR(optimizer4, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer5 = optim.Adam(net5.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_5 = lr_scheduler.StepLR(optimizer5, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer6 = optim.Adam(net6.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_6 = lr_scheduler.StepLR(optimizer6, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer7 = optim.Adam(net7.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_7 = lr_scheduler.StepLR(optimizer7, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer8 = optim.Adam(net8.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_8 = lr_scheduler.StepLR(optimizer8, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer9 = optim.Adam(net9.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_9 = lr_scheduler.StepLR(optimizer9, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer10 = optim.Adam(net10.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_10 = lr_scheduler.StepLR(optimizer10, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "o0xfDFb0PoH1"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer11 = optim.Adam(net11.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_11 = lr_scheduler.StepLR(optimizer11, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer12 = optim.Adam(net12.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_12 = lr_scheduler.StepLR(optimizer12, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer13 = optim.Adam(net13.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_13 = lr_scheduler.StepLR(optimizer13, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer14 = optim.Adam(net14.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_14 = lr_scheduler.StepLR(optimizer14, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer15 = optim.Adam(net15.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_15 = lr_scheduler.StepLR(optimizer15, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer16 = optim.Adam(net16.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_16 = lr_scheduler.StepLR(optimizer16, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer17 = optim.Adam(net17.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_17 = lr_scheduler.StepLR(optimizer17, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer18 = optim.Adam(net18.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_18 = lr_scheduler.StepLR(optimizer18, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer19 = optim.Adam(net19.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_19 = lr_scheduler.StepLR(optimizer19, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer20 = optim.Adam(net20.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_20 = lr_scheduler.StepLR(optimizer20, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "qY3Cko4BQQvU"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer21 = optim.Adam(net21.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_21 = lr_scheduler.StepLR(optimizer21, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer22 = optim.Adam(net22.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_22 = lr_scheduler.StepLR(optimizer22, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer23 = optim.Adam(net23.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_23 = lr_scheduler.StepLR(optimizer23, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer24 = optim.Adam(net24.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_24 = lr_scheduler.StepLR(optimizer24, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer25 = optim.Adam(net25.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_25 = lr_scheduler.StepLR(optimizer25, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer26 = optim.Adam(net26.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_26 = lr_scheduler.StepLR(optimizer26, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer27 = optim.Adam(net27.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_27 = lr_scheduler.StepLR(optimizer27, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer28 = optim.Adam(net28.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_28 = lr_scheduler.StepLR(optimizer28, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer29 = optim.Adam(net29.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_29 = lr_scheduler.StepLR(optimizer29, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer30 = optim.Adam(net30.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_30 = lr_scheduler.StepLR(optimizer30, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "FdFGD0EMQyPn"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer31 = optim.Adam(net31.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_31 = lr_scheduler.StepLR(optimizer31, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer32 = optim.Adam(net32.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_32 = lr_scheduler.StepLR(optimizer32, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer33 = optim.Adam(net33.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_33 = lr_scheduler.StepLR(optimizer33, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer34 = optim.Adam(net34.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_34 = lr_scheduler.StepLR(optimizer34, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer35 = optim.Adam(net35.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_35 = lr_scheduler.StepLR(optimizer35, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer36 = optim.Adam(net36.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_36 = lr_scheduler.StepLR(optimizer36, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer37 = optim.Adam(net37.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_37 = lr_scheduler.StepLR(optimizer37, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer38 = optim.Adam(net38.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_38 = lr_scheduler.StepLR(optimizer38, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer39 = optim.Adam(net39.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_39 = lr_scheduler.StepLR(optimizer39, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer40 = optim.Adam(net40.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_40 = lr_scheduler.StepLR(optimizer40, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "5ky7LadZRTcX"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer41 = optim.Adam(net41.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_41 = lr_scheduler.StepLR(optimizer41, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer42 = optim.Adam(net42.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_42 = lr_scheduler.StepLR(optimizer42, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer43 = optim.Adam(net43.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_43 = lr_scheduler.StepLR(optimizer43, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer44 = optim.Adam(net44.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_44 = lr_scheduler.StepLR(optimizer44, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer45 = optim.Adam(net45.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_45 = lr_scheduler.StepLR(optimizer45, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer46 = optim.Adam(net46.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_46 = lr_scheduler.StepLR(optimizer46, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer47 = optim.Adam(net47.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_47 = lr_scheduler.StepLR(optimizer47, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer48 = optim.Adam(net48.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_48 = lr_scheduler.StepLR(optimizer48, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer49 = optim.Adam(net49.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_49 = lr_scheduler.StepLR(optimizer49, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer50 = optim.Adam(net50.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_50 = lr_scheduler.StepLR(optimizer50, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "xgI7zfDrL30V"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer51 = optim.Adam(net51.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_51 = lr_scheduler.StepLR(optimizer51, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer52 = optim.Adam(net52.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_52 = lr_scheduler.StepLR(optimizer52, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer53 = optim.Adam(net53.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_53 = lr_scheduler.StepLR(optimizer53, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer54 = optim.Adam(net54.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_54 = lr_scheduler.StepLR(optimizer54, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer55 = optim.Adam(net55.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_55 = lr_scheduler.StepLR(optimizer55, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer56 = optim.Adam(net56.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_56 = lr_scheduler.StepLR(optimizer56, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer57 = optim.Adam(net57.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_57 = lr_scheduler.StepLR(optimizer57, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer58 = optim.Adam(net58.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_58 = lr_scheduler.StepLR(optimizer58, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer59 = optim.Adam(net59.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_59 = lr_scheduler.StepLR(optimizer59, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer60 = optim.Adam(net60.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_60 = lr_scheduler.StepLR(optimizer60, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "ab8xAAtML3nq"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer61 = optim.Adam(net61.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_61 = lr_scheduler.StepLR(optimizer61, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer62 = optim.Adam(net62.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_62 = lr_scheduler.StepLR(optimizer62, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer63 = optim.Adam(net63.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_63 = lr_scheduler.StepLR(optimizer63, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer64 = optim.Adam(net64.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_64 = lr_scheduler.StepLR(optimizer64, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer65 = optim.Adam(net65.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_65 = lr_scheduler.StepLR(optimizer65, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer66 = optim.Adam(net66.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_66 = lr_scheduler.StepLR(optimizer66, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer67 = optim.Adam(net67.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_67 = lr_scheduler.StepLR(optimizer67, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer68 = optim.Adam(net68.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_68 = lr_scheduler.StepLR(optimizer68, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer69 = optim.Adam(net69.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_69 = lr_scheduler.StepLR(optimizer69, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer70 = optim.Adam(net70.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_70 = lr_scheduler.StepLR(optimizer70, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "IFAJhy06L3cM"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer71 = optim.Adam(net71.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_71 = lr_scheduler.StepLR(optimizer71, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer72 = optim.Adam(net72.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_72 = lr_scheduler.StepLR(optimizer72, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer73 = optim.Adam(net73.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_73 = lr_scheduler.StepLR(optimizer73, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer74 = optim.Adam(net74.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_74 = lr_scheduler.StepLR(optimizer74, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer75 = optim.Adam(net75.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_75 = lr_scheduler.StepLR(optimizer75, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer76 = optim.Adam(net76.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_76 = lr_scheduler.StepLR(optimizer76, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer77 = optim.Adam(net77.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_77 = lr_scheduler.StepLR(optimizer77, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer78 = optim.Adam(net78.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_78 = lr_scheduler.StepLR(optimizer78, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer79 = optim.Adam(net79.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_79 = lr_scheduler.StepLR(optimizer79, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer80 = optim.Adam(net80.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_80 = lr_scheduler.StepLR(optimizer80, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "gtQbm30UL3L8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net90' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-e438970488a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# Observe that all parameters are being optimized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0moptimizer90\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet90\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-07\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# Decay LR by a factor of 0.1 every 7 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net90' is not defined"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer81 = optim.Adam(net81.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_81 = lr_scheduler.StepLR(optimizer81, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer82 = optim.Adam(net82.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_82 = lr_scheduler.StepLR(optimizer82, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer83 = optim.Adam(net83.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_83 = lr_scheduler.StepLR(optimizer83, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer84 = optim.Adam(net84.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_84 = lr_scheduler.StepLR(optimizer84, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer85 = optim.Adam(net85.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_85 = lr_scheduler.StepLR(optimizer85, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer86 = optim.Adam(net86.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_86 = lr_scheduler.StepLR(optimizer86, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer87 = optim.Adam(net87.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_87 = lr_scheduler.StepLR(optimizer87, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer88 = optim.Adam(net88.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_88 = lr_scheduler.StepLR(optimizer88, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer89 = optim.Adam(net89.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_89 = lr_scheduler.StepLR(optimizer89, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer90 = optim.Adam(net90.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_90 = lr_scheduler.StepLR(optimizer90, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer90 = optim.Adam(net90.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_90 = lr_scheduler.StepLR(optimizer90, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "M7klsnTwL22h"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer91 = optim.Adam(net91.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_91 = lr_scheduler.StepLR(optimizer91, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer92 = optim.Adam(net92.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_92 = lr_scheduler.StepLR(optimizer92, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer93 = optim.Adam(net93.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_93 = lr_scheduler.StepLR(optimizer93, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer94 = optim.Adam(net94.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_94 = lr_scheduler.StepLR(optimizer94, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer95 = optim.Adam(net95.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_95 = lr_scheduler.StepLR(optimizer95, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer96 = optim.Adam(net96.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_96 = lr_scheduler.StepLR(optimizer96, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer97 = optim.Adam(net97.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_97 = lr_scheduler.StepLR(optimizer97, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer98 = optim.Adam(net98.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_98 = lr_scheduler.StepLR(optimizer98, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer99 = optim.Adam(net99.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_99 = lr_scheduler.StepLR(optimizer99, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer100 = optim.Adam(net100.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_100 = lr_scheduler.StepLR(optimizer100, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "eH9-h-ygGwAI"
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer101 = optim.Adam(net101.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_101 = lr_scheduler.StepLR(optimizer101, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer102 = optim.Adam(net102.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_102 = lr_scheduler.StepLR(optimizer102, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer103 = optim.Adam(net103.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_103 = lr_scheduler.StepLR(optimizer103, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer104 = optim.Adam(net104.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_104 = lr_scheduler.StepLR(optimizer104, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer105 = optim.Adam(net105.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_105 = lr_scheduler.StepLR(optimizer105, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer106 = optim.Adam(net106.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_106 = lr_scheduler.StepLR(optimizer106, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer107 = optim.Adam(net107.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_107 = lr_scheduler.StepLR(optimizer107, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer108 = optim.Adam(net108.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_108 = lr_scheduler.StepLR(optimizer108, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer109 = optim.Adam(net109.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_109 = lr_scheduler.StepLR(optimizer109, step_size=20, gamma=0.1)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer110 = optim.Adam(net110.parameters(), lr=0.001, weight_decay=1e-07)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler_110 = lr_scheduler.StepLR(optimizer110, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "xK4gcNUxsiCL"
   },
   "outputs": [],
   "source": [
    "num_epochs = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "EUdFOk4LLNIu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6637)\n",
      "Train Loss: 1.0992 Acc: 0.8296\n",
      "Val Loss: 0.1573 Acc: 0.9536\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7727)\n",
      "Train Loss: 0.1169 Acc: 0.9659\n",
      "Val Loss: 0.1314 Acc: 0.9636\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7778)\n",
      "Train Loss: 0.0803 Acc: 0.9722\n",
      "Val Loss: 0.1434 Acc: 0.9585\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7839)\n",
      "Train Loss: 0.0566 Acc: 0.9799\n",
      "Val Loss: 0.1243 Acc: 0.9670\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0380 Acc: 0.9886\n",
      "Val Loss: 0.1370 Acc: 0.9680\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0399 Acc: 0.9879\n",
      "Val Loss: 0.1580 Acc: 0.9650\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0239 Acc: 0.9932\n",
      "Val Loss: 0.1571 Acc: 0.9671\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0246 Acc: 0.9922\n",
      "Val Loss: 0.1557 Acc: 0.9658\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0250 Acc: 0.9922\n",
      "Val Loss: 0.1361 Acc: 0.9701\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0112 Acc: 0.9965\n",
      "Val Loss: 0.1451 Acc: 0.9726\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0178 Acc: 0.9938\n",
      "Val Loss: 0.1616 Acc: 0.9678\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7893)\n",
      "Train Loss: 0.0460 Acc: 0.9866\n",
      "Val Loss: 0.1637 Acc: 0.9670\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0254 Acc: 0.9935\n",
      "Val Loss: 0.1432 Acc: 0.9687\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0040 Acc: 0.9985\n",
      "Val Loss: 0.1261 Acc: 0.9745\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0062 Acc: 0.9981\n",
      "Val Loss: 0.1484 Acc: 0.9728\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0012 Acc: 0.9996\n",
      "Val Loss: 0.1262 Acc: 0.9785\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1243 Acc: 0.9790\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1240 Acc: 0.9790\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1241 Acc: 0.9790\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1244 Acc: 0.9788\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1244 Acc: 0.9789\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1245 Acc: 0.9789\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1245 Acc: 0.9788\n",
      "\n",
      "Training complete in 5m 50s\n",
      "Best val Acc: 0.978998\n"
     ]
    }
   ],
   "source": [
    "best_net1, best_acc1, last_net1 = train_model(net1, train_q_dl, test_dl, criterion, optimizer1, exp_lr_scheduler_1,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "sIYJegwxK7m9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6271)\n",
      "Train Loss: 1.6721 Acc: 0.7839\n",
      "Val Loss: 0.1641 Acc: 0.9525\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7680)\n",
      "Train Loss: 0.1336 Acc: 0.9600\n",
      "Val Loss: 0.1802 Acc: 0.9440\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7767)\n",
      "Train Loss: 0.0890 Acc: 0.9709\n",
      "Val Loss: 0.1722 Acc: 0.9484\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7859)\n",
      "Train Loss: 0.0526 Acc: 0.9824\n",
      "Val Loss: 0.1256 Acc: 0.9674\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0310 Acc: 0.9891\n",
      "Val Loss: 0.1496 Acc: 0.9599\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0258 Acc: 0.9906\n",
      "Val Loss: 0.1306 Acc: 0.9648\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0214 Acc: 0.9932\n",
      "Val Loss: 0.1349 Acc: 0.9659\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0283 Acc: 0.9908\n",
      "Val Loss: 0.1411 Acc: 0.9673\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0180 Acc: 0.9945\n",
      "Val Loss: 0.1776 Acc: 0.9653\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0188 Acc: 0.9928\n",
      "Val Loss: 0.1563 Acc: 0.9661\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0348 Acc: 0.9896\n",
      "Val Loss: 0.1842 Acc: 0.9651\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0318 Acc: 0.9908\n",
      "Val Loss: 0.2233 Acc: 0.9586\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0256 Acc: 0.9934\n",
      "Val Loss: 0.1497 Acc: 0.9690\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0165 Acc: 0.9951\n",
      "Val Loss: 0.1517 Acc: 0.9722\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0149 Acc: 0.9958\n",
      "Val Loss: 0.1992 Acc: 0.9688\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0358 Acc: 0.9902\n",
      "Val Loss: 0.1916 Acc: 0.9631\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0178 Acc: 0.9938\n",
      "Val Loss: 0.1943 Acc: 0.9661\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0149 Acc: 0.9952\n",
      "Val Loss: 0.1640 Acc: 0.9715\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0122 Acc: 0.9961\n",
      "Val Loss: 0.2184 Acc: 0.9663\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0145 Acc: 0.9960\n",
      "Val Loss: 0.1715 Acc: 0.9715\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0024 Acc: 0.9995\n",
      "Val Loss: 0.1497 Acc: 0.9755\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1488 Acc: 0.9759\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1487 Acc: 0.9756\n",
      "\n",
      "Training complete in 6m 4s\n",
      "Best val Acc: 0.975907\n"
     ]
    }
   ],
   "source": [
    "best_net2, best_acc2, last_net2 = train_model(net2, train_q_dl, test_dl, criterion, optimizer2, exp_lr_scheduler_2,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "rV7nmdPsSbYg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6466)\n",
      "Train Loss: 1.5418 Acc: 0.8083\n",
      "Val Loss: 0.1817 Acc: 0.9440\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7658)\n",
      "Train Loss: 0.1417 Acc: 0.9573\n",
      "Val Loss: 0.1553 Acc: 0.9529\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7811)\n",
      "Train Loss: 0.0733 Acc: 0.9764\n",
      "Val Loss: 0.1179 Acc: 0.9653\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7892)\n",
      "Train Loss: 0.0414 Acc: 0.9865\n",
      "Val Loss: 0.1604 Acc: 0.9526\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7875)\n",
      "Train Loss: 0.0447 Acc: 0.9844\n",
      "Val Loss: 0.1140 Acc: 0.9684\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0274 Acc: 0.9911\n",
      "Val Loss: 0.1339 Acc: 0.9684\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0184 Acc: 0.9936\n",
      "Val Loss: 0.1498 Acc: 0.9655\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0285 Acc: 0.9909\n",
      "Val Loss: 0.2214 Acc: 0.9565\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7879)\n",
      "Train Loss: 0.0469 Acc: 0.9849\n",
      "Val Loss: 0.2154 Acc: 0.9552\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0307 Acc: 0.9904\n",
      "Val Loss: 0.1372 Acc: 0.9702\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0202 Acc: 0.9932\n",
      "Val Loss: 0.1836 Acc: 0.9634\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0226 Acc: 0.9925\n",
      "Val Loss: 0.1342 Acc: 0.9714\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0100 Acc: 0.9965\n",
      "Val Loss: 0.1407 Acc: 0.9733\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0163 Acc: 0.9949\n",
      "Val Loss: 0.2326 Acc: 0.9578\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0270 Acc: 0.9922\n",
      "Val Loss: 0.1965 Acc: 0.9657\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7900)\n",
      "Train Loss: 0.0454 Acc: 0.9875\n",
      "Val Loss: 0.2290 Acc: 0.9596\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0198 Acc: 0.9931\n",
      "Val Loss: 0.1735 Acc: 0.9715\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0159 Acc: 0.9951\n",
      "Val Loss: 0.2140 Acc: 0.9671\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0165 Acc: 0.9954\n",
      "Val Loss: 0.1748 Acc: 0.9700\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0076 Acc: 0.9979\n",
      "Val Loss: 0.1537 Acc: 0.9747\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0031 Acc: 0.9994\n",
      "Val Loss: 0.1482 Acc: 0.9757\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0005 Acc: 0.9999\n",
      "Val Loss: 0.1468 Acc: 0.9758\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1458 Acc: 0.9763\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.976271\n"
     ]
    }
   ],
   "source": [
    "best_net3, best_acc3, last_net3 = train_model(net3, train_q_dl, test_dl, criterion, optimizer3, exp_lr_scheduler_3,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "UVyFZIXLSpP3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6663)\n",
      "Train Loss: 1.4610 Acc: 0.8329\n",
      "Val Loss: 0.1943 Acc: 0.9404\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7703)\n",
      "Train Loss: 0.1217 Acc: 0.9629\n",
      "Val Loss: 0.1621 Acc: 0.9511\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7797)\n",
      "Train Loss: 0.0768 Acc: 0.9746\n",
      "Val Loss: 0.1477 Acc: 0.9557\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7882)\n",
      "Train Loss: 0.0461 Acc: 0.9852\n",
      "Val Loss: 0.1168 Acc: 0.9669\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0361 Acc: 0.9874\n",
      "Val Loss: 0.1140 Acc: 0.9702\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0371 Acc: 0.9869\n",
      "Val Loss: 0.1451 Acc: 0.9627\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0427 Acc: 0.9871\n",
      "Val Loss: 0.1212 Acc: 0.9696\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0267 Acc: 0.9915\n",
      "Val Loss: 0.1211 Acc: 0.9720\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0164 Acc: 0.9949\n",
      "Val Loss: 0.1442 Acc: 0.9685\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0150 Acc: 0.9959\n",
      "Val Loss: 0.1271 Acc: 0.9731\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0239 Acc: 0.9921\n",
      "Val Loss: 0.1649 Acc: 0.9657\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0524 Acc: 0.9860\n",
      "Val Loss: 0.1567 Acc: 0.9664\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0172 Acc: 0.9948\n",
      "Val Loss: 0.1296 Acc: 0.9737\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0067 Acc: 0.9980\n",
      "Val Loss: 0.1216 Acc: 0.9757\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0068 Acc: 0.9976\n",
      "Val Loss: 0.1675 Acc: 0.9696\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0124 Acc: 0.9961\n",
      "Val Loss: 0.1651 Acc: 0.9731\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0150 Acc: 0.9956\n",
      "Val Loss: 0.1437 Acc: 0.9729\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0211 Acc: 0.9940\n",
      "Val Loss: 0.1794 Acc: 0.9697\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0194 Acc: 0.9951\n",
      "Val Loss: 0.1708 Acc: 0.9723\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0109 Acc: 0.9971\n",
      "Val Loss: 0.1826 Acc: 0.9692\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0046 Acc: 0.9985\n",
      "Val Loss: 0.1387 Acc: 0.9764\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0005 Acc: 0.9999\n",
      "Val Loss: 0.1380 Acc: 0.9765\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1374 Acc: 0.9767\n",
      "\n",
      "Training complete in 6m 16s\n",
      "Best val Acc: 0.976725\n"
     ]
    }
   ],
   "source": [
    "best_net4, best_acc4, last_net4 = train_model(net4, train_q_dl, test_dl, criterion, optimizer4, exp_lr_scheduler_4,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "dsg8yfjaTAi4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6493)\n",
      "Train Loss: 1.3658 Acc: 0.8116\n",
      "Val Loss: 0.2026 Acc: 0.9387\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7619)\n",
      "Train Loss: 0.1450 Acc: 0.9524\n",
      "Val Loss: 0.1565 Acc: 0.9523\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7752)\n",
      "Train Loss: 0.0997 Acc: 0.9690\n",
      "Val Loss: 0.1466 Acc: 0.9550\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7815)\n",
      "Train Loss: 0.0657 Acc: 0.9769\n",
      "Val Loss: 0.1593 Acc: 0.9549\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0363 Acc: 0.9878\n",
      "Val Loss: 0.1178 Acc: 0.9683\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0220 Acc: 0.9931\n",
      "Val Loss: 0.1321 Acc: 0.9649\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0328 Acc: 0.9900\n",
      "Val Loss: 0.2041 Acc: 0.9549\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7874)\n",
      "Train Loss: 0.0476 Acc: 0.9842\n",
      "Val Loss: 0.2013 Acc: 0.9584\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0382 Acc: 0.9869\n",
      "Val Loss: 0.1454 Acc: 0.9680\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0384 Acc: 0.9884\n",
      "Val Loss: 0.1993 Acc: 0.9577\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0377 Acc: 0.9891\n",
      "Val Loss: 0.1713 Acc: 0.9665\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0144 Acc: 0.9949\n",
      "Val Loss: 0.1491 Acc: 0.9694\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0079 Acc: 0.9975\n",
      "Val Loss: 0.1763 Acc: 0.9664\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0204 Acc: 0.9941\n",
      "Val Loss: 0.1924 Acc: 0.9636\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0236 Acc: 0.9924\n",
      "Val Loss: 0.1798 Acc: 0.9692\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0305 Acc: 0.9914\n",
      "Val Loss: 0.1786 Acc: 0.9648\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0210 Acc: 0.9941\n",
      "Val Loss: 0.1560 Acc: 0.9695\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0077 Acc: 0.9980\n",
      "Val Loss: 0.1697 Acc: 0.9716\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0139 Acc: 0.9958\n",
      "Val Loss: 0.1723 Acc: 0.9703\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0172 Acc: 0.9945\n",
      "Val Loss: 0.1870 Acc: 0.9681\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0070 Acc: 0.9980\n",
      "Val Loss: 0.1548 Acc: 0.9720\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0014 Acc: 0.9998\n",
      "Val Loss: 0.1508 Acc: 0.9730\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0005 Acc: 0.9999\n",
      "Val Loss: 0.1501 Acc: 0.9733\n",
      "\n",
      "Training complete in 6m 51s\n",
      "Best val Acc: 0.973270\n"
     ]
    }
   ],
   "source": [
    "best_net5, best_acc5, last_net5 = train_model(net5, train_q_dl, test_dl, criterion, optimizer5, exp_lr_scheduler_5,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "9a5on_kCTGLh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6488)\n",
      "Train Loss: 1.4901 Acc: 0.8110\n",
      "Val Loss: 0.2402 Acc: 0.9274\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7597)\n",
      "Train Loss: 0.1595 Acc: 0.9496\n",
      "Val Loss: 0.1825 Acc: 0.9445\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7771)\n",
      "Train Loss: 0.0919 Acc: 0.9714\n",
      "Val Loss: 0.1233 Acc: 0.9628\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7855)\n",
      "Train Loss: 0.0564 Acc: 0.9819\n",
      "Val Loss: 0.1119 Acc: 0.9666\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0342 Acc: 0.9886\n",
      "Val Loss: 0.1316 Acc: 0.9629\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7898)\n",
      "Train Loss: 0.0375 Acc: 0.9872\n",
      "Val Loss: 0.1127 Acc: 0.9707\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0272 Acc: 0.9932\n",
      "Val Loss: 0.1251 Acc: 0.9665\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0308 Acc: 0.9891\n",
      "Val Loss: 0.1555 Acc: 0.9625\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0412 Acc: 0.9864\n",
      "Val Loss: 0.1370 Acc: 0.9678\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0254 Acc: 0.9915\n",
      "Val Loss: 0.1352 Acc: 0.9689\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0134 Acc: 0.9949\n",
      "Val Loss: 0.1396 Acc: 0.9694\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0060 Acc: 0.9984\n",
      "Val Loss: 0.1380 Acc: 0.9742\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0036 Acc: 0.9986\n",
      "Val Loss: 0.1570 Acc: 0.9722\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0162 Acc: 0.9950\n",
      "Val Loss: 0.1814 Acc: 0.9657\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7881)\n",
      "Train Loss: 0.0470 Acc: 0.9851\n",
      "Val Loss: 0.2014 Acc: 0.9603\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0423 Acc: 0.9884\n",
      "Val Loss: 0.1283 Acc: 0.9757\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0211 Acc: 0.9931\n",
      "Val Loss: 0.1844 Acc: 0.9636\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0172 Acc: 0.9940\n",
      "Val Loss: 0.1638 Acc: 0.9718\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0070 Acc: 0.9981\n",
      "Val Loss: 0.1594 Acc: 0.9738\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0048 Acc: 0.9981\n",
      "Val Loss: 0.1659 Acc: 0.9754\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0022 Acc: 0.9989\n",
      "Val Loss: 0.1492 Acc: 0.9788\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1483 Acc: 0.9789\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1476 Acc: 0.9790\n",
      "\n",
      "Training complete in 6m 16s\n",
      "Best val Acc: 0.978998\n"
     ]
    }
   ],
   "source": [
    "best_net6, best_acc6, last_net6 = train_model(net6, train_q_dl, test_dl, criterion, optimizer6, exp_lr_scheduler_6,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "wYaDRIv1TLbK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6873)\n",
      "Train Loss: 0.9582 Acc: 0.8591\n",
      "Val Loss: 0.1947 Acc: 0.9424\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7710)\n",
      "Train Loss: 0.1128 Acc: 0.9637\n",
      "Val Loss: 0.1256 Acc: 0.9591\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7839)\n",
      "Train Loss: 0.0597 Acc: 0.9799\n",
      "Val Loss: 0.1387 Acc: 0.9605\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0322 Acc: 0.9900\n",
      "Val Loss: 0.1225 Acc: 0.9694\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0266 Acc: 0.9914\n",
      "Val Loss: 0.1609 Acc: 0.9592\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0294 Acc: 0.9900\n",
      "Val Loss: 0.1354 Acc: 0.9669\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0144 Acc: 0.9952\n",
      "Val Loss: 0.1421 Acc: 0.9676\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0256 Acc: 0.9914\n",
      "Val Loss: 0.1581 Acc: 0.9649\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0330 Acc: 0.9900\n",
      "Val Loss: 0.2082 Acc: 0.9603\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0301 Acc: 0.9911\n",
      "Val Loss: 0.1248 Acc: 0.9692\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0123 Acc: 0.9955\n",
      "Val Loss: 0.1254 Acc: 0.9735\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0155 Acc: 0.9954\n",
      "Val Loss: 0.1326 Acc: 0.9735\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0188 Acc: 0.9945\n",
      "Val Loss: 0.1867 Acc: 0.9665\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0157 Acc: 0.9964\n",
      "Val Loss: 0.1317 Acc: 0.9740\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0048 Acc: 0.9984\n",
      "Val Loss: 0.1337 Acc: 0.9752\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0049 Acc: 0.9985\n",
      "Val Loss: 0.1623 Acc: 0.9750\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0189 Acc: 0.9951\n",
      "Val Loss: 0.1625 Acc: 0.9727\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0271 Acc: 0.9929\n",
      "Val Loss: 0.1750 Acc: 0.9695\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0342 Acc: 0.9902\n",
      "Val Loss: 0.2328 Acc: 0.9657\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0242 Acc: 0.9929\n",
      "Val Loss: 0.1656 Acc: 0.9746\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0053 Acc: 0.9980\n",
      "Val Loss: 0.1434 Acc: 0.9778\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1420 Acc: 0.9777\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1413 Acc: 0.9778\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.977816\n"
     ]
    }
   ],
   "source": [
    "best_net7, best_acc7, last_net7 = train_model(net7, train_q_dl, test_dl, criterion, optimizer7, exp_lr_scheduler_7,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "HKVw0HeNTQ8g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6520)\n",
      "Train Loss: 1.3165 Acc: 0.8150\n",
      "Val Loss: 0.1886 Acc: 0.9404\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7662)\n",
      "Train Loss: 0.1422 Acc: 0.9577\n",
      "Val Loss: 0.1524 Acc: 0.9545\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7818)\n",
      "Train Loss: 0.0729 Acc: 0.9772\n",
      "Val Loss: 0.1462 Acc: 0.9600\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7838)\n",
      "Train Loss: 0.0647 Acc: 0.9798\n",
      "Val Loss: 0.1165 Acc: 0.9674\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7878)\n",
      "Train Loss: 0.0457 Acc: 0.9848\n",
      "Val Loss: 0.1240 Acc: 0.9662\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7904)\n",
      "Train Loss: 0.0362 Acc: 0.9880\n",
      "Val Loss: 0.1421 Acc: 0.9634\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0232 Acc: 0.9924\n",
      "Val Loss: 0.1650 Acc: 0.9640\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0120 Acc: 0.9964\n",
      "Val Loss: 0.1337 Acc: 0.9725\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0293 Acc: 0.9906\n",
      "Val Loss: 0.1579 Acc: 0.9655\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0255 Acc: 0.9922\n",
      "Val Loss: 0.1544 Acc: 0.9675\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0144 Acc: 0.9955\n",
      "Val Loss: 0.1711 Acc: 0.9665\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0190 Acc: 0.9940\n",
      "Val Loss: 0.1684 Acc: 0.9674\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0398 Acc: 0.9878\n",
      "Val Loss: 0.2805 Acc: 0.9528\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0378 Acc: 0.9886\n",
      "Val Loss: 0.1377 Acc: 0.9740\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0242 Acc: 0.9931\n",
      "Val Loss: 0.1442 Acc: 0.9735\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0259 Acc: 0.9929\n",
      "Val Loss: 0.1660 Acc: 0.9721\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0073 Acc: 0.9976\n",
      "Val Loss: 0.1479 Acc: 0.9751\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0090 Acc: 0.9975\n",
      "Val Loss: 0.1862 Acc: 0.9707\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0243 Acc: 0.9930\n",
      "Val Loss: 0.2188 Acc: 0.9650\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0240 Acc: 0.9942\n",
      "Val Loss: 0.1897 Acc: 0.9694\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0060 Acc: 0.9979\n",
      "Val Loss: 0.1531 Acc: 0.9749\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1505 Acc: 0.9751\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1494 Acc: 0.9754\n",
      "\n",
      "Training complete in 6m 17s\n",
      "Best val Acc: 0.975361\n"
     ]
    }
   ],
   "source": [
    "best_net8, best_acc8, last_net8 = train_model(net8, train_q_dl, test_dl, criterion, optimizer8, exp_lr_scheduler_8,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "6Glt3QtjTWu6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6563)\n",
      "Train Loss: 1.2602 Acc: 0.8204\n",
      "Val Loss: 0.2003 Acc: 0.9389\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7663)\n",
      "Train Loss: 0.1389 Acc: 0.9579\n",
      "Val Loss: 0.1211 Acc: 0.9624\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7802)\n",
      "Train Loss: 0.0747 Acc: 0.9752\n",
      "Val Loss: 0.1558 Acc: 0.9573\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7886)\n",
      "Train Loss: 0.0447 Acc: 0.9858\n",
      "Val Loss: 0.1286 Acc: 0.9675\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7904)\n",
      "Train Loss: 0.0354 Acc: 0.9880\n",
      "Val Loss: 0.1591 Acc: 0.9600\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0263 Acc: 0.9925\n",
      "Val Loss: 0.1128 Acc: 0.9723\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0172 Acc: 0.9939\n",
      "Val Loss: 0.1231 Acc: 0.9692\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0130 Acc: 0.9955\n",
      "Val Loss: 0.1161 Acc: 0.9749\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0348 Acc: 0.9905\n",
      "Val Loss: 0.1438 Acc: 0.9715\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0237 Acc: 0.9922\n",
      "Val Loss: 0.1757 Acc: 0.9651\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0268 Acc: 0.9911\n",
      "Val Loss: 0.1375 Acc: 0.9710\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0186 Acc: 0.9935\n",
      "Val Loss: 0.1552 Acc: 0.9712\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0181 Acc: 0.9941\n",
      "Val Loss: 0.1383 Acc: 0.9732\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0276 Acc: 0.9918\n",
      "Val Loss: 0.1676 Acc: 0.9654\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0326 Acc: 0.9911\n",
      "Val Loss: 0.1151 Acc: 0.9785\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0062 Acc: 0.9976\n",
      "Val Loss: 0.1455 Acc: 0.9744\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0038 Acc: 0.9989\n",
      "Val Loss: 0.1314 Acc: 0.9765\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0018 Acc: 0.9998\n",
      "Val Loss: 0.1151 Acc: 0.9810\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1143 Acc: 0.9813\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1141 Acc: 0.9814\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1141 Acc: 0.9814\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1142 Acc: 0.9814\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1142 Acc: 0.9814\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.981362\n"
     ]
    }
   ],
   "source": [
    "best_net9, best_acc9, last_net9 = train_model(net9, train_q_dl, test_dl, criterion, optimizer9, exp_lr_scheduler_9,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "A0QgSOFbTcT5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6517)\n",
      "Train Loss: 1.2888 Acc: 0.8146\n",
      "Val Loss: 0.2145 Acc: 0.9307\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7650)\n",
      "Train Loss: 0.1368 Acc: 0.9563\n",
      "Val Loss: 0.1511 Acc: 0.9533\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7802)\n",
      "Train Loss: 0.0753 Acc: 0.9752\n",
      "Val Loss: 0.1825 Acc: 0.9498\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7834)\n",
      "Train Loss: 0.0597 Acc: 0.9792\n",
      "Val Loss: 0.1421 Acc: 0.9626\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7866)\n",
      "Train Loss: 0.0447 Acc: 0.9832\n",
      "Val Loss: 0.1862 Acc: 0.9520\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7878)\n",
      "Train Loss: 0.0428 Acc: 0.9848\n",
      "Val Loss: 0.1426 Acc: 0.9663\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0255 Acc: 0.9916\n",
      "Val Loss: 0.1592 Acc: 0.9621\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0386 Acc: 0.9879\n",
      "Val Loss: 0.1516 Acc: 0.9674\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0230 Acc: 0.9922\n",
      "Val Loss: 0.1440 Acc: 0.9676\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0118 Acc: 0.9959\n",
      "Val Loss: 0.1527 Acc: 0.9696\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0078 Acc: 0.9978\n",
      "Val Loss: 0.1443 Acc: 0.9740\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0153 Acc: 0.9958\n",
      "Val Loss: 0.1913 Acc: 0.9664\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7865)\n",
      "Train Loss: 0.0563 Acc: 0.9831\n",
      "Val Loss: 0.1989 Acc: 0.9635\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0414 Acc: 0.9861\n",
      "Val Loss: 0.1392 Acc: 0.9717\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0161 Acc: 0.9945\n",
      "Val Loss: 0.1730 Acc: 0.9668\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0069 Acc: 0.9979\n",
      "Val Loss: 0.1407 Acc: 0.9749\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0105 Acc: 0.9974\n",
      "Val Loss: 0.1571 Acc: 0.9690\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0017 Acc: 0.9994\n",
      "Val Loss: 0.1585 Acc: 0.9748\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0010 Acc: 0.9995\n",
      "Val Loss: 0.1319 Acc: 0.9782\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1309 Acc: 0.9790\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1309 Acc: 0.9790\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1308 Acc: 0.9791\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1308 Acc: 0.9792\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.979180\n"
     ]
    }
   ],
   "source": [
    "best_net10, best_acc10, last_net10 = train_model(net10, train_q_dl, test_dl, criterion, optimizer10, exp_lr_scheduler_10,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "CsnIrhtaSyLH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6273)\n",
      "Train Loss: 1.7765 Acc: 0.7841\n",
      "Val Loss: 0.1910 Acc: 0.9416\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7605)\n",
      "Train Loss: 0.1567 Acc: 0.9506\n",
      "Val Loss: 0.1675 Acc: 0.9507\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7703)\n",
      "Train Loss: 0.1104 Acc: 0.9629\n",
      "Val Loss: 0.1530 Acc: 0.9555\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7811)\n",
      "Train Loss: 0.0652 Acc: 0.9764\n",
      "Val Loss: 0.1510 Acc: 0.9597\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7858)\n",
      "Train Loss: 0.0523 Acc: 0.9822\n",
      "Val Loss: 0.1622 Acc: 0.9570\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7876)\n",
      "Train Loss: 0.0476 Acc: 0.9845\n",
      "Val Loss: 0.1333 Acc: 0.9669\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0168 Acc: 0.9948\n",
      "Val Loss: 0.1442 Acc: 0.9691\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0210 Acc: 0.9922\n",
      "Val Loss: 0.1588 Acc: 0.9664\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0380 Acc: 0.9886\n",
      "Val Loss: 0.1743 Acc: 0.9609\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0373 Acc: 0.9869\n",
      "Val Loss: 0.1557 Acc: 0.9675\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0318 Acc: 0.9891\n",
      "Val Loss: 0.1863 Acc: 0.9641\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7877)\n",
      "Train Loss: 0.0544 Acc: 0.9846\n",
      "Val Loss: 0.2091 Acc: 0.9569\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0290 Acc: 0.9910\n",
      "Val Loss: 0.1592 Acc: 0.9688\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7978)\n",
      "Train Loss: 0.0104 Acc: 0.9972\n",
      "Val Loss: 0.1508 Acc: 0.9715\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0055 Acc: 0.9980\n",
      "Val Loss: 0.1566 Acc: 0.9708\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0023 Acc: 0.9995\n",
      "Val Loss: 0.1443 Acc: 0.9745\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0020 Acc: 0.9995\n",
      "Val Loss: 0.1647 Acc: 0.9719\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1509 Acc: 0.9763\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1512 Acc: 0.9755\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1513 Acc: 0.9759\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1514 Acc: 0.9759\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1514 Acc: 0.9760\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1515 Acc: 0.9760\n",
      "\n",
      "Training complete in 6m 17s\n",
      "Best val Acc: 0.976271\n"
     ]
    }
   ],
   "source": [
    "best_net11, best_acc11, last_net11 = train_model(net11, train_r1_dl, test_dl, criterion, optimizer11, exp_lr_scheduler_11,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "T9VmBfEiTzG4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6733)\n",
      "Train Loss: 1.0043 Acc: 0.8416\n",
      "Val Loss: 0.1645 Acc: 0.9510\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7724)\n",
      "Train Loss: 0.1087 Acc: 0.9655\n",
      "Val Loss: 0.1244 Acc: 0.9646\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7823)\n",
      "Train Loss: 0.0645 Acc: 0.9779\n",
      "Val Loss: 0.1161 Acc: 0.9672\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0507 Acc: 0.9835\n",
      "Val Loss: 0.1314 Acc: 0.9667\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0293 Acc: 0.9900\n",
      "Val Loss: 0.1718 Acc: 0.9559\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0325 Acc: 0.9878\n",
      "Val Loss: 0.1321 Acc: 0.9675\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0305 Acc: 0.9895\n",
      "Val Loss: 0.1626 Acc: 0.9627\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0319 Acc: 0.9908\n",
      "Val Loss: 0.1357 Acc: 0.9695\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0174 Acc: 0.9934\n",
      "Val Loss: 0.1826 Acc: 0.9616\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0169 Acc: 0.9949\n",
      "Val Loss: 0.1569 Acc: 0.9713\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0353 Acc: 0.9892\n",
      "Val Loss: 0.1729 Acc: 0.9658\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0267 Acc: 0.9921\n",
      "Val Loss: 0.1679 Acc: 0.9706\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0220 Acc: 0.9934\n",
      "Val Loss: 0.1363 Acc: 0.9716\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0109 Acc: 0.9965\n",
      "Val Loss: 0.1371 Acc: 0.9764\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0160 Acc: 0.9951\n",
      "Val Loss: 0.1377 Acc: 0.9754\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0092 Acc: 0.9971\n",
      "Val Loss: 0.1295 Acc: 0.9762\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0086 Acc: 0.9975\n",
      "Val Loss: 0.1595 Acc: 0.9734\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0014 Acc: 0.9998\n",
      "Val Loss: 0.1264 Acc: 0.9777\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1206 Acc: 0.9804\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1208 Acc: 0.9805\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1209 Acc: 0.9805\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1209 Acc: 0.9805\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1209 Acc: 0.9805\n",
      "\n",
      "Training complete in 6m 16s\n",
      "Best val Acc: 0.980453\n"
     ]
    }
   ],
   "source": [
    "best_net12, best_acc12, last_net12 = train_model(net12, train_r2_dl, test_dl, criterion, optimizer12, exp_lr_scheduler_12,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "_lb20TeNWobi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6424)\n",
      "Train Loss: 1.2641 Acc: 0.8030\n",
      "Val Loss: 0.1622 Acc: 0.9515\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7703)\n",
      "Train Loss: 0.1130 Acc: 0.9629\n",
      "Val Loss: 0.1466 Acc: 0.9535\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7834)\n",
      "Train Loss: 0.0658 Acc: 0.9792\n",
      "Val Loss: 0.1266 Acc: 0.9670\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0389 Acc: 0.9878\n",
      "Val Loss: 0.1419 Acc: 0.9612\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0274 Acc: 0.9900\n",
      "Val Loss: 0.1256 Acc: 0.9687\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0209 Acc: 0.9922\n",
      "Val Loss: 0.1378 Acc: 0.9660\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0249 Acc: 0.9911\n",
      "Val Loss: 0.1469 Acc: 0.9661\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0235 Acc: 0.9925\n",
      "Val Loss: 0.1698 Acc: 0.9648\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0256 Acc: 0.9910\n",
      "Val Loss: 0.1613 Acc: 0.9650\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0150 Acc: 0.9952\n",
      "Val Loss: 0.1507 Acc: 0.9704\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0116 Acc: 0.9965\n",
      "Val Loss: 0.1396 Acc: 0.9735\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0231 Acc: 0.9925\n",
      "Val Loss: 0.1892 Acc: 0.9615\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0195 Acc: 0.9945\n",
      "Val Loss: 0.1960 Acc: 0.9671\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0086 Acc: 0.9971\n",
      "Val Loss: 0.1494 Acc: 0.9729\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0231 Acc: 0.9941\n",
      "Val Loss: 0.1537 Acc: 0.9705\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0175 Acc: 0.9940\n",
      "Val Loss: 0.1696 Acc: 0.9691\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0228 Acc: 0.9929\n",
      "Val Loss: 0.1735 Acc: 0.9655\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0155 Acc: 0.9950\n",
      "Val Loss: 0.1934 Acc: 0.9673\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0069 Acc: 0.9979\n",
      "Val Loss: 0.1560 Acc: 0.9724\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0239 Acc: 0.9935\n",
      "Val Loss: 0.1849 Acc: 0.9740\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0071 Acc: 0.9975\n",
      "Val Loss: 0.1541 Acc: 0.9779\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1533 Acc: 0.9775\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1529 Acc: 0.9776\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.977907\n"
     ]
    }
   ],
   "source": [
    "best_net13, best_acc13, last_net13 = train_model(net13, train_r3_dl, test_dl, criterion, optimizer13, exp_lr_scheduler_13,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "pEqZ1Eg3Wz3R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6412)\n",
      "Train Loss: 1.9127 Acc: 0.8015\n",
      "Val Loss: 0.2025 Acc: 0.9362\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7641)\n",
      "Train Loss: 0.1386 Acc: 0.9551\n",
      "Val Loss: 0.1307 Acc: 0.9596\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7793)\n",
      "Train Loss: 0.0752 Acc: 0.9741\n",
      "Val Loss: 0.1593 Acc: 0.9541\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7821)\n",
      "Train Loss: 0.0611 Acc: 0.9776\n",
      "Val Loss: 0.1477 Acc: 0.9606\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7854)\n",
      "Train Loss: 0.0503 Acc: 0.9818\n",
      "Val Loss: 0.1216 Acc: 0.9689\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7884)\n",
      "Train Loss: 0.0419 Acc: 0.9855\n",
      "Val Loss: 0.1286 Acc: 0.9691\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0268 Acc: 0.9905\n",
      "Val Loss: 0.1087 Acc: 0.9748\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0204 Acc: 0.9934\n",
      "Val Loss: 0.1330 Acc: 0.9713\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0125 Acc: 0.9959\n",
      "Val Loss: 0.1291 Acc: 0.9702\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0138 Acc: 0.9958\n",
      "Val Loss: 0.1466 Acc: 0.9677\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0203 Acc: 0.9935\n",
      "Val Loss: 0.1285 Acc: 0.9718\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0234 Acc: 0.9926\n",
      "Val Loss: 0.1543 Acc: 0.9670\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0165 Acc: 0.9948\n",
      "Val Loss: 0.1291 Acc: 0.9734\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0155 Acc: 0.9958\n",
      "Val Loss: 0.1568 Acc: 0.9699\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0450 Acc: 0.9864\n",
      "Val Loss: 0.2250 Acc: 0.9513\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0366 Acc: 0.9891\n",
      "Val Loss: 0.1689 Acc: 0.9675\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0434 Acc: 0.9879\n",
      "Val Loss: 0.2091 Acc: 0.9605\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0312 Acc: 0.9896\n",
      "Val Loss: 0.1307 Acc: 0.9757\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0092 Acc: 0.9969\n",
      "Val Loss: 0.1429 Acc: 0.9769\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0028 Acc: 0.9994\n",
      "Val Loss: 0.1695 Acc: 0.9707\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7992)\n",
      "Train Loss: 0.0035 Acc: 0.9990\n",
      "Val Loss: 0.1362 Acc: 0.9776\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1349 Acc: 0.9784\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1342 Acc: 0.9785\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.978544\n"
     ]
    }
   ],
   "source": [
    "best_net14, best_acc14, last_net14 = train_model(net14, train_r4_dl, test_dl, criterion, optimizer14, exp_lr_scheduler_14,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "MAQEREI2W5me"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6414)\n",
      "Train Loss: 1.6887 Acc: 0.8017\n",
      "Val Loss: 0.1890 Acc: 0.9416\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7599)\n",
      "Train Loss: 0.1578 Acc: 0.9499\n",
      "Val Loss: 0.1820 Acc: 0.9447\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7734)\n",
      "Train Loss: 0.0974 Acc: 0.9667\n",
      "Val Loss: 0.1425 Acc: 0.9575\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7804)\n",
      "Train Loss: 0.0738 Acc: 0.9755\n",
      "Val Loss: 0.1337 Acc: 0.9628\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0451 Acc: 0.9854\n",
      "Val Loss: 0.1468 Acc: 0.9632\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0390 Acc: 0.9878\n",
      "Val Loss: 0.1453 Acc: 0.9636\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0443 Acc: 0.9854\n",
      "Val Loss: 0.1532 Acc: 0.9621\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0322 Acc: 0.9888\n",
      "Val Loss: 0.1376 Acc: 0.9693\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0170 Acc: 0.9942\n",
      "Val Loss: 0.1590 Acc: 0.9665\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7919)\n",
      "Train Loss: 0.0337 Acc: 0.9899\n",
      "Val Loss: 0.2551 Acc: 0.9501\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0330 Acc: 0.9882\n",
      "Val Loss: 0.1524 Acc: 0.9666\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0199 Acc: 0.9934\n",
      "Val Loss: 0.1735 Acc: 0.9678\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0112 Acc: 0.9965\n",
      "Val Loss: 0.1697 Acc: 0.9707\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0290 Acc: 0.9922\n",
      "Val Loss: 0.1899 Acc: 0.9636\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0322 Acc: 0.9906\n",
      "Val Loss: 0.1809 Acc: 0.9635\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0207 Acc: 0.9932\n",
      "Val Loss: 0.1842 Acc: 0.9645\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0333 Acc: 0.9900\n",
      "Val Loss: 0.2110 Acc: 0.9669\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0137 Acc: 0.9952\n",
      "Val Loss: 0.2115 Acc: 0.9678\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0196 Acc: 0.9942\n",
      "Val Loss: 0.2116 Acc: 0.9642\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0124 Acc: 0.9965\n",
      "Val Loss: 0.2494 Acc: 0.9642\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0062 Acc: 0.9982\n",
      "Val Loss: 0.1866 Acc: 0.9720\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1844 Acc: 0.9719\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1831 Acc: 0.9722\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.972179\n"
     ]
    }
   ],
   "source": [
    "best_net15, best_acc15, last_net15 = train_model(net15, train_r5_dl, test_dl, criterion, optimizer15, exp_lr_scheduler_15,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "nFoeSdsVUJ-5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6556)\n",
      "Train Loss: 1.0878 Acc: 0.8195\n",
      "Val Loss: 0.1744 Acc: 0.9457\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7665)\n",
      "Train Loss: 0.1254 Acc: 0.9581\n",
      "Val Loss: 0.1276 Acc: 0.9600\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7828)\n",
      "Train Loss: 0.0656 Acc: 0.9785\n",
      "Val Loss: 0.1109 Acc: 0.9692\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7871)\n",
      "Train Loss: 0.0472 Acc: 0.9839\n",
      "Val Loss: 0.1386 Acc: 0.9654\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7851)\n",
      "Train Loss: 0.0489 Acc: 0.9814\n",
      "Val Loss: 0.1234 Acc: 0.9685\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0249 Acc: 0.9916\n",
      "Val Loss: 0.1085 Acc: 0.9722\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0157 Acc: 0.9951\n",
      "Val Loss: 0.1303 Acc: 0.9685\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0267 Acc: 0.9915\n",
      "Val Loss: 0.1867 Acc: 0.9609\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0278 Acc: 0.9912\n",
      "Val Loss: 0.1273 Acc: 0.9715\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0236 Acc: 0.9929\n",
      "Val Loss: 0.1318 Acc: 0.9704\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0110 Acc: 0.9968\n",
      "Val Loss: 0.1360 Acc: 0.9730\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0196 Acc: 0.9935\n",
      "Val Loss: 0.1926 Acc: 0.9671\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0342 Acc: 0.9891\n",
      "Val Loss: 0.1447 Acc: 0.9717\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0205 Acc: 0.9932\n",
      "Val Loss: 0.1467 Acc: 0.9727\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0264 Acc: 0.9915\n",
      "Val Loss: 0.1657 Acc: 0.9708\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0136 Acc: 0.9954\n",
      "Val Loss: 0.1466 Acc: 0.9731\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0077 Acc: 0.9981\n",
      "Val Loss: 0.1710 Acc: 0.9729\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0362 Acc: 0.9896\n",
      "Val Loss: 0.2025 Acc: 0.9653\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0256 Acc: 0.9928\n",
      "Val Loss: 0.1904 Acc: 0.9681\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0219 Acc: 0.9925\n",
      "Val Loss: 0.1840 Acc: 0.9715\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0055 Acc: 0.9985\n",
      "Val Loss: 0.1522 Acc: 0.9768\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0006 Acc: 0.9999\n",
      "Val Loss: 0.1495 Acc: 0.9771\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1487 Acc: 0.9776\n",
      "\n",
      "Training complete in 6m 16s\n",
      "Best val Acc: 0.977634\n"
     ]
    }
   ],
   "source": [
    "best_net16, best_acc16, last_net16 = train_model(net16, train_r6_dl, test_dl, criterion, optimizer16, exp_lr_scheduler_16,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "T7M0XEjnURLh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6675)\n",
      "Train Loss: 1.4429 Acc: 0.8344\n",
      "Val Loss: 0.2190 Acc: 0.9347\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7675)\n",
      "Train Loss: 0.1262 Acc: 0.9594\n",
      "Val Loss: 0.1652 Acc: 0.9573\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7791)\n",
      "Train Loss: 0.0817 Acc: 0.9739\n",
      "Val Loss: 0.1484 Acc: 0.9588\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7853)\n",
      "Train Loss: 0.0565 Acc: 0.9816\n",
      "Val Loss: 0.1613 Acc: 0.9581\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0411 Acc: 0.9854\n",
      "Val Loss: 0.1652 Acc: 0.9601\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0218 Acc: 0.9924\n",
      "Val Loss: 0.1711 Acc: 0.9659\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7898)\n",
      "Train Loss: 0.0389 Acc: 0.9872\n",
      "Val Loss: 0.1472 Acc: 0.9655\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0361 Acc: 0.9885\n",
      "Val Loss: 0.1720 Acc: 0.9642\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0252 Acc: 0.9930\n",
      "Val Loss: 0.1547 Acc: 0.9674\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0187 Acc: 0.9942\n",
      "Val Loss: 0.1817 Acc: 0.9667\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0246 Acc: 0.9912\n",
      "Val Loss: 0.2151 Acc: 0.9655\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0171 Acc: 0.9940\n",
      "Val Loss: 0.1624 Acc: 0.9725\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0264 Acc: 0.9911\n",
      "Val Loss: 0.2412 Acc: 0.9541\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0388 Acc: 0.9889\n",
      "Val Loss: 0.2185 Acc: 0.9655\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0225 Acc: 0.9930\n",
      "Val Loss: 0.1856 Acc: 0.9695\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0160 Acc: 0.9946\n",
      "Val Loss: 0.1859 Acc: 0.9718\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0160 Acc: 0.9954\n",
      "Val Loss: 0.2112 Acc: 0.9705\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0245 Acc: 0.9930\n",
      "Val Loss: 0.2056 Acc: 0.9657\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7978)\n",
      "Train Loss: 0.0082 Acc: 0.9972\n",
      "Val Loss: 0.1761 Acc: 0.9733\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0081 Acc: 0.9975\n",
      "Val Loss: 0.1547 Acc: 0.9755\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0007 Acc: 0.9999\n",
      "Val Loss: 0.1508 Acc: 0.9760\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1499 Acc: 0.9762\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1493 Acc: 0.9763\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.976271\n"
     ]
    }
   ],
   "source": [
    "best_net17, best_acc17, last_net17 = train_model(net17, train_r7_dl, test_dl, criterion, optimizer17, exp_lr_scheduler_17,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "46jUYaNXUXU4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6594)\n",
      "Train Loss: 1.3010 Acc: 0.8243\n",
      "Val Loss: 0.1570 Acc: 0.9537\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7717)\n",
      "Train Loss: 0.1095 Acc: 0.9646\n",
      "Val Loss: 0.1507 Acc: 0.9536\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7859)\n",
      "Train Loss: 0.0561 Acc: 0.9824\n",
      "Val Loss: 0.1311 Acc: 0.9630\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7836)\n",
      "Train Loss: 0.0575 Acc: 0.9795\n",
      "Val Loss: 0.1061 Acc: 0.9713\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0383 Acc: 0.9861\n",
      "Val Loss: 0.1172 Acc: 0.9716\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0207 Acc: 0.9918\n",
      "Val Loss: 0.1279 Acc: 0.9696\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0172 Acc: 0.9944\n",
      "Val Loss: 0.1326 Acc: 0.9702\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0119 Acc: 0.9964\n",
      "Val Loss: 0.1302 Acc: 0.9716\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0195 Acc: 0.9938\n",
      "Val Loss: 0.1403 Acc: 0.9697\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0195 Acc: 0.9942\n",
      "Val Loss: 0.1325 Acc: 0.9725\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0236 Acc: 0.9938\n",
      "Val Loss: 0.1600 Acc: 0.9749\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7880)\n",
      "Train Loss: 0.0509 Acc: 0.9850\n",
      "Val Loss: 0.2797 Acc: 0.9441\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0539 Acc: 0.9854\n",
      "Val Loss: 0.1295 Acc: 0.9737\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0097 Acc: 0.9969\n",
      "Val Loss: 0.1056 Acc: 0.9787\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0009 Acc: 0.9999\n",
      "Val Loss: 0.1148 Acc: 0.9789\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1109 Acc: 0.9798\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1114 Acc: 0.9803\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1117 Acc: 0.9799\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1120 Acc: 0.9800\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1125 Acc: 0.9801\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1125 Acc: 0.9801\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1125 Acc: 0.9800\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1126 Acc: 0.9800\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.980271\n"
     ]
    }
   ],
   "source": [
    "best_net18, best_acc18, last_net18 = train_model(net18, train_r8_dl, test_dl, criterion, optimizer18, exp_lr_scheduler_18,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "4toDC5SFUe3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6237)\n",
      "Train Loss: 1.2629 Acc: 0.7796\n",
      "Val Loss: 0.1897 Acc: 0.9448\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7692)\n",
      "Train Loss: 0.1123 Acc: 0.9615\n",
      "Val Loss: 0.1397 Acc: 0.9615\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7797)\n",
      "Train Loss: 0.0729 Acc: 0.9746\n",
      "Val Loss: 0.1297 Acc: 0.9658\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7854)\n",
      "Train Loss: 0.0532 Acc: 0.9818\n",
      "Val Loss: 0.1887 Acc: 0.9479\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7880)\n",
      "Train Loss: 0.0411 Acc: 0.9850\n",
      "Val Loss: 0.1351 Acc: 0.9681\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0259 Acc: 0.9912\n",
      "Val Loss: 0.1247 Acc: 0.9720\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0159 Acc: 0.9948\n",
      "Val Loss: 0.1625 Acc: 0.9672\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0138 Acc: 0.9944\n",
      "Val Loss: 0.1665 Acc: 0.9657\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0366 Acc: 0.9889\n",
      "Val Loss: 0.1439 Acc: 0.9690\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0210 Acc: 0.9925\n",
      "Val Loss: 0.1763 Acc: 0.9686\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0316 Acc: 0.9902\n",
      "Val Loss: 0.1795 Acc: 0.9685\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0272 Acc: 0.9911\n",
      "Val Loss: 0.1890 Acc: 0.9677\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0242 Acc: 0.9915\n",
      "Val Loss: 0.1725 Acc: 0.9717\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0233 Acc: 0.9926\n",
      "Val Loss: 0.1744 Acc: 0.9701\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0100 Acc: 0.9964\n",
      "Val Loss: 0.1696 Acc: 0.9701\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0066 Acc: 0.9978\n",
      "Val Loss: 0.1796 Acc: 0.9737\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0303 Acc: 0.9918\n",
      "Val Loss: 0.2170 Acc: 0.9697\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0226 Acc: 0.9924\n",
      "Val Loss: 0.2284 Acc: 0.9653\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0223 Acc: 0.9935\n",
      "Val Loss: 0.2175 Acc: 0.9683\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0135 Acc: 0.9960\n",
      "Val Loss: 0.1803 Acc: 0.9734\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0039 Acc: 0.9991\n",
      "Val Loss: 0.1623 Acc: 0.9765\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0012 Acc: 0.9998\n",
      "Val Loss: 0.1606 Acc: 0.9767\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1599 Acc: 0.9773\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.977271\n"
     ]
    }
   ],
   "source": [
    "best_net19, best_acc19, last_net19 = train_model(net19, train_r9_dl, test_dl, criterion, optimizer19, exp_lr_scheduler_19,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "rojnzpqWUoYD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6304)\n",
      "Train Loss: 1.4458 Acc: 0.7880\n",
      "Val Loss: 0.1972 Acc: 0.9380\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7661)\n",
      "Train Loss: 0.1400 Acc: 0.9576\n",
      "Val Loss: 0.1712 Acc: 0.9462\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7801)\n",
      "Train Loss: 0.0818 Acc: 0.9751\n",
      "Val Loss: 0.1207 Acc: 0.9625\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7861)\n",
      "Train Loss: 0.0508 Acc: 0.9826\n",
      "Val Loss: 0.1342 Acc: 0.9619\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0334 Acc: 0.9879\n",
      "Val Loss: 0.1152 Acc: 0.9703\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0393 Acc: 0.9876\n",
      "Val Loss: 0.1564 Acc: 0.9615\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0278 Acc: 0.9915\n",
      "Val Loss: 0.1293 Acc: 0.9675\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0269 Acc: 0.9914\n",
      "Val Loss: 0.1293 Acc: 0.9680\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0214 Acc: 0.9918\n",
      "Val Loss: 0.1344 Acc: 0.9711\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0265 Acc: 0.9925\n",
      "Val Loss: 0.1725 Acc: 0.9670\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0222 Acc: 0.9928\n",
      "Val Loss: 0.1580 Acc: 0.9680\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0201 Acc: 0.9932\n",
      "Val Loss: 0.1917 Acc: 0.9639\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0375 Acc: 0.9888\n",
      "Val Loss: 0.1917 Acc: 0.9623\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0213 Acc: 0.9925\n",
      "Val Loss: 0.1756 Acc: 0.9657\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0294 Acc: 0.9922\n",
      "Val Loss: 0.2062 Acc: 0.9647\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0194 Acc: 0.9944\n",
      "Val Loss: 0.1856 Acc: 0.9658\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0171 Acc: 0.9948\n",
      "Val Loss: 0.1803 Acc: 0.9687\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0109 Acc: 0.9962\n",
      "Val Loss: 0.1457 Acc: 0.9741\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0121 Acc: 0.9976\n",
      "Val Loss: 0.1452 Acc: 0.9765\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0158 Acc: 0.9951\n",
      "Val Loss: 0.1582 Acc: 0.9726\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7992)\n",
      "Train Loss: 0.0037 Acc: 0.9990\n",
      "Val Loss: 0.1405 Acc: 0.9754\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1373 Acc: 0.9761\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1358 Acc: 0.9766\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.976634\n"
     ]
    }
   ],
   "source": [
    "best_net20, best_acc20, last_net20 = train_model(net20, train_r10_dl, test_dl, criterion, optimizer20, exp_lr_scheduler_20,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "OYRDeop1P7Jf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6464)\n",
      "Train Loss: 1.5580 Acc: 0.8080\n",
      "Val Loss: 0.2075 Acc: 0.9339\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7639)\n",
      "Train Loss: 0.1447 Acc: 0.9549\n",
      "Val Loss: 0.1817 Acc: 0.9441\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7775)\n",
      "Train Loss: 0.0863 Acc: 0.9719\n",
      "Val Loss: 0.1590 Acc: 0.9525\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7818)\n",
      "Train Loss: 0.0715 Acc: 0.9772\n",
      "Val Loss: 0.1305 Acc: 0.9631\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0403 Acc: 0.9864\n",
      "Val Loss: 0.1774 Acc: 0.9563\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7876)\n",
      "Train Loss: 0.0457 Acc: 0.9845\n",
      "Val Loss: 0.2093 Acc: 0.9561\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7885)\n",
      "Train Loss: 0.0442 Acc: 0.9856\n",
      "Val Loss: 0.1622 Acc: 0.9600\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0376 Acc: 0.9861\n",
      "Val Loss: 0.1852 Acc: 0.9588\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0202 Acc: 0.9932\n",
      "Val Loss: 0.1911 Acc: 0.9598\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0164 Acc: 0.9954\n",
      "Val Loss: 0.1855 Acc: 0.9641\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7919)\n",
      "Train Loss: 0.0297 Acc: 0.9899\n",
      "Val Loss: 0.2078 Acc: 0.9602\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0256 Acc: 0.9914\n",
      "Val Loss: 0.1948 Acc: 0.9645\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0215 Acc: 0.9938\n",
      "Val Loss: 0.1532 Acc: 0.9690\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0118 Acc: 0.9960\n",
      "Val Loss: 0.1475 Acc: 0.9716\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0089 Acc: 0.9979\n",
      "Val Loss: 0.1483 Acc: 0.9710\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0301 Acc: 0.9908\n",
      "Val Loss: 0.1705 Acc: 0.9681\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0200 Acc: 0.9940\n",
      "Val Loss: 0.1859 Acc: 0.9669\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0196 Acc: 0.9944\n",
      "Val Loss: 0.2100 Acc: 0.9621\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0207 Acc: 0.9945\n",
      "Val Loss: 0.2015 Acc: 0.9657\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0175 Acc: 0.9949\n",
      "Val Loss: 0.1800 Acc: 0.9708\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0050 Acc: 0.9984\n",
      "Val Loss: 0.1693 Acc: 0.9735\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1661 Acc: 0.9735\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1647 Acc: 0.9739\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.973907\n"
     ]
    }
   ],
   "source": [
    "best_net21, best_acc21, last_net21 = train_model(net21, train_s1_dl, test_dl, criterion, optimizer21, exp_lr_scheduler_21,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "coyDk4PlQCCi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6518)\n",
      "Train Loss: 1.3822 Acc: 0.8147\n",
      "Val Loss: 0.2049 Acc: 0.9344\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7661)\n",
      "Train Loss: 0.1298 Acc: 0.9576\n",
      "Val Loss: 0.1448 Acc: 0.9551\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7818)\n",
      "Train Loss: 0.0691 Acc: 0.9772\n",
      "Val Loss: 0.1302 Acc: 0.9661\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7873)\n",
      "Train Loss: 0.0520 Acc: 0.9841\n",
      "Val Loss: 0.1525 Acc: 0.9603\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7862)\n",
      "Train Loss: 0.0490 Acc: 0.9828\n",
      "Val Loss: 0.1179 Acc: 0.9684\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0249 Acc: 0.9911\n",
      "Val Loss: 0.1439 Acc: 0.9649\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0244 Acc: 0.9924\n",
      "Val Loss: 0.1421 Acc: 0.9683\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0285 Acc: 0.9912\n",
      "Val Loss: 0.1792 Acc: 0.9647\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7875)\n",
      "Train Loss: 0.0561 Acc: 0.9844\n",
      "Val Loss: 0.1362 Acc: 0.9680\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0264 Acc: 0.9920\n",
      "Val Loss: 0.1504 Acc: 0.9695\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0168 Acc: 0.9946\n",
      "Val Loss: 0.1415 Acc: 0.9730\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0141 Acc: 0.9952\n",
      "Val Loss: 0.1418 Acc: 0.9726\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0059 Acc: 0.9981\n",
      "Val Loss: 0.1269 Acc: 0.9744\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0017 Acc: 0.9995\n",
      "Val Loss: 0.1293 Acc: 0.9764\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0037 Acc: 0.9989\n",
      "Val Loss: 0.1594 Acc: 0.9745\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0302 Acc: 0.9915\n",
      "Val Loss: 0.2026 Acc: 0.9648\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0434 Acc: 0.9864\n",
      "Val Loss: 0.1639 Acc: 0.9699\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0431 Acc: 0.9879\n",
      "Val Loss: 0.1506 Acc: 0.9697\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0266 Acc: 0.9921\n",
      "Val Loss: 0.1718 Acc: 0.9665\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0187 Acc: 0.9946\n",
      "Val Loss: 0.1330 Acc: 0.9753\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0038 Acc: 0.9986\n",
      "Val Loss: 0.1190 Acc: 0.9786\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0007 Acc: 1.0000\n",
      "Val Loss: 0.1190 Acc: 0.9790\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1192 Acc: 0.9790\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.978998\n"
     ]
    }
   ],
   "source": [
    "best_net22, best_acc22, last_net22 = train_model(net22, train_s2_dl, test_dl, criterion, optimizer22, exp_lr_scheduler_22,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "l9oaHMrvQalM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(5810)\n",
      "Train Loss: 1.8097 Acc: 0.7262\n",
      "Val Loss: 0.2434 Acc: 0.9249\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7631)\n",
      "Train Loss: 0.1570 Acc: 0.9539\n",
      "Val Loss: 0.1535 Acc: 0.9503\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7764)\n",
      "Train Loss: 0.0882 Acc: 0.9705\n",
      "Val Loss: 0.1401 Acc: 0.9592\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7834)\n",
      "Train Loss: 0.0633 Acc: 0.9792\n",
      "Val Loss: 0.1381 Acc: 0.9601\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7878)\n",
      "Train Loss: 0.0446 Acc: 0.9848\n",
      "Val Loss: 0.1588 Acc: 0.9575\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7919)\n",
      "Train Loss: 0.0329 Acc: 0.9899\n",
      "Val Loss: 0.1651 Acc: 0.9555\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0389 Acc: 0.9861\n",
      "Val Loss: 0.1595 Acc: 0.9641\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0184 Acc: 0.9935\n",
      "Val Loss: 0.1309 Acc: 0.9697\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0183 Acc: 0.9934\n",
      "Val Loss: 0.1452 Acc: 0.9663\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0081 Acc: 0.9979\n",
      "Val Loss: 0.1511 Acc: 0.9680\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0121 Acc: 0.9958\n",
      "Val Loss: 0.2335 Acc: 0.9554\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7894)\n",
      "Train Loss: 0.0411 Acc: 0.9868\n",
      "Val Loss: 0.1659 Acc: 0.9649\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0289 Acc: 0.9898\n",
      "Val Loss: 0.1789 Acc: 0.9641\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0233 Acc: 0.9919\n",
      "Val Loss: 0.1736 Acc: 0.9630\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0191 Acc: 0.9936\n",
      "Val Loss: 0.1454 Acc: 0.9722\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0067 Acc: 0.9979\n",
      "Val Loss: 0.1604 Acc: 0.9708\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0152 Acc: 0.9959\n",
      "Val Loss: 0.1689 Acc: 0.9668\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0130 Acc: 0.9950\n",
      "Val Loss: 0.1981 Acc: 0.9680\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0313 Acc: 0.9915\n",
      "Val Loss: 0.2469 Acc: 0.9519\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0391 Acc: 0.9891\n",
      "Val Loss: 0.2333 Acc: 0.9571\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0110 Acc: 0.9965\n",
      "Val Loss: 0.1592 Acc: 0.9719\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0008 Acc: 1.0000\n",
      "Val Loss: 0.1544 Acc: 0.9725\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1538 Acc: 0.9730\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.972998\n"
     ]
    }
   ],
   "source": [
    "best_net23, best_acc23, last_net23 = train_model(net23, train_s3_dl, test_dl, criterion, optimizer23, exp_lr_scheduler_23,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "cufzYPUjQgUF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6421)\n",
      "Train Loss: 1.8369 Acc: 0.8026\n",
      "Val Loss: 0.1914 Acc: 0.9403\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7669)\n",
      "Train Loss: 0.1282 Acc: 0.9586\n",
      "Val Loss: 0.1567 Acc: 0.9554\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7771)\n",
      "Train Loss: 0.0852 Acc: 0.9714\n",
      "Val Loss: 0.1306 Acc: 0.9623\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7825)\n",
      "Train Loss: 0.0622 Acc: 0.9781\n",
      "Val Loss: 0.1265 Acc: 0.9634\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0406 Acc: 0.9860\n",
      "Val Loss: 0.1406 Acc: 0.9655\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0335 Acc: 0.9892\n",
      "Val Loss: 0.1403 Acc: 0.9695\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0311 Acc: 0.9901\n",
      "Val Loss: 0.1536 Acc: 0.9635\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0264 Acc: 0.9901\n",
      "Val Loss: 0.1678 Acc: 0.9637\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0272 Acc: 0.9906\n",
      "Val Loss: 0.1624 Acc: 0.9654\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0224 Acc: 0.9912\n",
      "Val Loss: 0.1453 Acc: 0.9697\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0129 Acc: 0.9960\n",
      "Val Loss: 0.1703 Acc: 0.9618\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0311 Acc: 0.9906\n",
      "Val Loss: 0.1406 Acc: 0.9718\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0227 Acc: 0.9930\n",
      "Val Loss: 0.1739 Acc: 0.9668\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0257 Acc: 0.9922\n",
      "Val Loss: 0.1369 Acc: 0.9743\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0149 Acc: 0.9955\n",
      "Val Loss: 0.1389 Acc: 0.9713\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0049 Acc: 0.9985\n",
      "Val Loss: 0.1254 Acc: 0.9758\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0062 Acc: 0.9981\n",
      "Val Loss: 0.1614 Acc: 0.9726\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0161 Acc: 0.9948\n",
      "Val Loss: 0.1911 Acc: 0.9678\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0382 Acc: 0.9911\n",
      "Val Loss: 0.1942 Acc: 0.9658\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0307 Acc: 0.9915\n",
      "Val Loss: 0.1604 Acc: 0.9713\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0066 Acc: 0.9976\n",
      "Val Loss: 0.1388 Acc: 0.9751\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0011 Acc: 0.9998\n",
      "Val Loss: 0.1395 Acc: 0.9751\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1386 Acc: 0.9755\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.975816\n"
     ]
    }
   ],
   "source": [
    "best_net24, best_acc24, last_net24 = train_model(net24, train_s4_dl, test_dl, criterion, optimizer24, exp_lr_scheduler_24,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "2grAtf0UaYCs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6521)\n",
      "Train Loss: 1.5110 Acc: 0.8151\n",
      "Val Loss: 0.1927 Acc: 0.9396\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7613)\n",
      "Train Loss: 0.1557 Acc: 0.9516\n",
      "Val Loss: 0.1639 Acc: 0.9499\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7780)\n",
      "Train Loss: 0.0844 Acc: 0.9725\n",
      "Val Loss: 0.1440 Acc: 0.9601\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7813)\n",
      "Train Loss: 0.0677 Acc: 0.9766\n",
      "Val Loss: 0.1749 Acc: 0.9531\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7864)\n",
      "Train Loss: 0.0490 Acc: 0.9830\n",
      "Val Loss: 0.1835 Acc: 0.9537\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7884)\n",
      "Train Loss: 0.0436 Acc: 0.9855\n",
      "Val Loss: 0.1418 Acc: 0.9645\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7880)\n",
      "Train Loss: 0.0412 Acc: 0.9850\n",
      "Val Loss: 0.1564 Acc: 0.9644\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7894)\n",
      "Train Loss: 0.0372 Acc: 0.9868\n",
      "Val Loss: 0.2006 Acc: 0.9545\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0315 Acc: 0.9895\n",
      "Val Loss: 0.1432 Acc: 0.9675\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0109 Acc: 0.9962\n",
      "Val Loss: 0.1522 Acc: 0.9688\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0127 Acc: 0.9960\n",
      "Val Loss: 0.1678 Acc: 0.9675\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0115 Acc: 0.9968\n",
      "Val Loss: 0.2513 Acc: 0.9574\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0202 Acc: 0.9950\n",
      "Val Loss: 0.1565 Acc: 0.9698\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0062 Acc: 0.9981\n",
      "Val Loss: 0.1913 Acc: 0.9652\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7978)\n",
      "Train Loss: 0.0075 Acc: 0.9972\n",
      "Val Loss: 0.1601 Acc: 0.9710\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7893)\n",
      "Train Loss: 0.0470 Acc: 0.9866\n",
      "Val Loss: 0.2734 Acc: 0.9565\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7865)\n",
      "Train Loss: 0.0676 Acc: 0.9831\n",
      "Val Loss: 0.2371 Acc: 0.9535\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0315 Acc: 0.9905\n",
      "Val Loss: 0.1892 Acc: 0.9637\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0133 Acc: 0.9959\n",
      "Val Loss: 0.2025 Acc: 0.9670\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0043 Acc: 0.9988\n",
      "Val Loss: 0.1574 Acc: 0.9765\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0028 Acc: 0.9991\n",
      "Val Loss: 0.1473 Acc: 0.9770\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1472 Acc: 0.9771\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1474 Acc: 0.9773\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.977271\n"
     ]
    }
   ],
   "source": [
    "best_net25, best_acc25, last_net25 = train_model(net25, train_s5_dl, test_dl, criterion, optimizer25, exp_lr_scheduler_25,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "HP6TZCYmaePD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6486)\n",
      "Train Loss: 1.5653 Acc: 0.8107\n",
      "Val Loss: 0.2396 Acc: 0.9274\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7616)\n",
      "Train Loss: 0.1404 Acc: 0.9520\n",
      "Val Loss: 0.1903 Acc: 0.9443\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7785)\n",
      "Train Loss: 0.0845 Acc: 0.9731\n",
      "Val Loss: 0.1503 Acc: 0.9558\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7804)\n",
      "Train Loss: 0.0686 Acc: 0.9755\n",
      "Val Loss: 0.1583 Acc: 0.9577\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7882)\n",
      "Train Loss: 0.0456 Acc: 0.9852\n",
      "Val Loss: 0.1601 Acc: 0.9603\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0365 Acc: 0.9874\n",
      "Val Loss: 0.1790 Acc: 0.9558\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7877)\n",
      "Train Loss: 0.0441 Acc: 0.9846\n",
      "Val Loss: 0.1567 Acc: 0.9626\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0332 Acc: 0.9886\n",
      "Val Loss: 0.1765 Acc: 0.9624\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0341 Acc: 0.9882\n",
      "Val Loss: 0.1784 Acc: 0.9595\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0141 Acc: 0.9954\n",
      "Val Loss: 0.1515 Acc: 0.9688\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0076 Acc: 0.9974\n",
      "Val Loss: 0.1715 Acc: 0.9679\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0074 Acc: 0.9974\n",
      "Val Loss: 0.1543 Acc: 0.9720\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0228 Acc: 0.9925\n",
      "Val Loss: 0.1831 Acc: 0.9665\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0277 Acc: 0.9918\n",
      "Val Loss: 0.1670 Acc: 0.9704\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0374 Acc: 0.9884\n",
      "Val Loss: 0.1793 Acc: 0.9605\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0195 Acc: 0.9928\n",
      "Val Loss: 0.2125 Acc: 0.9630\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0171 Acc: 0.9944\n",
      "Val Loss: 0.1843 Acc: 0.9663\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0072 Acc: 0.9975\n",
      "Val Loss: 0.1881 Acc: 0.9722\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0065 Acc: 0.9981\n",
      "Val Loss: 0.2140 Acc: 0.9676\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0359 Acc: 0.9896\n",
      "Val Loss: 0.3872 Acc: 0.9461\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0156 Acc: 0.9964\n",
      "Val Loss: 0.1845 Acc: 0.9711\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0022 Acc: 0.9995\n",
      "Val Loss: 0.1810 Acc: 0.9724\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0007 Acc: 0.9999\n",
      "Val Loss: 0.1806 Acc: 0.9725\n",
      "\n",
      "Training complete in 6m 8s\n",
      "Best val Acc: 0.972543\n"
     ]
    }
   ],
   "source": [
    "best_net26, best_acc26, last_net26 = train_model(net26, train_s6_dl, test_dl, criterion, optimizer26, exp_lr_scheduler_26,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "3bhdd1irakPf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6078)\n",
      "Train Loss: 1.5731 Acc: 0.7598\n",
      "Val Loss: 0.2106 Acc: 0.9368\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7592)\n",
      "Train Loss: 0.1693 Acc: 0.9490\n",
      "Val Loss: 0.1753 Acc: 0.9456\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7746)\n",
      "Train Loss: 0.1041 Acc: 0.9683\n",
      "Val Loss: 0.1379 Acc: 0.9609\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7840)\n",
      "Train Loss: 0.0677 Acc: 0.9800\n",
      "Val Loss: 0.1931 Acc: 0.9473\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7874)\n",
      "Train Loss: 0.0484 Acc: 0.9842\n",
      "Val Loss: 0.1723 Acc: 0.9565\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7882)\n",
      "Train Loss: 0.0397 Acc: 0.9852\n",
      "Val Loss: 0.1345 Acc: 0.9632\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0410 Acc: 0.9861\n",
      "Val Loss: 0.1593 Acc: 0.9595\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0316 Acc: 0.9895\n",
      "Val Loss: 0.1644 Acc: 0.9617\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0194 Acc: 0.9946\n",
      "Val Loss: 0.1399 Acc: 0.9693\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0224 Acc: 0.9926\n",
      "Val Loss: 0.1646 Acc: 0.9655\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0292 Acc: 0.9902\n",
      "Val Loss: 0.1978 Acc: 0.9621\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0370 Acc: 0.9885\n",
      "Val Loss: 0.1582 Acc: 0.9682\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0230 Acc: 0.9932\n",
      "Val Loss: 0.1726 Acc: 0.9654\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0215 Acc: 0.9926\n",
      "Val Loss: 0.1707 Acc: 0.9653\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0066 Acc: 0.9975\n",
      "Val Loss: 0.1498 Acc: 0.9715\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0018 Acc: 0.9996\n",
      "Val Loss: 0.1263 Acc: 0.9763\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1221 Acc: 0.9778\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1222 Acc: 0.9777\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1224 Acc: 0.9778\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1227 Acc: 0.9782\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1227 Acc: 0.9782\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1228 Acc: 0.9782\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1228 Acc: 0.9782\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.978180\n"
     ]
    }
   ],
   "source": [
    "best_net27, best_acc27, last_net27 = train_model(net27, train_s7_dl, test_dl, criterion, optimizer27, exp_lr_scheduler_27,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "uv3xXizwaqR2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6536)\n",
      "Train Loss: 1.1822 Acc: 0.8170\n",
      "Val Loss: 0.1762 Acc: 0.9447\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7705)\n",
      "Train Loss: 0.1150 Acc: 0.9631\n",
      "Val Loss: 0.1387 Acc: 0.9571\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7820)\n",
      "Train Loss: 0.0653 Acc: 0.9775\n",
      "Val Loss: 0.1281 Acc: 0.9616\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7886)\n",
      "Train Loss: 0.0452 Acc: 0.9858\n",
      "Val Loss: 0.1732 Acc: 0.9536\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7872)\n",
      "Train Loss: 0.0508 Acc: 0.9840\n",
      "Val Loss: 0.1522 Acc: 0.9601\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0283 Acc: 0.9902\n",
      "Val Loss: 0.1235 Acc: 0.9683\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7887)\n",
      "Train Loss: 0.0446 Acc: 0.9859\n",
      "Val Loss: 0.1111 Acc: 0.9728\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0236 Acc: 0.9919\n",
      "Val Loss: 0.1103 Acc: 0.9745\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0141 Acc: 0.9951\n",
      "Val Loss: 0.1249 Acc: 0.9747\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0106 Acc: 0.9960\n",
      "Val Loss: 0.1230 Acc: 0.9729\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0068 Acc: 0.9980\n",
      "Val Loss: 0.1538 Acc: 0.9716\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0297 Acc: 0.9914\n",
      "Val Loss: 0.1318 Acc: 0.9715\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0206 Acc: 0.9936\n",
      "Val Loss: 0.2124 Acc: 0.9605\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7874)\n",
      "Train Loss: 0.0475 Acc: 0.9842\n",
      "Val Loss: 0.1464 Acc: 0.9707\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0123 Acc: 0.9955\n",
      "Val Loss: 0.2409 Acc: 0.9587\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0361 Acc: 0.9890\n",
      "Val Loss: 0.1908 Acc: 0.9634\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0289 Acc: 0.9928\n",
      "Val Loss: 0.1576 Acc: 0.9699\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0134 Acc: 0.9956\n",
      "Val Loss: 0.1936 Acc: 0.9694\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0262 Acc: 0.9931\n",
      "Val Loss: 0.2001 Acc: 0.9681\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0158 Acc: 0.9952\n",
      "Val Loss: 0.1496 Acc: 0.9756\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0036 Acc: 0.9984\n",
      "Val Loss: 0.1371 Acc: 0.9772\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1368 Acc: 0.9776\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1364 Acc: 0.9777\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.977725\n"
     ]
    }
   ],
   "source": [
    "best_net28, best_acc28, last_net28 = train_model(net28, train_s8_dl, test_dl, criterion, optimizer28, exp_lr_scheduler_28,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "nLPD7cYbawOx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6189)\n",
      "Train Loss: 2.0466 Acc: 0.7736\n",
      "Val Loss: 0.2216 Acc: 0.9322\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7584)\n",
      "Train Loss: 0.1617 Acc: 0.9480\n",
      "Val Loss: 0.1778 Acc: 0.9449\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7719)\n",
      "Train Loss: 0.1114 Acc: 0.9649\n",
      "Val Loss: 0.1599 Acc: 0.9541\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7823)\n",
      "Train Loss: 0.0671 Acc: 0.9779\n",
      "Val Loss: 0.1644 Acc: 0.9550\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7837)\n",
      "Train Loss: 0.0594 Acc: 0.9796\n",
      "Val Loss: 0.1976 Acc: 0.9515\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0362 Acc: 0.9879\n",
      "Val Loss: 0.1432 Acc: 0.9636\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0330 Acc: 0.9891\n",
      "Val Loss: 0.2098 Acc: 0.9544\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0199 Acc: 0.9924\n",
      "Val Loss: 0.1660 Acc: 0.9644\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0192 Acc: 0.9941\n",
      "Val Loss: 0.1626 Acc: 0.9665\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0254 Acc: 0.9920\n",
      "Val Loss: 0.1663 Acc: 0.9663\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0303 Acc: 0.9900\n",
      "Val Loss: 0.1930 Acc: 0.9659\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0363 Acc: 0.9882\n",
      "Val Loss: 0.1882 Acc: 0.9645\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0294 Acc: 0.9906\n",
      "Val Loss: 0.1723 Acc: 0.9663\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0130 Acc: 0.9951\n",
      "Val Loss: 0.1618 Acc: 0.9717\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0146 Acc: 0.9955\n",
      "Val Loss: 0.1948 Acc: 0.9667\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0298 Acc: 0.9902\n",
      "Val Loss: 0.1982 Acc: 0.9658\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0341 Acc: 0.9895\n",
      "Val Loss: 0.1628 Acc: 0.9695\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0091 Acc: 0.9978\n",
      "Val Loss: 0.1887 Acc: 0.9694\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0020 Acc: 0.9994\n",
      "Val Loss: 0.1646 Acc: 0.9728\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1704 Acc: 0.9728\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1700 Acc: 0.9727\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1698 Acc: 0.9729\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1696 Acc: 0.9731\n",
      "\n",
      "Training complete in 6m 8s\n",
      "Best val Acc: 0.973088\n"
     ]
    }
   ],
   "source": [
    "best_net29, best_acc29, last_net29 = train_model(net29, train_s9_dl, test_dl, criterion, optimizer29, exp_lr_scheduler_29,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "oqPava7ma17T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6558)\n",
      "Train Loss: 1.5429 Acc: 0.8197\n",
      "Val Loss: 0.1538 Acc: 0.9545\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7681)\n",
      "Train Loss: 0.1267 Acc: 0.9601\n",
      "Val Loss: 0.1479 Acc: 0.9533\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7819)\n",
      "Train Loss: 0.0746 Acc: 0.9774\n",
      "Val Loss: 0.1145 Acc: 0.9689\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7887)\n",
      "Train Loss: 0.0457 Acc: 0.9859\n",
      "Val Loss: 0.1169 Acc: 0.9674\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0323 Acc: 0.9889\n",
      "Val Loss: 0.1439 Acc: 0.9633\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0226 Acc: 0.9918\n",
      "Val Loss: 0.1657 Acc: 0.9614\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0351 Acc: 0.9885\n",
      "Val Loss: 0.1344 Acc: 0.9667\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0167 Acc: 0.9945\n",
      "Val Loss: 0.1440 Acc: 0.9697\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0118 Acc: 0.9959\n",
      "Val Loss: 0.1353 Acc: 0.9736\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0154 Acc: 0.9949\n",
      "Val Loss: 0.1523 Acc: 0.9687\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0275 Acc: 0.9906\n",
      "Val Loss: 0.1813 Acc: 0.9644\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0432 Acc: 0.9874\n",
      "Val Loss: 0.1658 Acc: 0.9645\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0257 Acc: 0.9915\n",
      "Val Loss: 0.1462 Acc: 0.9694\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0120 Acc: 0.9964\n",
      "Val Loss: 0.1641 Acc: 0.9696\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0062 Acc: 0.9979\n",
      "Val Loss: 0.1723 Acc: 0.9736\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0136 Acc: 0.9951\n",
      "Val Loss: 0.2262 Acc: 0.9662\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0261 Acc: 0.9929\n",
      "Val Loss: 0.1736 Acc: 0.9695\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0213 Acc: 0.9934\n",
      "Val Loss: 0.1762 Acc: 0.9725\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0099 Acc: 0.9962\n",
      "Val Loss: 0.1939 Acc: 0.9707\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0176 Acc: 0.9956\n",
      "Val Loss: 0.2065 Acc: 0.9690\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0096 Acc: 0.9976\n",
      "Val Loss: 0.1651 Acc: 0.9752\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0010 Acc: 0.9996\n",
      "Val Loss: 0.1600 Acc: 0.9757\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1588 Acc: 0.9759\n",
      "\n",
      "Training complete in 6m 18s\n",
      "Best val Acc: 0.975907\n"
     ]
    }
   ],
   "source": [
    "best_net30, best_acc30, last_net30 = train_model(net30, train_s10_dl, test_dl, criterion, optimizer30, exp_lr_scheduler_30,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "xRiFWDaKbA1k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6722)\n",
      "Train Loss: 1.1883 Acc: 0.8403\n",
      "Val Loss: 0.1859 Acc: 0.9421\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7704)\n",
      "Train Loss: 0.1110 Acc: 0.9630\n",
      "Val Loss: 0.1125 Acc: 0.9653\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7809)\n",
      "Train Loss: 0.0710 Acc: 0.9761\n",
      "Val Loss: 0.1693 Acc: 0.9524\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7836)\n",
      "Train Loss: 0.0584 Acc: 0.9795\n",
      "Val Loss: 0.1450 Acc: 0.9615\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0377 Acc: 0.9878\n",
      "Val Loss: 0.0970 Acc: 0.9726\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0260 Acc: 0.9916\n",
      "Val Loss: 0.1147 Acc: 0.9706\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0281 Acc: 0.9904\n",
      "Val Loss: 0.1557 Acc: 0.9660\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0199 Acc: 0.9935\n",
      "Val Loss: 0.1180 Acc: 0.9744\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0159 Acc: 0.9938\n",
      "Val Loss: 0.1355 Acc: 0.9732\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0277 Acc: 0.9908\n",
      "Val Loss: 0.1508 Acc: 0.9702\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0226 Acc: 0.9919\n",
      "Val Loss: 0.1225 Acc: 0.9756\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0098 Acc: 0.9965\n",
      "Val Loss: 0.1288 Acc: 0.9762\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0148 Acc: 0.9962\n",
      "Val Loss: 0.1418 Acc: 0.9731\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0196 Acc: 0.9940\n",
      "Val Loss: 0.1432 Acc: 0.9717\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0089 Acc: 0.9974\n",
      "Val Loss: 0.1221 Acc: 0.9783\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0372 Acc: 0.9889\n",
      "Val Loss: 0.1611 Acc: 0.9708\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0399 Acc: 0.9876\n",
      "Val Loss: 0.1507 Acc: 0.9695\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0196 Acc: 0.9950\n",
      "Val Loss: 0.1359 Acc: 0.9748\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7973)\n",
      "Train Loss: 0.0112 Acc: 0.9966\n",
      "Val Loss: 0.1649 Acc: 0.9728\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0108 Acc: 0.9961\n",
      "Val Loss: 0.1436 Acc: 0.9765\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0055 Acc: 0.9984\n",
      "Val Loss: 0.1127 Acc: 0.9805\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1116 Acc: 0.9808\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1113 Acc: 0.9810\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.980998\n"
     ]
    }
   ],
   "source": [
    "best_net31, best_acc31, last_net31 = train_model(net31, train_t1_dl, test_dl, criterion, optimizer31, exp_lr_scheduler_31,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "iq_DR_z_bMpS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6548)\n",
      "Train Loss: 1.3280 Acc: 0.8185\n",
      "Val Loss: 0.2282 Acc: 0.9305\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7637)\n",
      "Train Loss: 0.1422 Acc: 0.9546\n",
      "Val Loss: 0.1778 Acc: 0.9458\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7751)\n",
      "Train Loss: 0.0975 Acc: 0.9689\n",
      "Val Loss: 0.1346 Acc: 0.9609\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7824)\n",
      "Train Loss: 0.0638 Acc: 0.9780\n",
      "Val Loss: 0.1209 Acc: 0.9645\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0303 Acc: 0.9896\n",
      "Val Loss: 0.1111 Acc: 0.9723\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0203 Acc: 0.9922\n",
      "Val Loss: 0.1295 Acc: 0.9684\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0309 Acc: 0.9898\n",
      "Val Loss: 0.1317 Acc: 0.9707\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0408 Acc: 0.9854\n",
      "Val Loss: 0.1736 Acc: 0.9594\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0246 Acc: 0.9916\n",
      "Val Loss: 0.1357 Acc: 0.9695\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0174 Acc: 0.9936\n",
      "Val Loss: 0.1577 Acc: 0.9685\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7905)\n",
      "Train Loss: 0.0411 Acc: 0.9881\n",
      "Val Loss: 0.1267 Acc: 0.9741\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0107 Acc: 0.9962\n",
      "Val Loss: 0.1264 Acc: 0.9758\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0222 Acc: 0.9934\n",
      "Val Loss: 0.1868 Acc: 0.9668\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0336 Acc: 0.9890\n",
      "Val Loss: 0.1639 Acc: 0.9717\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0227 Acc: 0.9928\n",
      "Val Loss: 0.1455 Acc: 0.9728\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0215 Acc: 0.9925\n",
      "Val Loss: 0.2021 Acc: 0.9658\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0091 Acc: 0.9974\n",
      "Val Loss: 0.1460 Acc: 0.9755\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0044 Acc: 0.9988\n",
      "Val Loss: 0.1428 Acc: 0.9784\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0008 Acc: 0.9999\n",
      "Val Loss: 0.1344 Acc: 0.9792\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1404 Acc: 0.9789\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1397 Acc: 0.9789\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1392 Acc: 0.9790\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1389 Acc: 0.9790\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.979180\n"
     ]
    }
   ],
   "source": [
    "best_net32, best_acc32, last_net32 = train_model(net32, train_t2_dl, test_dl, criterion, optimizer32, exp_lr_scheduler_32,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "id": "hsE_mDCubS7j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6219)\n",
      "Train Loss: 1.8618 Acc: 0.7774\n",
      "Val Loss: 0.1966 Acc: 0.9397\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7609)\n",
      "Train Loss: 0.1544 Acc: 0.9511\n",
      "Val Loss: 0.1388 Acc: 0.9581\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7768)\n",
      "Train Loss: 0.0846 Acc: 0.9710\n",
      "Val Loss: 0.1316 Acc: 0.9632\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7826)\n",
      "Train Loss: 0.0656 Acc: 0.9782\n",
      "Val Loss: 0.1246 Acc: 0.9647\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7842)\n",
      "Train Loss: 0.0567 Acc: 0.9802\n",
      "Val Loss: 0.1232 Acc: 0.9685\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7865)\n",
      "Train Loss: 0.0484 Acc: 0.9831\n",
      "Val Loss: 0.1604 Acc: 0.9628\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0302 Acc: 0.9890\n",
      "Val Loss: 0.1601 Acc: 0.9623\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7904)\n",
      "Train Loss: 0.0364 Acc: 0.9880\n",
      "Val Loss: 0.1701 Acc: 0.9634\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0250 Acc: 0.9910\n",
      "Val Loss: 0.1736 Acc: 0.9605\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0169 Acc: 0.9939\n",
      "Val Loss: 0.1469 Acc: 0.9713\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0134 Acc: 0.9946\n",
      "Val Loss: 0.1523 Acc: 0.9697\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0140 Acc: 0.9956\n",
      "Val Loss: 0.2283 Acc: 0.9605\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0386 Acc: 0.9886\n",
      "Val Loss: 0.1925 Acc: 0.9615\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0361 Acc: 0.9888\n",
      "Val Loss: 0.1913 Acc: 0.9628\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0182 Acc: 0.9935\n",
      "Val Loss: 0.1673 Acc: 0.9682\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0152 Acc: 0.9945\n",
      "Val Loss: 0.1730 Acc: 0.9680\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0503 Acc: 0.9869\n",
      "Val Loss: 0.2013 Acc: 0.9631\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0248 Acc: 0.9919\n",
      "Val Loss: 0.1538 Acc: 0.9720\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0124 Acc: 0.9971\n",
      "Val Loss: 0.1618 Acc: 0.9752\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0037 Acc: 0.9989\n",
      "Val Loss: 0.1564 Acc: 0.9749\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0024 Acc: 0.9991\n",
      "Val Loss: 0.1377 Acc: 0.9783\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1374 Acc: 0.9782\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1371 Acc: 0.9784\n",
      "\n",
      "Training complete in 6m 16s\n",
      "Best val Acc: 0.978362\n"
     ]
    }
   ],
   "source": [
    "best_net33, best_acc33, last_net33 = train_model(net33, train_t3_dl, test_dl, criterion, optimizer33, exp_lr_scheduler_33,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "0GuApc7GbZB1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6500)\n",
      "Train Loss: 1.0504 Acc: 0.8125\n",
      "Val Loss: 0.1676 Acc: 0.9491\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7649)\n",
      "Train Loss: 0.1278 Acc: 0.9561\n",
      "Val Loss: 0.1295 Acc: 0.9599\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7793)\n",
      "Train Loss: 0.0808 Acc: 0.9741\n",
      "Val Loss: 0.1148 Acc: 0.9642\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7839)\n",
      "Train Loss: 0.0589 Acc: 0.9799\n",
      "Val Loss: 0.1135 Acc: 0.9681\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0307 Acc: 0.9896\n",
      "Val Loss: 0.1229 Acc: 0.9682\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0190 Acc: 0.9936\n",
      "Val Loss: 0.1271 Acc: 0.9684\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0280 Acc: 0.9900\n",
      "Val Loss: 0.1486 Acc: 0.9622\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7896)\n",
      "Train Loss: 0.0384 Acc: 0.9870\n",
      "Val Loss: 0.1386 Acc: 0.9641\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0329 Acc: 0.9888\n",
      "Val Loss: 0.1376 Acc: 0.9671\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0298 Acc: 0.9901\n",
      "Val Loss: 0.1351 Acc: 0.9705\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0131 Acc: 0.9956\n",
      "Val Loss: 0.1437 Acc: 0.9716\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0203 Acc: 0.9928\n",
      "Val Loss: 0.1561 Acc: 0.9720\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0344 Acc: 0.9904\n",
      "Val Loss: 0.1478 Acc: 0.9713\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0157 Acc: 0.9948\n",
      "Val Loss: 0.1206 Acc: 0.9760\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7973)\n",
      "Train Loss: 0.0091 Acc: 0.9966\n",
      "Val Loss: 0.1533 Acc: 0.9673\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0263 Acc: 0.9915\n",
      "Val Loss: 0.1824 Acc: 0.9688\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0198 Acc: 0.9939\n",
      "Val Loss: 0.2077 Acc: 0.9635\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0172 Acc: 0.9951\n",
      "Val Loss: 0.1674 Acc: 0.9730\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0195 Acc: 0.9935\n",
      "Val Loss: 0.1841 Acc: 0.9702\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0381 Acc: 0.9906\n",
      "Val Loss: 0.2453 Acc: 0.9595\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0099 Acc: 0.9965\n",
      "Val Loss: 0.1602 Acc: 0.9747\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0014 Acc: 0.9998\n",
      "Val Loss: 0.1507 Acc: 0.9755\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1492 Acc: 0.9758\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.975998\n"
     ]
    }
   ],
   "source": [
    "best_net34, best_acc34, last_net34 = train_model(net34, train_t4_dl, test_dl, criterion, optimizer34, exp_lr_scheduler_34,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "Q93MZI4BbeWR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6511)\n",
      "Train Loss: 1.4963 Acc: 0.8139\n",
      "Val Loss: 0.1781 Acc: 0.9450\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7594)\n",
      "Train Loss: 0.1594 Acc: 0.9493\n",
      "Val Loss: 0.1482 Acc: 0.9564\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7736)\n",
      "Train Loss: 0.1006 Acc: 0.9670\n",
      "Val Loss: 0.1335 Acc: 0.9611\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7822)\n",
      "Train Loss: 0.0679 Acc: 0.9778\n",
      "Val Loss: 0.1423 Acc: 0.9601\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7828)\n",
      "Train Loss: 0.0617 Acc: 0.9785\n",
      "Val Loss: 0.1297 Acc: 0.9656\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7896)\n",
      "Train Loss: 0.0404 Acc: 0.9870\n",
      "Val Loss: 0.1378 Acc: 0.9643\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0190 Acc: 0.9942\n",
      "Val Loss: 0.1607 Acc: 0.9635\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0302 Acc: 0.9896\n",
      "Val Loss: 0.1941 Acc: 0.9593\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7819)\n",
      "Train Loss: 0.0741 Acc: 0.9774\n",
      "Val Loss: 0.1844 Acc: 0.9565\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0282 Acc: 0.9910\n",
      "Val Loss: 0.1308 Acc: 0.9700\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0142 Acc: 0.9949\n",
      "Val Loss: 0.1239 Acc: 0.9730\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0099 Acc: 0.9969\n",
      "Val Loss: 0.1401 Acc: 0.9705\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0081 Acc: 0.9974\n",
      "Val Loss: 0.1334 Acc: 0.9731\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0153 Acc: 0.9948\n",
      "Val Loss: 0.1264 Acc: 0.9726\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0448 Acc: 0.9878\n",
      "Val Loss: 0.1794 Acc: 0.9642\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7896)\n",
      "Train Loss: 0.0453 Acc: 0.9870\n",
      "Val Loss: 0.1442 Acc: 0.9728\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0147 Acc: 0.9946\n",
      "Val Loss: 0.2294 Acc: 0.9611\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0263 Acc: 0.9921\n",
      "Val Loss: 0.1538 Acc: 0.9737\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0078 Acc: 0.9976\n",
      "Val Loss: 0.1296 Acc: 0.9758\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0170 Acc: 0.9955\n",
      "Val Loss: 0.1587 Acc: 0.9733\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0085 Acc: 0.9981\n",
      "Val Loss: 0.1234 Acc: 0.9781\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0019 Acc: 0.9999\n",
      "Val Loss: 0.1207 Acc: 0.9787\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0010 Acc: 0.9999\n",
      "Val Loss: 0.1197 Acc: 0.9790\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.978998\n"
     ]
    }
   ],
   "source": [
    "best_net35, best_acc35, last_net35 = train_model(net35, train_t5_dl, test_dl, criterion, optimizer35, exp_lr_scheduler_35,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "Z59uUJzabj0w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6279)\n",
      "Train Loss: 1.1584 Acc: 0.7849\n",
      "Val Loss: 0.1932 Acc: 0.9394\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7661)\n",
      "Train Loss: 0.1382 Acc: 0.9576\n",
      "Val Loss: 0.1544 Acc: 0.9505\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7783)\n",
      "Train Loss: 0.0939 Acc: 0.9729\n",
      "Val Loss: 0.1416 Acc: 0.9582\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7838)\n",
      "Train Loss: 0.0613 Acc: 0.9798\n",
      "Val Loss: 0.1327 Acc: 0.9648\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7871)\n",
      "Train Loss: 0.0454 Acc: 0.9839\n",
      "Val Loss: 0.1386 Acc: 0.9623\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0311 Acc: 0.9891\n",
      "Val Loss: 0.1472 Acc: 0.9650\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0220 Acc: 0.9921\n",
      "Val Loss: 0.1312 Acc: 0.9687\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0230 Acc: 0.9929\n",
      "Val Loss: 0.1534 Acc: 0.9686\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0189 Acc: 0.9940\n",
      "Val Loss: 0.1353 Acc: 0.9702\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0269 Acc: 0.9915\n",
      "Val Loss: 0.3291 Acc: 0.9394\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7871)\n",
      "Train Loss: 0.0457 Acc: 0.9839\n",
      "Val Loss: 0.1414 Acc: 0.9691\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0202 Acc: 0.9931\n",
      "Val Loss: 0.1620 Acc: 0.9689\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0173 Acc: 0.9935\n",
      "Val Loss: 0.1724 Acc: 0.9698\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0203 Acc: 0.9950\n",
      "Val Loss: 0.1560 Acc: 0.9706\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0188 Acc: 0.9938\n",
      "Val Loss: 0.1506 Acc: 0.9709\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0231 Acc: 0.9934\n",
      "Val Loss: 0.1879 Acc: 0.9668\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0290 Acc: 0.9925\n",
      "Val Loss: 0.1679 Acc: 0.9715\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0128 Acc: 0.9960\n",
      "Val Loss: 0.1519 Acc: 0.9725\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0098 Acc: 0.9970\n",
      "Val Loss: 0.1613 Acc: 0.9742\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0075 Acc: 0.9976\n",
      "Val Loss: 0.2201 Acc: 0.9681\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0048 Acc: 0.9984\n",
      "Val Loss: 0.1635 Acc: 0.9754\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1608 Acc: 0.9753\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1598 Acc: 0.9757\n",
      "\n",
      "Training complete in 6m 17s\n",
      "Best val Acc: 0.975725\n"
     ]
    }
   ],
   "source": [
    "best_net36, best_acc36, last_net36 = train_model(net36, train_t6_dl, test_dl, criterion, optimizer36, exp_lr_scheduler_36,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "tpIqPH-PbqNL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6482)\n",
      "Train Loss: 1.2327 Acc: 0.8103\n",
      "Val Loss: 0.2325 Acc: 0.9311\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7651)\n",
      "Train Loss: 0.1478 Acc: 0.9564\n",
      "Val Loss: 0.1385 Acc: 0.9570\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7790)\n",
      "Train Loss: 0.0799 Acc: 0.9738\n",
      "Val Loss: 0.1148 Acc: 0.9673\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7861)\n",
      "Train Loss: 0.0548 Acc: 0.9826\n",
      "Val Loss: 0.1218 Acc: 0.9675\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0276 Acc: 0.9911\n",
      "Val Loss: 0.1203 Acc: 0.9687\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0247 Acc: 0.9916\n",
      "Val Loss: 0.1374 Acc: 0.9656\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0265 Acc: 0.9910\n",
      "Val Loss: 0.1363 Acc: 0.9698\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7853)\n",
      "Train Loss: 0.0566 Acc: 0.9816\n",
      "Val Loss: 0.1164 Acc: 0.9723\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0187 Acc: 0.9931\n",
      "Val Loss: 0.1366 Acc: 0.9698\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0125 Acc: 0.9959\n",
      "Val Loss: 0.1420 Acc: 0.9722\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0205 Acc: 0.9932\n",
      "Val Loss: 0.1410 Acc: 0.9741\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0191 Acc: 0.9934\n",
      "Val Loss: 0.1667 Acc: 0.9692\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7896)\n",
      "Train Loss: 0.0476 Acc: 0.9870\n",
      "Val Loss: 0.1260 Acc: 0.9721\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0152 Acc: 0.9948\n",
      "Val Loss: 0.1349 Acc: 0.9736\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0116 Acc: 0.9959\n",
      "Val Loss: 0.1427 Acc: 0.9744\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0213 Acc: 0.9926\n",
      "Val Loss: 0.1683 Acc: 0.9688\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0224 Acc: 0.9936\n",
      "Val Loss: 0.1892 Acc: 0.9676\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0250 Acc: 0.9928\n",
      "Val Loss: 0.1523 Acc: 0.9732\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0161 Acc: 0.9958\n",
      "Val Loss: 0.1655 Acc: 0.9700\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0143 Acc: 0.9955\n",
      "Val Loss: 0.1619 Acc: 0.9739\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0040 Acc: 0.9979\n",
      "Val Loss: 0.1447 Acc: 0.9761\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0005 Acc: 0.9999\n",
      "Val Loss: 0.1427 Acc: 0.9765\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1425 Acc: 0.9764\n",
      "\n",
      "Training complete in 6m 18s\n",
      "Best val Acc: 0.976452\n"
     ]
    }
   ],
   "source": [
    "best_net37, best_acc37, last_net37 = train_model(net37, train_t7_dl, test_dl, criterion, optimizer37, exp_lr_scheduler_37,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "rLiNHEkLb1rK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6298)\n",
      "Train Loss: 1.1968 Acc: 0.7873\n",
      "Val Loss: 0.2122 Acc: 0.9366\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7560)\n",
      "Train Loss: 0.1642 Acc: 0.9450\n",
      "Val Loss: 0.1397 Acc: 0.9567\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7760)\n",
      "Train Loss: 0.0920 Acc: 0.9700\n",
      "Val Loss: 0.1495 Acc: 0.9548\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7812)\n",
      "Train Loss: 0.0648 Acc: 0.9765\n",
      "Val Loss: 0.1450 Acc: 0.9628\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0380 Acc: 0.9871\n",
      "Val Loss: 0.1446 Acc: 0.9651\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0350 Acc: 0.9885\n",
      "Val Loss: 0.1657 Acc: 0.9595\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7870)\n",
      "Train Loss: 0.0485 Acc: 0.9838\n",
      "Val Loss: 0.1536 Acc: 0.9634\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0229 Acc: 0.9924\n",
      "Val Loss: 0.1393 Acc: 0.9685\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0103 Acc: 0.9968\n",
      "Val Loss: 0.1458 Acc: 0.9685\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0104 Acc: 0.9962\n",
      "Val Loss: 0.1725 Acc: 0.9639\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0114 Acc: 0.9964\n",
      "Val Loss: 0.1494 Acc: 0.9685\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0292 Acc: 0.9902\n",
      "Val Loss: 0.1941 Acc: 0.9626\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0286 Acc: 0.9904\n",
      "Val Loss: 0.1590 Acc: 0.9704\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0298 Acc: 0.9910\n",
      "Val Loss: 0.1637 Acc: 0.9697\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0358 Acc: 0.9891\n",
      "Val Loss: 0.1786 Acc: 0.9672\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0212 Acc: 0.9934\n",
      "Val Loss: 0.1483 Acc: 0.9725\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0082 Acc: 0.9971\n",
      "Val Loss: 0.1442 Acc: 0.9744\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0042 Acc: 0.9989\n",
      "Val Loss: 0.1287 Acc: 0.9755\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0005 Acc: 0.9999\n",
      "Val Loss: 0.1313 Acc: 0.9767\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1344 Acc: 0.9765\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1339 Acc: 0.9766\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1336 Acc: 0.9765\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1334 Acc: 0.9765\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.976725\n"
     ]
    }
   ],
   "source": [
    "best_net38, best_acc38, last_net38 = train_model(net38, train_t8_dl, test_dl, criterion, optimizer38, exp_lr_scheduler_38,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "uE-dK-g0b7m5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6614)\n",
      "Train Loss: 1.3784 Acc: 0.8267\n",
      "Val Loss: 0.1986 Acc: 0.9396\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7559)\n",
      "Train Loss: 0.1686 Acc: 0.9449\n",
      "Val Loss: 0.1393 Acc: 0.9575\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7724)\n",
      "Train Loss: 0.1065 Acc: 0.9655\n",
      "Val Loss: 0.1250 Acc: 0.9634\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7790)\n",
      "Train Loss: 0.0750 Acc: 0.9738\n",
      "Val Loss: 0.1343 Acc: 0.9657\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7841)\n",
      "Train Loss: 0.0608 Acc: 0.9801\n",
      "Val Loss: 0.1329 Acc: 0.9647\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7898)\n",
      "Train Loss: 0.0377 Acc: 0.9872\n",
      "Val Loss: 0.1368 Acc: 0.9639\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0363 Acc: 0.9886\n",
      "Val Loss: 0.1420 Acc: 0.9624\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0302 Acc: 0.9890\n",
      "Val Loss: 0.1515 Acc: 0.9659\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7869)\n",
      "Train Loss: 0.0508 Acc: 0.9836\n",
      "Val Loss: 0.1248 Acc: 0.9725\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7919)\n",
      "Train Loss: 0.0295 Acc: 0.9899\n",
      "Val Loss: 0.1288 Acc: 0.9694\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0127 Acc: 0.9952\n",
      "Val Loss: 0.1193 Acc: 0.9717\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0196 Acc: 0.9941\n",
      "Val Loss: 0.1333 Acc: 0.9705\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0126 Acc: 0.9960\n",
      "Val Loss: 0.1552 Acc: 0.9707\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0201 Acc: 0.9934\n",
      "Val Loss: 0.1811 Acc: 0.9675\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0303 Acc: 0.9911\n",
      "Val Loss: 0.2009 Acc: 0.9615\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0223 Acc: 0.9929\n",
      "Val Loss: 0.2095 Acc: 0.9651\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0196 Acc: 0.9936\n",
      "Val Loss: 0.2090 Acc: 0.9624\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0270 Acc: 0.9926\n",
      "Val Loss: 0.1772 Acc: 0.9661\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0208 Acc: 0.9946\n",
      "Val Loss: 0.1666 Acc: 0.9705\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0090 Acc: 0.9974\n",
      "Val Loss: 0.1513 Acc: 0.9746\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0025 Acc: 0.9995\n",
      "Val Loss: 0.1459 Acc: 0.9757\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1453 Acc: 0.9756\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1451 Acc: 0.9757\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.975725\n"
     ]
    }
   ],
   "source": [
    "best_net39, best_acc39, last_net39 = train_model(net39, train_t9_dl, test_dl, criterion, optimizer39, exp_lr_scheduler_39,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "bvT21vCkcE6k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(4185)\n",
      "Train Loss: 2.3961 Acc: 0.5231\n",
      "Val Loss: 0.6091 Acc: 0.8863\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(5272)\n",
      "Train Loss: 1.3766 Acc: 0.6590\n",
      "Val Loss: 0.5400 Acc: 0.9282\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(5450)\n",
      "Train Loss: 1.2856 Acc: 0.6813\n",
      "Val Loss: 0.5761 Acc: 0.9302\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(5571)\n",
      "Train Loss: 1.2115 Acc: 0.6964\n",
      "Val Loss: 0.6109 Acc: 0.9237\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(5651)\n",
      "Train Loss: 1.1566 Acc: 0.7064\n",
      "Val Loss: 0.5841 Acc: 0.9195\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(5701)\n",
      "Train Loss: 1.1048 Acc: 0.7126\n",
      "Val Loss: 0.5675 Acc: 0.9182\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(5737)\n",
      "Train Loss: 1.0549 Acc: 0.7171\n",
      "Val Loss: 0.4985 Acc: 0.9124\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(5814)\n",
      "Train Loss: 0.9813 Acc: 0.7268\n",
      "Val Loss: 0.5512 Acc: 0.8909\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(5885)\n",
      "Train Loss: 0.9257 Acc: 0.7356\n",
      "Val Loss: 0.5499 Acc: 0.8816\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(6070)\n",
      "Train Loss: 0.8410 Acc: 0.7588\n",
      "Val Loss: 0.5853 Acc: 0.8622\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(6132)\n",
      "Train Loss: 0.7766 Acc: 0.7665\n",
      "Val Loss: 0.6070 Acc: 0.8494\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(6330)\n",
      "Train Loss: 0.6857 Acc: 0.7913\n",
      "Val Loss: 0.6281 Acc: 0.8335\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(6468)\n",
      "Train Loss: 0.6154 Acc: 0.8085\n",
      "Val Loss: 0.7193 Acc: 0.7968\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(6614)\n",
      "Train Loss: 0.5524 Acc: 0.8267\n",
      "Val Loss: 0.7277 Acc: 0.7953\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(6762)\n",
      "Train Loss: 0.4794 Acc: 0.8452\n",
      "Val Loss: 0.7208 Acc: 0.7990\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(6933)\n",
      "Train Loss: 0.4118 Acc: 0.8666\n",
      "Val Loss: 0.7553 Acc: 0.7889\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7024)\n",
      "Train Loss: 0.3673 Acc: 0.8780\n",
      "Val Loss: 0.8242 Acc: 0.7611\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7255)\n",
      "Train Loss: 0.2913 Acc: 0.9069\n",
      "Val Loss: 0.9639 Acc: 0.7403\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7287)\n",
      "Train Loss: 0.2701 Acc: 0.9109\n",
      "Val Loss: 0.9623 Acc: 0.7578\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7288)\n",
      "Train Loss: 0.2683 Acc: 0.9110\n",
      "Val Loss: 0.9403 Acc: 0.7627\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7676)\n",
      "Train Loss: 0.1384 Acc: 0.9595\n",
      "Val Loss: 0.8589 Acc: 0.7838\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7873)\n",
      "Train Loss: 0.0762 Acc: 0.9841\n",
      "Val Loss: 0.8765 Acc: 0.7829\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0594 Acc: 0.9908\n",
      "Val Loss: 0.8773 Acc: 0.7873\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.930175\n"
     ]
    }
   ],
   "source": [
    "best_net40, best_acc40, last_net40 = train_model(net40, train_t10_dl, test_dl, criterion, optimizer40, exp_lr_scheduler_40,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "Jnjo8uZocOzt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6149)\n",
      "Train Loss: 1.5879 Acc: 0.7686\n",
      "Val Loss: 0.2380 Acc: 0.9324\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7598)\n",
      "Train Loss: 0.1610 Acc: 0.9497\n",
      "Val Loss: 0.1824 Acc: 0.9474\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7771)\n",
      "Train Loss: 0.0918 Acc: 0.9714\n",
      "Val Loss: 0.1746 Acc: 0.9536\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7836)\n",
      "Train Loss: 0.0608 Acc: 0.9795\n",
      "Val Loss: 0.1498 Acc: 0.9613\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7862)\n",
      "Train Loss: 0.0486 Acc: 0.9828\n",
      "Val Loss: 0.1402 Acc: 0.9642\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0361 Acc: 0.9885\n",
      "Val Loss: 0.1453 Acc: 0.9637\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0164 Acc: 0.9951\n",
      "Val Loss: 0.1421 Acc: 0.9699\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0139 Acc: 0.9951\n",
      "Val Loss: 0.1871 Acc: 0.9613\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0141 Acc: 0.9956\n",
      "Val Loss: 0.1623 Acc: 0.9694\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7848)\n",
      "Train Loss: 0.0697 Acc: 0.9810\n",
      "Val Loss: 0.1856 Acc: 0.9569\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0215 Acc: 0.9925\n",
      "Val Loss: 0.1375 Acc: 0.9710\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0150 Acc: 0.9950\n",
      "Val Loss: 0.1520 Acc: 0.9706\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0046 Acc: 0.9986\n",
      "Val Loss: 0.1526 Acc: 0.9693\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0066 Acc: 0.9981\n",
      "Val Loss: 0.1413 Acc: 0.9724\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0011 Acc: 1.0000\n",
      "Val Loss: 0.1391 Acc: 0.9746\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1388 Acc: 0.9742\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1406 Acc: 0.9746\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1415 Acc: 0.9746\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1430 Acc: 0.9748\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1444 Acc: 0.9752\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1444 Acc: 0.9751\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1445 Acc: 0.9751\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1446 Acc: 0.9752\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.975180\n"
     ]
    }
   ],
   "source": [
    "best_net41, best_acc41, last_net41 = train_model(net41, train_u1_dl, test_dl, criterion, optimizer41, exp_lr_scheduler_41,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "-sil_Az3cdTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6229)\n",
      "Train Loss: 1.4784 Acc: 0.7786\n",
      "Val Loss: 0.1762 Acc: 0.9466\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7700)\n",
      "Train Loss: 0.1329 Acc: 0.9625\n",
      "Val Loss: 0.1291 Acc: 0.9610\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7811)\n",
      "Train Loss: 0.0753 Acc: 0.9764\n",
      "Val Loss: 0.1318 Acc: 0.9609\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7873)\n",
      "Train Loss: 0.0489 Acc: 0.9841\n",
      "Val Loss: 0.1492 Acc: 0.9607\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7853)\n",
      "Train Loss: 0.0525 Acc: 0.9816\n",
      "Val Loss: 0.1494 Acc: 0.9622\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0374 Acc: 0.9878\n",
      "Val Loss: 0.1612 Acc: 0.9601\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0250 Acc: 0.9915\n",
      "Val Loss: 0.1391 Acc: 0.9659\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0233 Acc: 0.9926\n",
      "Val Loss: 0.1434 Acc: 0.9696\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0209 Acc: 0.9930\n",
      "Val Loss: 0.1424 Acc: 0.9695\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0179 Acc: 0.9928\n",
      "Val Loss: 0.1611 Acc: 0.9681\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0291 Acc: 0.9905\n",
      "Val Loss: 0.1877 Acc: 0.9649\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0350 Acc: 0.9895\n",
      "Val Loss: 0.1392 Acc: 0.9713\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0082 Acc: 0.9976\n",
      "Val Loss: 0.1278 Acc: 0.9766\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0154 Acc: 0.9949\n",
      "Val Loss: 0.1851 Acc: 0.9660\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0322 Acc: 0.9901\n",
      "Val Loss: 0.1804 Acc: 0.9654\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0176 Acc: 0.9939\n",
      "Val Loss: 0.2739 Acc: 0.9497\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0391 Acc: 0.9879\n",
      "Val Loss: 0.1609 Acc: 0.9708\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0125 Acc: 0.9961\n",
      "Val Loss: 0.1474 Acc: 0.9742\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0142 Acc: 0.9955\n",
      "Val Loss: 0.1703 Acc: 0.9732\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0107 Acc: 0.9956\n",
      "Val Loss: 0.1871 Acc: 0.9712\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0114 Acc: 0.9984\n",
      "Val Loss: 0.1452 Acc: 0.9765\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0016 Acc: 0.9999\n",
      "Val Loss: 0.1432 Acc: 0.9772\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1410 Acc: 0.9770\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.977180\n"
     ]
    }
   ],
   "source": [
    "best_net42, best_acc42, last_net42 = train_model(net42, train_u2_dl, test_dl, criterion, optimizer42, exp_lr_scheduler_42,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "tP3_qXSRcihC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6572)\n",
      "Train Loss: 1.5574 Acc: 0.8215\n",
      "Val Loss: 0.2147 Acc: 0.9355\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7634)\n",
      "Train Loss: 0.1468 Acc: 0.9543\n",
      "Val Loss: 0.1729 Acc: 0.9498\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7726)\n",
      "Train Loss: 0.1037 Acc: 0.9657\n",
      "Val Loss: 0.1625 Acc: 0.9527\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7786)\n",
      "Train Loss: 0.0775 Acc: 0.9732\n",
      "Val Loss: 0.1794 Acc: 0.9525\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7839)\n",
      "Train Loss: 0.0585 Acc: 0.9799\n",
      "Val Loss: 0.1866 Acc: 0.9513\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7857)\n",
      "Train Loss: 0.0548 Acc: 0.9821\n",
      "Val Loss: 0.1451 Acc: 0.9631\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0341 Acc: 0.9871\n",
      "Val Loss: 0.1675 Acc: 0.9594\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0330 Acc: 0.9892\n",
      "Val Loss: 0.1847 Acc: 0.9598\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0276 Acc: 0.9906\n",
      "Val Loss: 0.1455 Acc: 0.9670\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0132 Acc: 0.9951\n",
      "Val Loss: 0.1599 Acc: 0.9655\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0141 Acc: 0.9955\n",
      "Val Loss: 0.1572 Acc: 0.9675\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0222 Acc: 0.9930\n",
      "Val Loss: 0.1532 Acc: 0.9686\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0192 Acc: 0.9939\n",
      "Val Loss: 0.1919 Acc: 0.9607\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0212 Acc: 0.9935\n",
      "Val Loss: 0.1804 Acc: 0.9664\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0271 Acc: 0.9902\n",
      "Val Loss: 0.2175 Acc: 0.9631\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7905)\n",
      "Train Loss: 0.0402 Acc: 0.9881\n",
      "Val Loss: 0.1721 Acc: 0.9666\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0250 Acc: 0.9931\n",
      "Val Loss: 0.1713 Acc: 0.9675\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0093 Acc: 0.9968\n",
      "Val Loss: 0.1785 Acc: 0.9684\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0050 Acc: 0.9989\n",
      "Val Loss: 0.1892 Acc: 0.9656\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0033 Acc: 0.9988\n",
      "Val Loss: 0.1798 Acc: 0.9705\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0018 Acc: 0.9995\n",
      "Val Loss: 0.1639 Acc: 0.9718\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1619 Acc: 0.9720\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1614 Acc: 0.9722\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.972179\n"
     ]
    }
   ],
   "source": [
    "best_net43, best_acc43, last_net43 = train_model(net43, train_u3_dl, test_dl, criterion, optimizer43, exp_lr_scheduler_43,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "lFLTw1I1coxL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6457)\n",
      "Train Loss: 1.6567 Acc: 0.8071\n",
      "Val Loss: 0.2262 Acc: 0.9272\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7651)\n",
      "Train Loss: 0.1436 Acc: 0.9564\n",
      "Val Loss: 0.1636 Acc: 0.9512\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7774)\n",
      "Train Loss: 0.0879 Acc: 0.9718\n",
      "Val Loss: 0.1308 Acc: 0.9637\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7822)\n",
      "Train Loss: 0.0643 Acc: 0.9778\n",
      "Val Loss: 0.1499 Acc: 0.9582\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0406 Acc: 0.9869\n",
      "Val Loss: 0.2156 Acc: 0.9489\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7871)\n",
      "Train Loss: 0.0426 Acc: 0.9839\n",
      "Val Loss: 0.1404 Acc: 0.9631\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0387 Acc: 0.9874\n",
      "Val Loss: 0.1375 Acc: 0.9705\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0253 Acc: 0.9916\n",
      "Val Loss: 0.1462 Acc: 0.9653\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0206 Acc: 0.9938\n",
      "Val Loss: 0.1564 Acc: 0.9633\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0120 Acc: 0.9961\n",
      "Val Loss: 0.1645 Acc: 0.9662\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0398 Acc: 0.9885\n",
      "Val Loss: 0.1596 Acc: 0.9662\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0235 Acc: 0.9924\n",
      "Val Loss: 0.1757 Acc: 0.9620\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0270 Acc: 0.9919\n",
      "Val Loss: 0.1981 Acc: 0.9628\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0350 Acc: 0.9904\n",
      "Val Loss: 0.1876 Acc: 0.9648\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7919)\n",
      "Train Loss: 0.0342 Acc: 0.9899\n",
      "Val Loss: 0.1962 Acc: 0.9658\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0293 Acc: 0.9918\n",
      "Val Loss: 0.1925 Acc: 0.9655\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0151 Acc: 0.9949\n",
      "Val Loss: 0.1710 Acc: 0.9715\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0086 Acc: 0.9971\n",
      "Val Loss: 0.1664 Acc: 0.9712\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0077 Acc: 0.9968\n",
      "Val Loss: 0.1684 Acc: 0.9721\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0172 Acc: 0.9948\n",
      "Val Loss: 0.2681 Acc: 0.9615\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0100 Acc: 0.9965\n",
      "Val Loss: 0.1767 Acc: 0.9732\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1734 Acc: 0.9730\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1725 Acc: 0.9731\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.973179\n"
     ]
    }
   ],
   "source": [
    "best_net44, best_acc44, last_net44 = train_model(net44, train_u4_dl, test_dl, criterion, optimizer44, exp_lr_scheduler_44,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "G0eCCgJPct6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6536)\n",
      "Train Loss: 1.3717 Acc: 0.8170\n",
      "Val Loss: 0.1845 Acc: 0.9410\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7646)\n",
      "Train Loss: 0.1422 Acc: 0.9557\n",
      "Val Loss: 0.1560 Acc: 0.9524\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7774)\n",
      "Train Loss: 0.0857 Acc: 0.9718\n",
      "Val Loss: 0.1673 Acc: 0.9513\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7856)\n",
      "Train Loss: 0.0543 Acc: 0.9820\n",
      "Val Loss: 0.1198 Acc: 0.9645\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7882)\n",
      "Train Loss: 0.0445 Acc: 0.9852\n",
      "Val Loss: 0.1193 Acc: 0.9669\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0318 Acc: 0.9892\n",
      "Val Loss: 0.1358 Acc: 0.9656\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0245 Acc: 0.9910\n",
      "Val Loss: 0.1556 Acc: 0.9634\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0234 Acc: 0.9912\n",
      "Val Loss: 0.1293 Acc: 0.9695\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0270 Acc: 0.9912\n",
      "Val Loss: 0.1545 Acc: 0.9666\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0158 Acc: 0.9940\n",
      "Val Loss: 0.1397 Acc: 0.9697\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0225 Acc: 0.9935\n",
      "Val Loss: 0.1612 Acc: 0.9665\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0302 Acc: 0.9905\n",
      "Val Loss: 0.1403 Acc: 0.9704\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0110 Acc: 0.9971\n",
      "Val Loss: 0.1635 Acc: 0.9666\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0049 Acc: 0.9986\n",
      "Val Loss: 0.1447 Acc: 0.9735\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0033 Acc: 0.9991\n",
      "Val Loss: 0.1356 Acc: 0.9725\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0007 Acc: 1.0000\n",
      "Val Loss: 0.1361 Acc: 0.9757\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1347 Acc: 0.9760\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1352 Acc: 0.9763\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1360 Acc: 0.9762\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1366 Acc: 0.9760\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1366 Acc: 0.9760\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1367 Acc: 0.9760\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1368 Acc: 0.9760\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.976271\n"
     ]
    }
   ],
   "source": [
    "best_net45, best_acc45, last_net45 = train_model(net45, train_u5_dl, test_dl, criterion, optimizer45, exp_lr_scheduler_45,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "rYSrRBBlczpl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6501)\n",
      "Train Loss: 0.9793 Acc: 0.8126\n",
      "Val Loss: 0.2249 Acc: 0.9319\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7631)\n",
      "Train Loss: 0.1463 Acc: 0.9539\n",
      "Val Loss: 0.2142 Acc: 0.9343\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7735)\n",
      "Train Loss: 0.0998 Acc: 0.9669\n",
      "Val Loss: 0.1486 Acc: 0.9574\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7807)\n",
      "Train Loss: 0.0697 Acc: 0.9759\n",
      "Val Loss: 0.1462 Acc: 0.9572\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7873)\n",
      "Train Loss: 0.0462 Acc: 0.9841\n",
      "Val Loss: 0.1415 Acc: 0.9612\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0287 Acc: 0.9914\n",
      "Val Loss: 0.1324 Acc: 0.9664\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0212 Acc: 0.9925\n",
      "Val Loss: 0.1700 Acc: 0.9610\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0242 Acc: 0.9921\n",
      "Val Loss: 0.1516 Acc: 0.9651\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0191 Acc: 0.9938\n",
      "Val Loss: 0.1780 Acc: 0.9631\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0190 Acc: 0.9938\n",
      "Val Loss: 0.1726 Acc: 0.9643\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0473 Acc: 0.9860\n",
      "Val Loss: 0.1933 Acc: 0.9592\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0337 Acc: 0.9895\n",
      "Val Loss: 0.1553 Acc: 0.9683\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0181 Acc: 0.9940\n",
      "Val Loss: 0.1627 Acc: 0.9705\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0215 Acc: 0.9942\n",
      "Val Loss: 0.1912 Acc: 0.9642\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0231 Acc: 0.9932\n",
      "Val Loss: 0.1771 Acc: 0.9645\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0167 Acc: 0.9949\n",
      "Val Loss: 0.1757 Acc: 0.9681\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0137 Acc: 0.9956\n",
      "Val Loss: 0.1766 Acc: 0.9657\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0057 Acc: 0.9986\n",
      "Val Loss: 0.1780 Acc: 0.9705\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0054 Acc: 0.9981\n",
      "Val Loss: 0.1638 Acc: 0.9703\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0226 Acc: 0.9934\n",
      "Val Loss: 0.2223 Acc: 0.9625\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0115 Acc: 0.9960\n",
      "Val Loss: 0.1770 Acc: 0.9704\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0008 Acc: 1.0000\n",
      "Val Loss: 0.1779 Acc: 0.9704\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1773 Acc: 0.9706\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.970634\n"
     ]
    }
   ],
   "source": [
    "best_net46, best_acc46, last_net46 = train_model(net46, train_u6_dl, test_dl, criterion, optimizer46, exp_lr_scheduler_46,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "J_d8uRqgc4Ui"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6280)\n",
      "Train Loss: 1.7898 Acc: 0.7850\n",
      "Val Loss: 0.1882 Acc: 0.9405\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7638)\n",
      "Train Loss: 0.1428 Acc: 0.9547\n",
      "Val Loss: 0.1601 Acc: 0.9520\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7792)\n",
      "Train Loss: 0.0819 Acc: 0.9740\n",
      "Val Loss: 0.1498 Acc: 0.9576\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7862)\n",
      "Train Loss: 0.0467 Acc: 0.9828\n",
      "Val Loss: 0.1227 Acc: 0.9646\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0355 Acc: 0.9879\n",
      "Val Loss: 0.1191 Acc: 0.9705\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0301 Acc: 0.9891\n",
      "Val Loss: 0.1296 Acc: 0.9693\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0161 Acc: 0.9959\n",
      "Val Loss: 0.1270 Acc: 0.9704\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0161 Acc: 0.9944\n",
      "Val Loss: 0.1513 Acc: 0.9649\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0292 Acc: 0.9909\n",
      "Val Loss: 0.1387 Acc: 0.9705\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0183 Acc: 0.9941\n",
      "Val Loss: 0.1466 Acc: 0.9691\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0270 Acc: 0.9921\n",
      "Val Loss: 0.2129 Acc: 0.9565\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0370 Acc: 0.9885\n",
      "Val Loss: 0.1870 Acc: 0.9615\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0235 Acc: 0.9925\n",
      "Val Loss: 0.1651 Acc: 0.9636\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0119 Acc: 0.9960\n",
      "Val Loss: 0.1717 Acc: 0.9660\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0125 Acc: 0.9964\n",
      "Val Loss: 0.1561 Acc: 0.9709\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0272 Acc: 0.9911\n",
      "Val Loss: 0.2696 Acc: 0.9555\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0331 Acc: 0.9906\n",
      "Val Loss: 0.1476 Acc: 0.9708\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0180 Acc: 0.9949\n",
      "Val Loss: 0.1739 Acc: 0.9675\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0103 Acc: 0.9971\n",
      "Val Loss: 0.1414 Acc: 0.9746\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0015 Acc: 0.9996\n",
      "Val Loss: 0.1323 Acc: 0.9760\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1324 Acc: 0.9763\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1320 Acc: 0.9764\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1317 Acc: 0.9763\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.976361\n"
     ]
    }
   ],
   "source": [
    "best_net47, best_acc47, last_net47 = train_model(net47, train_u7_dl, test_dl, criterion, optimizer47, exp_lr_scheduler_47,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "S0xfhOpSc-uY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6433)\n",
      "Train Loss: 1.3027 Acc: 0.8041\n",
      "Val Loss: 0.1704 Acc: 0.9476\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7677)\n",
      "Train Loss: 0.1301 Acc: 0.9596\n",
      "Val Loss: 0.1564 Acc: 0.9521\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7792)\n",
      "Train Loss: 0.0760 Acc: 0.9740\n",
      "Val Loss: 0.1376 Acc: 0.9628\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7872)\n",
      "Train Loss: 0.0448 Acc: 0.9840\n",
      "Val Loss: 0.1364 Acc: 0.9647\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0255 Acc: 0.9908\n",
      "Val Loss: 0.1208 Acc: 0.9681\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0299 Acc: 0.9902\n",
      "Val Loss: 0.1253 Acc: 0.9705\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7904)\n",
      "Train Loss: 0.0338 Acc: 0.9880\n",
      "Val Loss: 0.1546 Acc: 0.9675\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0296 Acc: 0.9902\n",
      "Val Loss: 0.1505 Acc: 0.9641\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0143 Acc: 0.9949\n",
      "Val Loss: 0.1367 Acc: 0.9672\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0272 Acc: 0.9915\n",
      "Val Loss: 0.1649 Acc: 0.9651\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0175 Acc: 0.9942\n",
      "Val Loss: 0.1862 Acc: 0.9637\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0318 Acc: 0.9888\n",
      "Val Loss: 0.1680 Acc: 0.9631\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0132 Acc: 0.9964\n",
      "Val Loss: 0.1503 Acc: 0.9677\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0100 Acc: 0.9976\n",
      "Val Loss: 0.1437 Acc: 0.9698\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0110 Acc: 0.9961\n",
      "Val Loss: 0.1624 Acc: 0.9689\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0116 Acc: 0.9978\n",
      "Val Loss: 0.1792 Acc: 0.9675\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0240 Acc: 0.9930\n",
      "Val Loss: 0.1591 Acc: 0.9687\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0173 Acc: 0.9940\n",
      "Val Loss: 0.1730 Acc: 0.9681\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0286 Acc: 0.9916\n",
      "Val Loss: 0.2438 Acc: 0.9612\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7915)\n",
      "Train Loss: 0.0374 Acc: 0.9894\n",
      "Val Loss: 0.2170 Acc: 0.9641\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0094 Acc: 0.9978\n",
      "Val Loss: 0.1616 Acc: 0.9705\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0013 Acc: 0.9998\n",
      "Val Loss: 0.1604 Acc: 0.9700\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1584 Acc: 0.9705\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.970452\n"
     ]
    }
   ],
   "source": [
    "best_net48, best_acc48, last_net48 = train_model(net48, train_u8_dl, test_dl, criterion, optimizer48, exp_lr_scheduler_48,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "1w6qitlwdErS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(5578)\n",
      "Train Loss: 1.7798 Acc: 0.6973\n",
      "Val Loss: 0.2945 Acc: 0.9164\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7555)\n",
      "Train Loss: 0.1852 Acc: 0.9444\n",
      "Val Loss: 0.1983 Acc: 0.9414\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7715)\n",
      "Train Loss: 0.1093 Acc: 0.9644\n",
      "Val Loss: 0.1921 Acc: 0.9462\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7793)\n",
      "Train Loss: 0.0804 Acc: 0.9741\n",
      "Val Loss: 0.1628 Acc: 0.9546\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7827)\n",
      "Train Loss: 0.0609 Acc: 0.9784\n",
      "Val Loss: 0.1636 Acc: 0.9561\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7867)\n",
      "Train Loss: 0.0485 Acc: 0.9834\n",
      "Val Loss: 0.1642 Acc: 0.9586\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7880)\n",
      "Train Loss: 0.0437 Acc: 0.9850\n",
      "Val Loss: 0.1624 Acc: 0.9580\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0247 Acc: 0.9925\n",
      "Val Loss: 0.1534 Acc: 0.9659\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0203 Acc: 0.9931\n",
      "Val Loss: 0.1660 Acc: 0.9637\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0454 Acc: 0.9860\n",
      "Val Loss: 0.1943 Acc: 0.9591\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0324 Acc: 0.9885\n",
      "Val Loss: 0.1975 Acc: 0.9596\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0256 Acc: 0.9920\n",
      "Val Loss: 0.1681 Acc: 0.9672\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0177 Acc: 0.9941\n",
      "Val Loss: 0.1960 Acc: 0.9618\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0135 Acc: 0.9958\n",
      "Val Loss: 0.2190 Acc: 0.9566\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0148 Acc: 0.9945\n",
      "Val Loss: 0.1876 Acc: 0.9659\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0117 Acc: 0.9965\n",
      "Val Loss: 0.2159 Acc: 0.9613\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0396 Acc: 0.9892\n",
      "Val Loss: 0.2790 Acc: 0.9544\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0411 Acc: 0.9878\n",
      "Val Loss: 0.2416 Acc: 0.9558\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0256 Acc: 0.9909\n",
      "Val Loss: 0.2330 Acc: 0.9631\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0175 Acc: 0.9949\n",
      "Val Loss: 0.1969 Acc: 0.9682\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0051 Acc: 0.9980\n",
      "Val Loss: 0.1884 Acc: 0.9708\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0010 Acc: 0.9998\n",
      "Val Loss: 0.1873 Acc: 0.9715\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1869 Acc: 0.9713\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.971452\n"
     ]
    }
   ],
   "source": [
    "best_net49, best_acc49, last_net49 = train_model(net49, train_u9_dl, test_dl, criterion, optimizer49, exp_lr_scheduler_49,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "rcBbDPu_dKdA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6326)\n",
      "Train Loss: 1.5190 Acc: 0.7907\n",
      "Val Loss: 0.2461 Acc: 0.9232\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7547)\n",
      "Train Loss: 0.1756 Acc: 0.9434\n",
      "Val Loss: 0.2070 Acc: 0.9360\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7672)\n",
      "Train Loss: 0.1209 Acc: 0.9590\n",
      "Val Loss: 0.1963 Acc: 0.9421\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7779)\n",
      "Train Loss: 0.0880 Acc: 0.9724\n",
      "Val Loss: 0.1608 Acc: 0.9544\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7825)\n",
      "Train Loss: 0.0608 Acc: 0.9781\n",
      "Val Loss: 0.1530 Acc: 0.9582\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0390 Acc: 0.9882\n",
      "Val Loss: 0.1813 Acc: 0.9533\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7900)\n",
      "Train Loss: 0.0400 Acc: 0.9875\n",
      "Val Loss: 0.1598 Acc: 0.9598\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0269 Acc: 0.9910\n",
      "Val Loss: 0.1892 Acc: 0.9581\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0282 Acc: 0.9905\n",
      "Val Loss: 0.1882 Acc: 0.9609\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0248 Acc: 0.9912\n",
      "Val Loss: 0.2068 Acc: 0.9572\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0369 Acc: 0.9885\n",
      "Val Loss: 0.1658 Acc: 0.9637\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0222 Acc: 0.9918\n",
      "Val Loss: 0.1929 Acc: 0.9607\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0260 Acc: 0.9912\n",
      "Val Loss: 0.1773 Acc: 0.9630\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0170 Acc: 0.9942\n",
      "Val Loss: 0.1917 Acc: 0.9668\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0174 Acc: 0.9946\n",
      "Val Loss: 0.2156 Acc: 0.9626\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7890)\n",
      "Train Loss: 0.0473 Acc: 0.9862\n",
      "Val Loss: 0.1986 Acc: 0.9657\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0228 Acc: 0.9926\n",
      "Val Loss: 0.2185 Acc: 0.9644\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0342 Acc: 0.9912\n",
      "Val Loss: 0.2032 Acc: 0.9634\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0163 Acc: 0.9962\n",
      "Val Loss: 0.1813 Acc: 0.9674\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0035 Acc: 0.9991\n",
      "Val Loss: 0.1572 Acc: 0.9729\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0012 Acc: 0.9996\n",
      "Val Loss: 0.1576 Acc: 0.9729\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0004 Acc: 0.9999\n",
      "Val Loss: 0.1585 Acc: 0.9729\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1591 Acc: 0.9732\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.973179\n"
     ]
    }
   ],
   "source": [
    "best_net50, best_acc50, last_net50 = train_model(net50, train_u10_dl, test_dl, criterion, optimizer50, exp_lr_scheduler_50,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "EnC5NR4J0niB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6576)\n",
      "Train Loss: 1.4976 Acc: 0.8220\n",
      "Val Loss: 0.1980 Acc: 0.9387\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7648)\n",
      "Train Loss: 0.1414 Acc: 0.9560\n",
      "Val Loss: 0.1437 Acc: 0.9566\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7816)\n",
      "Train Loss: 0.0743 Acc: 0.9770\n",
      "Val Loss: 0.1399 Acc: 0.9588\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7828)\n",
      "Train Loss: 0.0648 Acc: 0.9785\n",
      "Val Loss: 0.1535 Acc: 0.9599\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0331 Acc: 0.9890\n",
      "Val Loss: 0.1277 Acc: 0.9646\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0229 Acc: 0.9924\n",
      "Val Loss: 0.1419 Acc: 0.9660\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0278 Acc: 0.9908\n",
      "Val Loss: 0.1369 Acc: 0.9685\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0234 Acc: 0.9916\n",
      "Val Loss: 0.1417 Acc: 0.9657\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0138 Acc: 0.9950\n",
      "Val Loss: 0.1430 Acc: 0.9706\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0178 Acc: 0.9950\n",
      "Val Loss: 0.1419 Acc: 0.9709\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0251 Acc: 0.9914\n",
      "Val Loss: 0.1599 Acc: 0.9682\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0161 Acc: 0.9946\n",
      "Val Loss: 0.2495 Acc: 0.9561\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0342 Acc: 0.9891\n",
      "Val Loss: 0.1923 Acc: 0.9646\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0319 Acc: 0.9901\n",
      "Val Loss: 0.2032 Acc: 0.9655\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0221 Acc: 0.9941\n",
      "Val Loss: 0.1636 Acc: 0.9694\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0230 Acc: 0.9930\n",
      "Val Loss: 0.1769 Acc: 0.9686\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0245 Acc: 0.9934\n",
      "Val Loss: 0.1576 Acc: 0.9721\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0156 Acc: 0.9942\n",
      "Val Loss: 0.2025 Acc: 0.9690\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0221 Acc: 0.9942\n",
      "Val Loss: 0.1709 Acc: 0.9726\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0115 Acc: 0.9970\n",
      "Val Loss: 0.1728 Acc: 0.9715\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0025 Acc: 0.9989\n",
      "Val Loss: 0.1586 Acc: 0.9744\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1567 Acc: 0.9749\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1560 Acc: 0.9752\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.975180\n"
     ]
    }
   ],
   "source": [
    "best_net51, best_acc51, last_net51 = train_model(net51, train_v1_dl, test_dl, criterion, optimizer51, exp_lr_scheduler_51,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "id": "6gfhTqN20wmv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6595)\n",
      "Train Loss: 1.3430 Acc: 0.8244\n",
      "Val Loss: 0.2109 Acc: 0.9383\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7673)\n",
      "Train Loss: 0.1328 Acc: 0.9591\n",
      "Val Loss: 0.1289 Acc: 0.9628\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7801)\n",
      "Train Loss: 0.0779 Acc: 0.9751\n",
      "Val Loss: 0.1638 Acc: 0.9531\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7869)\n",
      "Train Loss: 0.0498 Acc: 0.9836\n",
      "Val Loss: 0.1385 Acc: 0.9634\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0373 Acc: 0.9878\n",
      "Val Loss: 0.1857 Acc: 0.9549\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0386 Acc: 0.9876\n",
      "Val Loss: 0.1545 Acc: 0.9608\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7876)\n",
      "Train Loss: 0.0475 Acc: 0.9845\n",
      "Val Loss: 0.1552 Acc: 0.9605\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0281 Acc: 0.9914\n",
      "Val Loss: 0.1347 Acc: 0.9670\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7973)\n",
      "Train Loss: 0.0105 Acc: 0.9966\n",
      "Val Loss: 0.1196 Acc: 0.9747\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0047 Acc: 0.9981\n",
      "Val Loss: 0.1394 Acc: 0.9742\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0422 Acc: 0.9854\n",
      "Val Loss: 0.1411 Acc: 0.9702\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0269 Acc: 0.9915\n",
      "Val Loss: 0.1620 Acc: 0.9681\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0247 Acc: 0.9930\n",
      "Val Loss: 0.1504 Acc: 0.9690\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0142 Acc: 0.9955\n",
      "Val Loss: 0.1705 Acc: 0.9715\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0132 Acc: 0.9961\n",
      "Val Loss: 0.1809 Acc: 0.9703\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0184 Acc: 0.9956\n",
      "Val Loss: 0.1483 Acc: 0.9728\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0097 Acc: 0.9965\n",
      "Val Loss: 0.1661 Acc: 0.9709\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0456 Acc: 0.9874\n",
      "Val Loss: 0.2082 Acc: 0.9685\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0419 Acc: 0.9905\n",
      "Val Loss: 0.2187 Acc: 0.9604\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0329 Acc: 0.9905\n",
      "Val Loss: 0.1669 Acc: 0.9754\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0072 Acc: 0.9978\n",
      "Val Loss: 0.1425 Acc: 0.9776\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0007 Acc: 1.0000\n",
      "Val Loss: 0.1407 Acc: 0.9778\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1398 Acc: 0.9784\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.978362\n"
     ]
    }
   ],
   "source": [
    "best_net52, best_acc52, last_net52 = train_model(net52, train_v2_dl, test_dl, criterion, optimizer52, exp_lr_scheduler_52,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "id": "M0vZw7Ud0wbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6633)\n",
      "Train Loss: 1.0661 Acc: 0.8291\n",
      "Val Loss: 0.2120 Acc: 0.9379\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7552)\n",
      "Train Loss: 0.1658 Acc: 0.9440\n",
      "Val Loss: 0.1526 Acc: 0.9517\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7746)\n",
      "Train Loss: 0.0935 Acc: 0.9683\n",
      "Val Loss: 0.1471 Acc: 0.9556\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7830)\n",
      "Train Loss: 0.0659 Acc: 0.9788\n",
      "Val Loss: 0.1484 Acc: 0.9601\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7866)\n",
      "Train Loss: 0.0478 Acc: 0.9832\n",
      "Val Loss: 0.1431 Acc: 0.9615\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7867)\n",
      "Train Loss: 0.0492 Acc: 0.9834\n",
      "Val Loss: 0.1365 Acc: 0.9656\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0340 Acc: 0.9890\n",
      "Val Loss: 0.1905 Acc: 0.9605\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0296 Acc: 0.9906\n",
      "Val Loss: 0.1588 Acc: 0.9636\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0174 Acc: 0.9934\n",
      "Val Loss: 0.1537 Acc: 0.9665\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0168 Acc: 0.9941\n",
      "Val Loss: 0.1571 Acc: 0.9693\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0118 Acc: 0.9958\n",
      "Val Loss: 0.1510 Acc: 0.9694\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0116 Acc: 0.9954\n",
      "Val Loss: 0.1681 Acc: 0.9683\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0143 Acc: 0.9951\n",
      "Val Loss: 0.1952 Acc: 0.9637\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0386 Acc: 0.9886\n",
      "Val Loss: 0.1983 Acc: 0.9612\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0335 Acc: 0.9890\n",
      "Val Loss: 0.1698 Acc: 0.9644\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0152 Acc: 0.9950\n",
      "Val Loss: 0.2305 Acc: 0.9634\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0183 Acc: 0.9949\n",
      "Val Loss: 0.1615 Acc: 0.9716\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0075 Acc: 0.9971\n",
      "Val Loss: 0.1738 Acc: 0.9700\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0099 Acc: 0.9971\n",
      "Val Loss: 0.2173 Acc: 0.9677\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0196 Acc: 0.9950\n",
      "Val Loss: 0.2309 Acc: 0.9676\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0092 Acc: 0.9965\n",
      "Val Loss: 0.1897 Acc: 0.9731\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0006 Acc: 0.9999\n",
      "Val Loss: 0.1867 Acc: 0.9733\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1857 Acc: 0.9734\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.973361\n"
     ]
    }
   ],
   "source": [
    "best_net53, best_acc53, last_net53 = train_model(net53, train_v3_dl, test_dl, criterion, optimizer53, exp_lr_scheduler_53,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "id": "Vbpbx4GA0wRT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6423)\n",
      "Train Loss: 1.7852 Acc: 0.8029\n",
      "Val Loss: 0.1970 Acc: 0.9424\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7553)\n",
      "Train Loss: 0.1763 Acc: 0.9441\n",
      "Val Loss: 0.1728 Acc: 0.9468\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7696)\n",
      "Train Loss: 0.1182 Acc: 0.9620\n",
      "Val Loss: 0.1491 Acc: 0.9554\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7765)\n",
      "Train Loss: 0.0879 Acc: 0.9706\n",
      "Val Loss: 0.1297 Acc: 0.9642\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7839)\n",
      "Train Loss: 0.0618 Acc: 0.9799\n",
      "Val Loss: 0.1221 Acc: 0.9645\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0384 Acc: 0.9864\n",
      "Val Loss: 0.1403 Acc: 0.9625\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7898)\n",
      "Train Loss: 0.0329 Acc: 0.9872\n",
      "Val Loss: 0.1326 Acc: 0.9667\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0200 Acc: 0.9939\n",
      "Val Loss: 0.1211 Acc: 0.9714\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0253 Acc: 0.9911\n",
      "Val Loss: 0.1678 Acc: 0.9617\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0236 Acc: 0.9916\n",
      "Val Loss: 0.1468 Acc: 0.9671\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0236 Acc: 0.9922\n",
      "Val Loss: 0.1582 Acc: 0.9678\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0295 Acc: 0.9915\n",
      "Val Loss: 0.1589 Acc: 0.9676\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0184 Acc: 0.9929\n",
      "Val Loss: 0.1638 Acc: 0.9684\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0174 Acc: 0.9945\n",
      "Val Loss: 0.1545 Acc: 0.9708\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0094 Acc: 0.9974\n",
      "Val Loss: 0.1722 Acc: 0.9679\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0042 Acc: 0.9985\n",
      "Val Loss: 0.1532 Acc: 0.9729\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0140 Acc: 0.9948\n",
      "Val Loss: 0.1693 Acc: 0.9696\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0393 Acc: 0.9879\n",
      "Val Loss: 0.2031 Acc: 0.9630\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0466 Acc: 0.9869\n",
      "Val Loss: 0.1699 Acc: 0.9655\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0235 Acc: 0.9930\n",
      "Val Loss: 0.1650 Acc: 0.9705\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0047 Acc: 0.9985\n",
      "Val Loss: 0.1473 Acc: 0.9729\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0011 Acc: 0.9999\n",
      "Val Loss: 0.1442 Acc: 0.9735\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0007 Acc: 1.0000\n",
      "Val Loss: 0.1436 Acc: 0.9735\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.973543\n"
     ]
    }
   ],
   "source": [
    "best_net54, best_acc54, last_net54 = train_model(net54, train_v4_dl, test_dl, criterion, optimizer54, exp_lr_scheduler_54,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "id": "TDwyB2tS0wGi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6472)\n",
      "Train Loss: 1.5709 Acc: 0.8090\n",
      "Val Loss: 0.2110 Acc: 0.9374\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7589)\n",
      "Train Loss: 0.1618 Acc: 0.9486\n",
      "Val Loss: 0.1855 Acc: 0.9434\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7717)\n",
      "Train Loss: 0.1010 Acc: 0.9646\n",
      "Val Loss: 0.1424 Acc: 0.9582\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7773)\n",
      "Train Loss: 0.0813 Acc: 0.9716\n",
      "Val Loss: 0.1375 Acc: 0.9591\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7863)\n",
      "Train Loss: 0.0527 Acc: 0.9829\n",
      "Val Loss: 0.1258 Acc: 0.9658\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7869)\n",
      "Train Loss: 0.0485 Acc: 0.9836\n",
      "Val Loss: 0.1444 Acc: 0.9623\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7887)\n",
      "Train Loss: 0.0336 Acc: 0.9859\n",
      "Val Loss: 0.1491 Acc: 0.9627\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0257 Acc: 0.9924\n",
      "Val Loss: 0.1505 Acc: 0.9642\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0249 Acc: 0.9910\n",
      "Val Loss: 0.1918 Acc: 0.9609\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0404 Acc: 0.9878\n",
      "Val Loss: 0.1764 Acc: 0.9612\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0440 Acc: 0.9884\n",
      "Val Loss: 0.1773 Acc: 0.9628\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0305 Acc: 0.9896\n",
      "Val Loss: 0.1726 Acc: 0.9616\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0133 Acc: 0.9955\n",
      "Val Loss: 0.1918 Acc: 0.9647\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0360 Acc: 0.9896\n",
      "Val Loss: 0.1394 Acc: 0.9677\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7973)\n",
      "Train Loss: 0.0112 Acc: 0.9966\n",
      "Val Loss: 0.1426 Acc: 0.9717\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0097 Acc: 0.9969\n",
      "Val Loss: 0.1653 Acc: 0.9686\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0094 Acc: 0.9974\n",
      "Val Loss: 0.1524 Acc: 0.9701\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0229 Acc: 0.9928\n",
      "Val Loss: 0.1790 Acc: 0.9667\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7887)\n",
      "Train Loss: 0.0488 Acc: 0.9859\n",
      "Val Loss: 0.2104 Acc: 0.9619\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0146 Acc: 0.9949\n",
      "Val Loss: 0.2089 Acc: 0.9653\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0079 Acc: 0.9982\n",
      "Val Loss: 0.1508 Acc: 0.9728\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0007 Acc: 1.0000\n",
      "Val Loss: 0.1487 Acc: 0.9731\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1484 Acc: 0.9734\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.973361\n"
     ]
    }
   ],
   "source": [
    "best_net55, best_acc55, last_net55 = train_model(net55, train_v5_dl, test_dl, criterion, optimizer55, exp_lr_scheduler_55,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "id": "J7MIdNng0v6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6745)\n",
      "Train Loss: 1.1029 Acc: 0.8431\n",
      "Val Loss: 0.1484 Acc: 0.9539\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7712)\n",
      "Train Loss: 0.1145 Acc: 0.9640\n",
      "Val Loss: 0.1172 Acc: 0.9643\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7834)\n",
      "Train Loss: 0.0625 Acc: 0.9792\n",
      "Val Loss: 0.1359 Acc: 0.9605\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7853)\n",
      "Train Loss: 0.0524 Acc: 0.9816\n",
      "Val Loss: 0.1144 Acc: 0.9661\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0308 Acc: 0.9902\n",
      "Val Loss: 0.0964 Acc: 0.9725\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0144 Acc: 0.9956\n",
      "Val Loss: 0.1117 Acc: 0.9722\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0082 Acc: 0.9975\n",
      "Val Loss: 0.1679 Acc: 0.9640\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0263 Acc: 0.9900\n",
      "Val Loss: 0.1319 Acc: 0.9703\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7863)\n",
      "Train Loss: 0.0573 Acc: 0.9829\n",
      "Val Loss: 0.1530 Acc: 0.9641\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0243 Acc: 0.9919\n",
      "Val Loss: 0.1212 Acc: 0.9716\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0131 Acc: 0.9954\n",
      "Val Loss: 0.1388 Acc: 0.9730\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0142 Acc: 0.9954\n",
      "Val Loss: 0.1708 Acc: 0.9695\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0226 Acc: 0.9934\n",
      "Val Loss: 0.1829 Acc: 0.9660\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0178 Acc: 0.9945\n",
      "Val Loss: 0.1755 Acc: 0.9682\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0161 Acc: 0.9955\n",
      "Val Loss: 0.1660 Acc: 0.9689\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0354 Acc: 0.9896\n",
      "Val Loss: 0.1964 Acc: 0.9610\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0198 Acc: 0.9950\n",
      "Val Loss: 0.1254 Acc: 0.9754\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0092 Acc: 0.9968\n",
      "Val Loss: 0.1524 Acc: 0.9738\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0232 Acc: 0.9936\n",
      "Val Loss: 0.1831 Acc: 0.9692\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0397 Acc: 0.9908\n",
      "Val Loss: 0.2345 Acc: 0.9620\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0130 Acc: 0.9965\n",
      "Val Loss: 0.1613 Acc: 0.9734\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0016 Acc: 0.9999\n",
      "Val Loss: 0.1578 Acc: 0.9743\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1567 Acc: 0.9746\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.975361\n"
     ]
    }
   ],
   "source": [
    "best_net56, best_acc56, last_net56 = train_model(net56, train_v6_dl, test_dl, criterion, optimizer56, exp_lr_scheduler_56,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "id": "OKGHrRIY0vtu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6140)\n",
      "Train Loss: 1.6588 Acc: 0.7675\n",
      "Val Loss: 0.2155 Acc: 0.9322\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7581)\n",
      "Train Loss: 0.1650 Acc: 0.9476\n",
      "Val Loss: 0.1633 Acc: 0.9505\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7757)\n",
      "Train Loss: 0.0936 Acc: 0.9696\n",
      "Val Loss: 0.1412 Acc: 0.9602\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7846)\n",
      "Train Loss: 0.0593 Acc: 0.9808\n",
      "Val Loss: 0.1241 Acc: 0.9664\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0414 Acc: 0.9861\n",
      "Val Loss: 0.1477 Acc: 0.9607\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0273 Acc: 0.9896\n",
      "Val Loss: 0.1306 Acc: 0.9681\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0248 Acc: 0.9921\n",
      "Val Loss: 0.1681 Acc: 0.9605\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0226 Acc: 0.9915\n",
      "Val Loss: 0.1842 Acc: 0.9622\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7905)\n",
      "Train Loss: 0.0343 Acc: 0.9881\n",
      "Val Loss: 0.1657 Acc: 0.9653\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0169 Acc: 0.9935\n",
      "Val Loss: 0.1637 Acc: 0.9672\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0242 Acc: 0.9924\n",
      "Val Loss: 0.1650 Acc: 0.9700\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0216 Acc: 0.9945\n",
      "Val Loss: 0.1686 Acc: 0.9663\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0297 Acc: 0.9906\n",
      "Val Loss: 0.1770 Acc: 0.9680\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0191 Acc: 0.9940\n",
      "Val Loss: 0.1466 Acc: 0.9730\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0052 Acc: 0.9984\n",
      "Val Loss: 0.1317 Acc: 0.9760\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1320 Acc: 0.9781\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1332 Acc: 0.9781\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1340 Acc: 0.9783\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1347 Acc: 0.9781\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1353 Acc: 0.9782\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1354 Acc: 0.9782\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1354 Acc: 0.9782\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1355 Acc: 0.9782\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.978271\n"
     ]
    }
   ],
   "source": [
    "best_net57, best_acc57, last_net57 = train_model(net57, train_v7_dl, test_dl, criterion, optimizer57, exp_lr_scheduler_57,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "Fl_-VohB0vhf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6763)\n",
      "Train Loss: 0.8428 Acc: 0.8454\n",
      "Val Loss: 0.1556 Acc: 0.9511\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7705)\n",
      "Train Loss: 0.1185 Acc: 0.9631\n",
      "Val Loss: 0.1512 Acc: 0.9563\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7809)\n",
      "Train Loss: 0.0723 Acc: 0.9761\n",
      "Val Loss: 0.1189 Acc: 0.9638\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0402 Acc: 0.9861\n",
      "Val Loss: 0.1186 Acc: 0.9691\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0393 Acc: 0.9869\n",
      "Val Loss: 0.1709 Acc: 0.9573\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7876)\n",
      "Train Loss: 0.0441 Acc: 0.9845\n",
      "Val Loss: 0.2048 Acc: 0.9560\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0289 Acc: 0.9909\n",
      "Val Loss: 0.1507 Acc: 0.9668\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0147 Acc: 0.9949\n",
      "Val Loss: 0.1140 Acc: 0.9738\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0062 Acc: 0.9982\n",
      "Val Loss: 0.1152 Acc: 0.9766\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0142 Acc: 0.9960\n",
      "Val Loss: 0.1705 Acc: 0.9648\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0462 Acc: 0.9860\n",
      "Val Loss: 0.1731 Acc: 0.9665\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0350 Acc: 0.9889\n",
      "Val Loss: 0.1592 Acc: 0.9665\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0205 Acc: 0.9926\n",
      "Val Loss: 0.1273 Acc: 0.9715\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0092 Acc: 0.9970\n",
      "Val Loss: 0.1400 Acc: 0.9723\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0102 Acc: 0.9969\n",
      "Val Loss: 0.1785 Acc: 0.9695\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0173 Acc: 0.9951\n",
      "Val Loss: 0.1876 Acc: 0.9637\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0288 Acc: 0.9919\n",
      "Val Loss: 0.2380 Acc: 0.9607\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0214 Acc: 0.9939\n",
      "Val Loss: 0.1608 Acc: 0.9715\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0279 Acc: 0.9916\n",
      "Val Loss: 0.1436 Acc: 0.9708\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0071 Acc: 0.9971\n",
      "Val Loss: 0.1541 Acc: 0.9718\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0038 Acc: 0.9988\n",
      "Val Loss: 0.1268 Acc: 0.9767\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1239 Acc: 0.9776\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1230 Acc: 0.9773\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.977634\n"
     ]
    }
   ],
   "source": [
    "best_net58, best_acc58, last_net58 = train_model(net58, train_v8_dl, test_dl, criterion, optimizer58, exp_lr_scheduler_58,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "iP6-IPc10vXW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6799)\n",
      "Train Loss: 1.0771 Acc: 0.8499\n",
      "Val Loss: 0.1771 Acc: 0.9436\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7718)\n",
      "Train Loss: 0.1162 Acc: 0.9647\n",
      "Val Loss: 0.1367 Acc: 0.9609\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7804)\n",
      "Train Loss: 0.0741 Acc: 0.9755\n",
      "Val Loss: 0.1331 Acc: 0.9627\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7872)\n",
      "Train Loss: 0.0443 Acc: 0.9840\n",
      "Val Loss: 0.1465 Acc: 0.9637\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0503 Acc: 0.9854\n",
      "Val Loss: 0.1751 Acc: 0.9556\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0336 Acc: 0.9882\n",
      "Val Loss: 0.1522 Acc: 0.9650\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0327 Acc: 0.9900\n",
      "Val Loss: 0.1422 Acc: 0.9674\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0322 Acc: 0.9912\n",
      "Val Loss: 0.1440 Acc: 0.9687\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0227 Acc: 0.9922\n",
      "Val Loss: 0.1938 Acc: 0.9656\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0165 Acc: 0.9954\n",
      "Val Loss: 0.1276 Acc: 0.9736\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0052 Acc: 0.9986\n",
      "Val Loss: 0.1316 Acc: 0.9755\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0096 Acc: 0.9970\n",
      "Val Loss: 0.2362 Acc: 0.9648\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0309 Acc: 0.9912\n",
      "Val Loss: 0.2966 Acc: 0.9461\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7892)\n",
      "Train Loss: 0.0417 Acc: 0.9865\n",
      "Val Loss: 0.2954 Acc: 0.9545\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0424 Acc: 0.9882\n",
      "Val Loss: 0.1835 Acc: 0.9702\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0265 Acc: 0.9920\n",
      "Val Loss: 0.1702 Acc: 0.9685\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0129 Acc: 0.9958\n",
      "Val Loss: 0.1598 Acc: 0.9731\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0107 Acc: 0.9970\n",
      "Val Loss: 0.1752 Acc: 0.9731\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0135 Acc: 0.9960\n",
      "Val Loss: 0.1641 Acc: 0.9741\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0066 Acc: 0.9982\n",
      "Val Loss: 0.1462 Acc: 0.9744\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7994)\n",
      "Train Loss: 0.0018 Acc: 0.9992\n",
      "Val Loss: 0.1343 Acc: 0.9785\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1337 Acc: 0.9786\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1336 Acc: 0.9786\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.978634\n"
     ]
    }
   ],
   "source": [
    "best_net59, best_acc59, last_net59 = train_model(net59, train_v9_dl, test_dl, criterion, optimizer59, exp_lr_scheduler_59,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "id": "oI2mW5_-0vIS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6760)\n",
      "Train Loss: 1.2491 Acc: 0.8450\n",
      "Val Loss: 0.1847 Acc: 0.9420\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7652)\n",
      "Train Loss: 0.1352 Acc: 0.9565\n",
      "Val Loss: 0.1554 Acc: 0.9543\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7806)\n",
      "Train Loss: 0.0825 Acc: 0.9758\n",
      "Val Loss: 0.1474 Acc: 0.9558\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7874)\n",
      "Train Loss: 0.0482 Acc: 0.9842\n",
      "Val Loss: 0.1294 Acc: 0.9657\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0402 Acc: 0.9860\n",
      "Val Loss: 0.1117 Acc: 0.9705\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0343 Acc: 0.9879\n",
      "Val Loss: 0.1297 Acc: 0.9681\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0254 Acc: 0.9920\n",
      "Val Loss: 0.1530 Acc: 0.9637\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0229 Acc: 0.9918\n",
      "Val Loss: 0.1228 Acc: 0.9716\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0103 Acc: 0.9968\n",
      "Val Loss: 0.1444 Acc: 0.9695\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0081 Acc: 0.9979\n",
      "Val Loss: 0.1439 Acc: 0.9710\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0173 Acc: 0.9960\n",
      "Val Loss: 0.1865 Acc: 0.9658\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0384 Acc: 0.9882\n",
      "Val Loss: 0.2249 Acc: 0.9492\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0421 Acc: 0.9882\n",
      "Val Loss: 0.1851 Acc: 0.9631\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0236 Acc: 0.9941\n",
      "Val Loss: 0.1424 Acc: 0.9709\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0174 Acc: 0.9945\n",
      "Val Loss: 0.1404 Acc: 0.9715\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0069 Acc: 0.9979\n",
      "Val Loss: 0.1321 Acc: 0.9749\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0006 Acc: 0.9999\n",
      "Val Loss: 0.1286 Acc: 0.9775\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0024 Acc: 0.9994\n",
      "Val Loss: 0.1463 Acc: 0.9756\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0051 Acc: 0.9982\n",
      "Val Loss: 0.1762 Acc: 0.9698\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0096 Acc: 0.9968\n",
      "Val Loss: 0.1813 Acc: 0.9670\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0034 Acc: 0.9991\n",
      "Val Loss: 0.1549 Acc: 0.9718\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1531 Acc: 0.9725\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1519 Acc: 0.9728\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.977543\n"
     ]
    }
   ],
   "source": [
    "best_net60, best_acc60, last_net60 = train_model(net60, train_v10_dl, test_dl, criterion, optimizer60, exp_lr_scheduler_60,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "id": "6Mha3Okv2ln7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6549)\n",
      "Train Loss: 1.1335 Acc: 0.8186\n",
      "Val Loss: 0.1953 Acc: 0.9364\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7644)\n",
      "Train Loss: 0.1417 Acc: 0.9555\n",
      "Val Loss: 0.1397 Acc: 0.9549\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7805)\n",
      "Train Loss: 0.0705 Acc: 0.9756\n",
      "Val Loss: 0.1341 Acc: 0.9602\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7855)\n",
      "Train Loss: 0.0528 Acc: 0.9819\n",
      "Val Loss: 0.1231 Acc: 0.9650\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0318 Acc: 0.9901\n",
      "Val Loss: 0.1082 Acc: 0.9695\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0254 Acc: 0.9914\n",
      "Val Loss: 0.1600 Acc: 0.9618\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0260 Acc: 0.9914\n",
      "Val Loss: 0.1246 Acc: 0.9711\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0386 Acc: 0.9879\n",
      "Val Loss: 0.1631 Acc: 0.9645\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0297 Acc: 0.9905\n",
      "Val Loss: 0.1264 Acc: 0.9705\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0264 Acc: 0.9909\n",
      "Val Loss: 0.1267 Acc: 0.9712\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0180 Acc: 0.9945\n",
      "Val Loss: 0.1599 Acc: 0.9702\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0135 Acc: 0.9961\n",
      "Val Loss: 0.1847 Acc: 0.9665\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0158 Acc: 0.9949\n",
      "Val Loss: 0.1332 Acc: 0.9725\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0197 Acc: 0.9940\n",
      "Val Loss: 0.1719 Acc: 0.9664\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0310 Acc: 0.9914\n",
      "Val Loss: 0.1545 Acc: 0.9702\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0299 Acc: 0.9920\n",
      "Val Loss: 0.1746 Acc: 0.9674\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0170 Acc: 0.9949\n",
      "Val Loss: 0.1458 Acc: 0.9699\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0054 Acc: 0.9978\n",
      "Val Loss: 0.1416 Acc: 0.9767\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7994)\n",
      "Train Loss: 0.0037 Acc: 0.9992\n",
      "Val Loss: 0.1439 Acc: 0.9742\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0057 Acc: 0.9982\n",
      "Val Loss: 0.1843 Acc: 0.9676\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0039 Acc: 0.9989\n",
      "Val Loss: 0.1533 Acc: 0.9752\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1515 Acc: 0.9756\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1505 Acc: 0.9756\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.976725\n"
     ]
    }
   ],
   "source": [
    "best_net61, best_acc61, last_net61 = train_model(net61, train_w1_dl, test_dl, criterion, optimizer61, exp_lr_scheduler_61,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "id": "FseTAeIt2vWw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6510)\n",
      "Train Loss: 1.2843 Acc: 0.8137\n",
      "Val Loss: 0.1966 Acc: 0.9363\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7663)\n",
      "Train Loss: 0.1336 Acc: 0.9579\n",
      "Val Loss: 0.1479 Acc: 0.9560\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7807)\n",
      "Train Loss: 0.0720 Acc: 0.9759\n",
      "Val Loss: 0.1262 Acc: 0.9633\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7856)\n",
      "Train Loss: 0.0512 Acc: 0.9820\n",
      "Val Loss: 0.1377 Acc: 0.9593\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7886)\n",
      "Train Loss: 0.0395 Acc: 0.9858\n",
      "Val Loss: 0.1662 Acc: 0.9565\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0278 Acc: 0.9905\n",
      "Val Loss: 0.1358 Acc: 0.9687\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0162 Acc: 0.9948\n",
      "Val Loss: 0.1342 Acc: 0.9687\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0202 Acc: 0.9935\n",
      "Val Loss: 0.1434 Acc: 0.9669\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0174 Acc: 0.9944\n",
      "Val Loss: 0.1483 Acc: 0.9665\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0247 Acc: 0.9925\n",
      "Val Loss: 0.1729 Acc: 0.9651\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0295 Acc: 0.9906\n",
      "Val Loss: 0.1731 Acc: 0.9657\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0177 Acc: 0.9946\n",
      "Val Loss: 0.1795 Acc: 0.9674\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7900)\n",
      "Train Loss: 0.0409 Acc: 0.9875\n",
      "Val Loss: 0.1549 Acc: 0.9671\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0174 Acc: 0.9954\n",
      "Val Loss: 0.1713 Acc: 0.9675\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0172 Acc: 0.9946\n",
      "Val Loss: 0.1816 Acc: 0.9628\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0124 Acc: 0.9956\n",
      "Val Loss: 0.1627 Acc: 0.9679\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0217 Acc: 0.9949\n",
      "Val Loss: 0.1462 Acc: 0.9707\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0047 Acc: 0.9991\n",
      "Val Loss: 0.1460 Acc: 0.9740\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0051 Acc: 0.9984\n",
      "Val Loss: 0.1703 Acc: 0.9711\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0092 Acc: 0.9971\n",
      "Val Loss: 0.1996 Acc: 0.9717\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0065 Acc: 0.9985\n",
      "Val Loss: 0.1626 Acc: 0.9745\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1612 Acc: 0.9751\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1604 Acc: 0.9748\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.975089\n"
     ]
    }
   ],
   "source": [
    "best_net62, best_acc62, last_net62 = train_model(net62, train_w2_dl, test_dl, criterion, optimizer62, exp_lr_scheduler_62,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "id": "W_pcr0xa2-b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6480)\n",
      "Train Loss: 1.2500 Acc: 0.8100\n",
      "Val Loss: 0.2079 Acc: 0.9357\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7678)\n",
      "Train Loss: 0.1340 Acc: 0.9597\n",
      "Val Loss: 0.1789 Acc: 0.9462\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7771)\n",
      "Train Loss: 0.0862 Acc: 0.9714\n",
      "Val Loss: 0.1419 Acc: 0.9615\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7844)\n",
      "Train Loss: 0.0611 Acc: 0.9805\n",
      "Val Loss: 0.1450 Acc: 0.9618\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7887)\n",
      "Train Loss: 0.0392 Acc: 0.9859\n",
      "Val Loss: 0.1627 Acc: 0.9625\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0386 Acc: 0.9871\n",
      "Val Loss: 0.1356 Acc: 0.9655\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0303 Acc: 0.9892\n",
      "Val Loss: 0.1281 Acc: 0.9694\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0209 Acc: 0.9932\n",
      "Val Loss: 0.1275 Acc: 0.9696\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0140 Acc: 0.9945\n",
      "Val Loss: 0.1561 Acc: 0.9675\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0299 Acc: 0.9891\n",
      "Val Loss: 0.1531 Acc: 0.9677\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0414 Acc: 0.9876\n",
      "Val Loss: 0.1802 Acc: 0.9605\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0259 Acc: 0.9926\n",
      "Val Loss: 0.1692 Acc: 0.9654\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0127 Acc: 0.9952\n",
      "Val Loss: 0.1498 Acc: 0.9700\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0124 Acc: 0.9962\n",
      "Val Loss: 0.1442 Acc: 0.9735\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0142 Acc: 0.9949\n",
      "Val Loss: 0.1377 Acc: 0.9745\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0129 Acc: 0.9958\n",
      "Val Loss: 0.2400 Acc: 0.9637\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0318 Acc: 0.9910\n",
      "Val Loss: 0.1879 Acc: 0.9647\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0110 Acc: 0.9965\n",
      "Val Loss: 0.1699 Acc: 0.9726\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0271 Acc: 0.9928\n",
      "Val Loss: 0.1707 Acc: 0.9681\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0266 Acc: 0.9934\n",
      "Val Loss: 0.1615 Acc: 0.9714\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0037 Acc: 0.9986\n",
      "Val Loss: 0.1479 Acc: 0.9743\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1468 Acc: 0.9747\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1461 Acc: 0.9751\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.975089\n"
     ]
    }
   ],
   "source": [
    "best_net63, best_acc63, last_net63 = train_model(net63, train_w3_dl, test_dl, criterion, optimizer63, exp_lr_scheduler_63,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "id": "a5k4F8i43LDP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6395)\n",
      "Train Loss: 1.5807 Acc: 0.7994\n",
      "Val Loss: 0.2288 Acc: 0.9297\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7637)\n",
      "Train Loss: 0.1458 Acc: 0.9546\n",
      "Val Loss: 0.1626 Acc: 0.9482\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7735)\n",
      "Train Loss: 0.0924 Acc: 0.9669\n",
      "Val Loss: 0.1807 Acc: 0.9535\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7842)\n",
      "Train Loss: 0.0616 Acc: 0.9802\n",
      "Val Loss: 0.1139 Acc: 0.9654\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0356 Acc: 0.9884\n",
      "Val Loss: 0.1129 Acc: 0.9685\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0235 Acc: 0.9924\n",
      "Val Loss: 0.1284 Acc: 0.9667\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0247 Acc: 0.9909\n",
      "Val Loss: 0.1190 Acc: 0.9688\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0275 Acc: 0.9911\n",
      "Val Loss: 0.1298 Acc: 0.9721\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0215 Acc: 0.9928\n",
      "Val Loss: 0.1996 Acc: 0.9591\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0287 Acc: 0.9911\n",
      "Val Loss: 0.1468 Acc: 0.9692\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0373 Acc: 0.9871\n",
      "Val Loss: 0.1523 Acc: 0.9673\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0279 Acc: 0.9906\n",
      "Val Loss: 0.1428 Acc: 0.9684\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0095 Acc: 0.9970\n",
      "Val Loss: 0.1308 Acc: 0.9732\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0092 Acc: 0.9971\n",
      "Val Loss: 0.1421 Acc: 0.9721\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0112 Acc: 0.9965\n",
      "Val Loss: 0.1424 Acc: 0.9745\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0061 Acc: 0.9979\n",
      "Val Loss: 0.1439 Acc: 0.9727\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0128 Acc: 0.9962\n",
      "Val Loss: 0.1463 Acc: 0.9727\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0397 Acc: 0.9892\n",
      "Val Loss: 0.1660 Acc: 0.9671\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0290 Acc: 0.9911\n",
      "Val Loss: 0.1899 Acc: 0.9633\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0192 Acc: 0.9944\n",
      "Val Loss: 0.2003 Acc: 0.9662\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0045 Acc: 0.9975\n",
      "Val Loss: 0.1553 Acc: 0.9739\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1520 Acc: 0.9749\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1508 Acc: 0.9749\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.974907\n"
     ]
    }
   ],
   "source": [
    "best_net64, best_acc64, last_net64 = train_model(net64, train_w4_dl, test_dl, criterion, optimizer64, exp_lr_scheduler_64,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "id": "8nfn8bpo3S5_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6567)\n",
      "Train Loss: 1.0863 Acc: 0.8209\n",
      "Val Loss: 0.2088 Acc: 0.9355\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7534)\n",
      "Train Loss: 0.1762 Acc: 0.9417\n",
      "Val Loss: 0.2282 Acc: 0.9307\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7726)\n",
      "Train Loss: 0.1057 Acc: 0.9657\n",
      "Val Loss: 0.1357 Acc: 0.9595\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7804)\n",
      "Train Loss: 0.0719 Acc: 0.9755\n",
      "Val Loss: 0.1825 Acc: 0.9470\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7867)\n",
      "Train Loss: 0.0499 Acc: 0.9834\n",
      "Val Loss: 0.1274 Acc: 0.9663\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0273 Acc: 0.9901\n",
      "Val Loss: 0.1405 Acc: 0.9665\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0208 Acc: 0.9915\n",
      "Val Loss: 0.1930 Acc: 0.9543\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0389 Acc: 0.9864\n",
      "Val Loss: 0.1370 Acc: 0.9665\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0260 Acc: 0.9918\n",
      "Val Loss: 0.1487 Acc: 0.9648\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0252 Acc: 0.9920\n",
      "Val Loss: 0.1884 Acc: 0.9622\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0237 Acc: 0.9916\n",
      "Val Loss: 0.1388 Acc: 0.9735\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0148 Acc: 0.9954\n",
      "Val Loss: 0.1655 Acc: 0.9665\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0304 Acc: 0.9901\n",
      "Val Loss: 0.1652 Acc: 0.9655\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0243 Acc: 0.9914\n",
      "Val Loss: 0.1812 Acc: 0.9714\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0421 Acc: 0.9869\n",
      "Val Loss: 0.1852 Acc: 0.9645\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7919)\n",
      "Train Loss: 0.0333 Acc: 0.9899\n",
      "Val Loss: 0.1587 Acc: 0.9707\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0174 Acc: 0.9948\n",
      "Val Loss: 0.1617 Acc: 0.9699\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0048 Acc: 0.9989\n",
      "Val Loss: 0.1239 Acc: 0.9773\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0132 Acc: 0.9958\n",
      "Val Loss: 0.1827 Acc: 0.9709\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0115 Acc: 0.9969\n",
      "Val Loss: 0.1416 Acc: 0.9746\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0010 Acc: 0.9996\n",
      "Val Loss: 0.1389 Acc: 0.9756\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1372 Acc: 0.9758\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1368 Acc: 0.9758\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.977271\n"
     ]
    }
   ],
   "source": [
    "best_net65, best_acc65, last_net65 = train_model(net65, train_w5_dl, test_dl, criterion, optimizer65, exp_lr_scheduler_65,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "id": "WGwYVMoU3Sus"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6743)\n",
      "Train Loss: 1.3529 Acc: 0.8429\n",
      "Val Loss: 0.1837 Acc: 0.9442\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7655)\n",
      "Train Loss: 0.1337 Acc: 0.9569\n",
      "Val Loss: 0.1372 Acc: 0.9616\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7791)\n",
      "Train Loss: 0.0813 Acc: 0.9739\n",
      "Val Loss: 0.1681 Acc: 0.9540\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7824)\n",
      "Train Loss: 0.0704 Acc: 0.9780\n",
      "Val Loss: 0.1305 Acc: 0.9637\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7869)\n",
      "Train Loss: 0.0471 Acc: 0.9836\n",
      "Val Loss: 0.1162 Acc: 0.9729\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0376 Acc: 0.9879\n",
      "Val Loss: 0.1346 Acc: 0.9673\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0361 Acc: 0.9861\n",
      "Val Loss: 0.1384 Acc: 0.9677\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0318 Acc: 0.9904\n",
      "Val Loss: 0.1473 Acc: 0.9697\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0186 Acc: 0.9939\n",
      "Val Loss: 0.2298 Acc: 0.9548\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7915)\n",
      "Train Loss: 0.0378 Acc: 0.9894\n",
      "Val Loss: 0.1580 Acc: 0.9699\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0202 Acc: 0.9942\n",
      "Val Loss: 0.1703 Acc: 0.9663\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0211 Acc: 0.9928\n",
      "Val Loss: 0.1455 Acc: 0.9732\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0203 Acc: 0.9942\n",
      "Val Loss: 0.1640 Acc: 0.9694\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0169 Acc: 0.9951\n",
      "Val Loss: 0.1567 Acc: 0.9691\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0260 Acc: 0.9929\n",
      "Val Loss: 0.1598 Acc: 0.9699\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0136 Acc: 0.9959\n",
      "Val Loss: 0.1652 Acc: 0.9722\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0098 Acc: 0.9955\n",
      "Val Loss: 0.2182 Acc: 0.9646\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0274 Acc: 0.9928\n",
      "Val Loss: 0.2332 Acc: 0.9661\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0410 Acc: 0.9898\n",
      "Val Loss: 0.2349 Acc: 0.9672\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0186 Acc: 0.9941\n",
      "Val Loss: 0.1940 Acc: 0.9712\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0052 Acc: 0.9988\n",
      "Val Loss: 0.1793 Acc: 0.9746\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0007 Acc: 0.9996\n",
      "Val Loss: 0.1789 Acc: 0.9745\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1787 Acc: 0.9747\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.974725\n"
     ]
    }
   ],
   "source": [
    "best_net66, best_acc66, last_net66 = train_model(net66, train_w6_dl, test_dl, criterion, optimizer66, exp_lr_scheduler_66,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "WfNABaWg3SkH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6353)\n",
      "Train Loss: 1.2576 Acc: 0.7941\n",
      "Val Loss: 0.2280 Acc: 0.9275\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7637)\n",
      "Train Loss: 0.1471 Acc: 0.9546\n",
      "Val Loss: 0.1347 Acc: 0.9574\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7818)\n",
      "Train Loss: 0.0693 Acc: 0.9772\n",
      "Val Loss: 0.1289 Acc: 0.9644\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7877)\n",
      "Train Loss: 0.0501 Acc: 0.9846\n",
      "Val Loss: 0.1307 Acc: 0.9615\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7900)\n",
      "Train Loss: 0.0369 Acc: 0.9875\n",
      "Val Loss: 0.1637 Acc: 0.9551\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0277 Acc: 0.9910\n",
      "Val Loss: 0.1442 Acc: 0.9648\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0352 Acc: 0.9882\n",
      "Val Loss: 0.1806 Acc: 0.9578\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0321 Acc: 0.9889\n",
      "Val Loss: 0.2294 Acc: 0.9514\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0337 Acc: 0.9901\n",
      "Val Loss: 0.1597 Acc: 0.9663\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0189 Acc: 0.9935\n",
      "Val Loss: 0.1419 Acc: 0.9696\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0219 Acc: 0.9931\n",
      "Val Loss: 0.1840 Acc: 0.9682\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0295 Acc: 0.9900\n",
      "Val Loss: 0.1755 Acc: 0.9648\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0216 Acc: 0.9936\n",
      "Val Loss: 0.1364 Acc: 0.9715\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0065 Acc: 0.9981\n",
      "Val Loss: 0.1493 Acc: 0.9702\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0119 Acc: 0.9960\n",
      "Val Loss: 0.1485 Acc: 0.9722\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0083 Acc: 0.9978\n",
      "Val Loss: 0.1791 Acc: 0.9676\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0322 Acc: 0.9904\n",
      "Val Loss: 0.2587 Acc: 0.9545\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0220 Acc: 0.9929\n",
      "Val Loss: 0.1946 Acc: 0.9682\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0303 Acc: 0.9906\n",
      "Val Loss: 0.1875 Acc: 0.9671\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0165 Acc: 0.9958\n",
      "Val Loss: 0.1842 Acc: 0.9701\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0047 Acc: 0.9984\n",
      "Val Loss: 0.1693 Acc: 0.9721\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1685 Acc: 0.9720\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1681 Acc: 0.9722\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.972179\n"
     ]
    }
   ],
   "source": [
    "best_net67, best_acc67, last_net67 = train_model(net67, train_w7_dl, test_dl, criterion, optimizer67, exp_lr_scheduler_67,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "id": "V0jZZuvE3SZx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6686)\n",
      "Train Loss: 1.2127 Acc: 0.8357\n",
      "Val Loss: 0.1827 Acc: 0.9455\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7686)\n",
      "Train Loss: 0.1246 Acc: 0.9607\n",
      "Val Loss: 0.1284 Acc: 0.9598\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7820)\n",
      "Train Loss: 0.0692 Acc: 0.9775\n",
      "Val Loss: 0.1578 Acc: 0.9573\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7894)\n",
      "Train Loss: 0.0430 Acc: 0.9868\n",
      "Val Loss: 0.1283 Acc: 0.9659\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7892)\n",
      "Train Loss: 0.0392 Acc: 0.9865\n",
      "Val Loss: 0.1961 Acc: 0.9495\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0358 Acc: 0.9878\n",
      "Val Loss: 0.1041 Acc: 0.9744\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0146 Acc: 0.9955\n",
      "Val Loss: 0.1252 Acc: 0.9706\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0272 Acc: 0.9906\n",
      "Val Loss: 0.1468 Acc: 0.9650\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0337 Acc: 0.9892\n",
      "Val Loss: 0.1994 Acc: 0.9577\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0347 Acc: 0.9904\n",
      "Val Loss: 0.1397 Acc: 0.9723\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0134 Acc: 0.9961\n",
      "Val Loss: 0.1337 Acc: 0.9719\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0074 Acc: 0.9979\n",
      "Val Loss: 0.1061 Acc: 0.9757\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0011 Acc: 0.9999\n",
      "Val Loss: 0.1052 Acc: 0.9772\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1040 Acc: 0.9789\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1030 Acc: 0.9792\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1044 Acc: 0.9788\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1051 Acc: 0.9787\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1059 Acc: 0.9786\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1067 Acc: 0.9786\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1074 Acc: 0.9788\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1075 Acc: 0.9789\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1076 Acc: 0.9789\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1076 Acc: 0.9790\n",
      "\n",
      "Training complete in 6m 15s\n",
      "Best val Acc: 0.979180\n"
     ]
    }
   ],
   "source": [
    "best_net68, best_acc68, last_net68 = train_model(net68, train_w8_dl, test_dl, criterion, optimizer68, exp_lr_scheduler_68,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "id": "S4nngEM73SND"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6626)\n",
      "Train Loss: 1.2722 Acc: 0.8283\n",
      "Val Loss: 0.1740 Acc: 0.9441\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7693)\n",
      "Train Loss: 0.1228 Acc: 0.9616\n",
      "Val Loss: 0.1542 Acc: 0.9553\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7826)\n",
      "Train Loss: 0.0699 Acc: 0.9782\n",
      "Val Loss: 0.1189 Acc: 0.9682\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0369 Acc: 0.9869\n",
      "Val Loss: 0.1129 Acc: 0.9699\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0350 Acc: 0.9879\n",
      "Val Loss: 0.1426 Acc: 0.9646\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0329 Acc: 0.9891\n",
      "Val Loss: 0.1399 Acc: 0.9673\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0254 Acc: 0.9920\n",
      "Val Loss: 0.1324 Acc: 0.9715\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7892)\n",
      "Train Loss: 0.0384 Acc: 0.9865\n",
      "Val Loss: 0.1325 Acc: 0.9714\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0197 Acc: 0.9934\n",
      "Val Loss: 0.1366 Acc: 0.9730\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0193 Acc: 0.9932\n",
      "Val Loss: 0.1452 Acc: 0.9709\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0181 Acc: 0.9940\n",
      "Val Loss: 0.1913 Acc: 0.9683\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0376 Acc: 0.9891\n",
      "Val Loss: 0.1430 Acc: 0.9704\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0200 Acc: 0.9941\n",
      "Val Loss: 0.1735 Acc: 0.9659\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0159 Acc: 0.9948\n",
      "Val Loss: 0.1428 Acc: 0.9755\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0051 Acc: 0.9982\n",
      "Val Loss: 0.1239 Acc: 0.9794\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0069 Acc: 0.9986\n",
      "Val Loss: 0.1451 Acc: 0.9738\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0074 Acc: 0.9975\n",
      "Val Loss: 0.1500 Acc: 0.9745\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0144 Acc: 0.9954\n",
      "Val Loss: 0.1690 Acc: 0.9725\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0273 Acc: 0.9932\n",
      "Val Loss: 0.2126 Acc: 0.9691\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7877)\n",
      "Train Loss: 0.0615 Acc: 0.9846\n",
      "Val Loss: 0.1861 Acc: 0.9663\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0133 Acc: 0.9959\n",
      "Val Loss: 0.1402 Acc: 0.9756\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0018 Acc: 0.9998\n",
      "Val Loss: 0.1367 Acc: 0.9764\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0008 Acc: 1.0000\n",
      "Val Loss: 0.1354 Acc: 0.9767\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.979362\n"
     ]
    }
   ],
   "source": [
    "best_net69, best_acc69, last_net69 = train_model(net69, train_w9_dl, test_dl, criterion, optimizer69, exp_lr_scheduler_69,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "id": "Qp25TuX33R51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6457)\n",
      "Train Loss: 1.3097 Acc: 0.8071\n",
      "Val Loss: 0.1702 Acc: 0.9487\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7650)\n",
      "Train Loss: 0.1365 Acc: 0.9563\n",
      "Val Loss: 0.1510 Acc: 0.9568\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7787)\n",
      "Train Loss: 0.0768 Acc: 0.9734\n",
      "Val Loss: 0.1357 Acc: 0.9598\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7838)\n",
      "Train Loss: 0.0597 Acc: 0.9798\n",
      "Val Loss: 0.1573 Acc: 0.9606\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7896)\n",
      "Train Loss: 0.0383 Acc: 0.9870\n",
      "Val Loss: 0.1432 Acc: 0.9658\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0326 Acc: 0.9884\n",
      "Val Loss: 0.1260 Acc: 0.9682\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0367 Acc: 0.9874\n",
      "Val Loss: 0.1725 Acc: 0.9564\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0337 Acc: 0.9890\n",
      "Val Loss: 0.1853 Acc: 0.9625\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0415 Acc: 0.9864\n",
      "Val Loss: 0.1370 Acc: 0.9695\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0215 Acc: 0.9928\n",
      "Val Loss: 0.1280 Acc: 0.9719\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0106 Acc: 0.9964\n",
      "Val Loss: 0.1827 Acc: 0.9626\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0180 Acc: 0.9932\n",
      "Val Loss: 0.1618 Acc: 0.9689\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0117 Acc: 0.9968\n",
      "Val Loss: 0.1822 Acc: 0.9694\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0150 Acc: 0.9945\n",
      "Val Loss: 0.2005 Acc: 0.9650\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0258 Acc: 0.9921\n",
      "Val Loss: 0.1752 Acc: 0.9692\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0312 Acc: 0.9902\n",
      "Val Loss: 0.2213 Acc: 0.9615\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0210 Acc: 0.9940\n",
      "Val Loss: 0.1548 Acc: 0.9722\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0144 Acc: 0.9950\n",
      "Val Loss: 0.1541 Acc: 0.9732\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0080 Acc: 0.9974\n",
      "Val Loss: 0.2021 Acc: 0.9665\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0210 Acc: 0.9946\n",
      "Val Loss: 0.2808 Acc: 0.9547\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7973)\n",
      "Train Loss: 0.0108 Acc: 0.9966\n",
      "Val Loss: 0.1514 Acc: 0.9734\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0007 Acc: 0.9999\n",
      "Val Loss: 0.1492 Acc: 0.9739\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1484 Acc: 0.9741\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.974089\n"
     ]
    }
   ],
   "source": [
    "best_net70, best_acc70, last_net70 = train_model(net70, train_w10_dl, test_dl, criterion, optimizer70, exp_lr_scheduler_70,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "id": "wmo_bSbk5Y-n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6526)\n",
      "Train Loss: 1.4045 Acc: 0.8157\n",
      "Val Loss: 0.1877 Acc: 0.9424\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7608)\n",
      "Train Loss: 0.1550 Acc: 0.9510\n",
      "Val Loss: 0.1577 Acc: 0.9528\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7758)\n",
      "Train Loss: 0.0951 Acc: 0.9698\n",
      "Val Loss: 0.1384 Acc: 0.9572\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7848)\n",
      "Train Loss: 0.0593 Acc: 0.9810\n",
      "Val Loss: 0.1367 Acc: 0.9613\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7885)\n",
      "Train Loss: 0.0452 Acc: 0.9856\n",
      "Val Loss: 0.1075 Acc: 0.9684\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0360 Acc: 0.9889\n",
      "Val Loss: 0.1271 Acc: 0.9666\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0483 Acc: 0.9835\n",
      "Val Loss: 0.1448 Acc: 0.9681\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0408 Acc: 0.9854\n",
      "Val Loss: 0.1467 Acc: 0.9687\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0309 Acc: 0.9906\n",
      "Val Loss: 0.1547 Acc: 0.9662\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0186 Acc: 0.9936\n",
      "Val Loss: 0.1823 Acc: 0.9655\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0195 Acc: 0.9941\n",
      "Val Loss: 0.1158 Acc: 0.9746\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0052 Acc: 0.9988\n",
      "Val Loss: 0.1331 Acc: 0.9723\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0082 Acc: 0.9978\n",
      "Val Loss: 0.1615 Acc: 0.9690\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0332 Acc: 0.9888\n",
      "Val Loss: 0.1743 Acc: 0.9661\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0301 Acc: 0.9912\n",
      "Val Loss: 0.1713 Acc: 0.9662\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0358 Acc: 0.9895\n",
      "Val Loss: 0.1516 Acc: 0.9689\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0245 Acc: 0.9916\n",
      "Val Loss: 0.1454 Acc: 0.9711\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0062 Acc: 0.9982\n",
      "Val Loss: 0.1336 Acc: 0.9754\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0035 Acc: 0.9988\n",
      "Val Loss: 0.1337 Acc: 0.9755\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0200 Acc: 0.9948\n",
      "Val Loss: 0.1485 Acc: 0.9714\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0053 Acc: 0.9980\n",
      "Val Loss: 0.1235 Acc: 0.9766\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1233 Acc: 0.9767\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1233 Acc: 0.9766\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.976725\n"
     ]
    }
   ],
   "source": [
    "best_net71, best_acc71, last_net71 = train_model(net71, train_x1_dl, test_dl, criterion, optimizer71, exp_lr_scheduler_71,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "id": "g_q86oMj5kCx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6306)\n",
      "Train Loss: 1.2217 Acc: 0.7883\n",
      "Val Loss: 0.2233 Acc: 0.9282\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7564)\n",
      "Train Loss: 0.1730 Acc: 0.9455\n",
      "Val Loss: 0.1441 Acc: 0.9542\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7742)\n",
      "Train Loss: 0.0975 Acc: 0.9677\n",
      "Val Loss: 0.1564 Acc: 0.9534\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7803)\n",
      "Train Loss: 0.0755 Acc: 0.9754\n",
      "Val Loss: 0.1584 Acc: 0.9555\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7851)\n",
      "Train Loss: 0.0507 Acc: 0.9814\n",
      "Val Loss: 0.1385 Acc: 0.9644\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0369 Acc: 0.9882\n",
      "Val Loss: 0.1511 Acc: 0.9610\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7904)\n",
      "Train Loss: 0.0330 Acc: 0.9880\n",
      "Val Loss: 0.1378 Acc: 0.9669\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0275 Acc: 0.9915\n",
      "Val Loss: 0.1149 Acc: 0.9715\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0174 Acc: 0.9942\n",
      "Val Loss: 0.1245 Acc: 0.9726\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0250 Acc: 0.9915\n",
      "Val Loss: 0.1809 Acc: 0.9600\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0350 Acc: 0.9892\n",
      "Val Loss: 0.1836 Acc: 0.9612\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0234 Acc: 0.9924\n",
      "Val Loss: 0.1442 Acc: 0.9720\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0149 Acc: 0.9948\n",
      "Val Loss: 0.1533 Acc: 0.9702\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7978)\n",
      "Train Loss: 0.0086 Acc: 0.9972\n",
      "Val Loss: 0.1566 Acc: 0.9733\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0144 Acc: 0.9942\n",
      "Val Loss: 0.2653 Acc: 0.9583\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0475 Acc: 0.9860\n",
      "Val Loss: 0.1442 Acc: 0.9692\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0130 Acc: 0.9952\n",
      "Val Loss: 0.1623 Acc: 0.9691\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0140 Acc: 0.9952\n",
      "Val Loss: 0.2308 Acc: 0.9595\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0177 Acc: 0.9951\n",
      "Val Loss: 0.2050 Acc: 0.9671\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0298 Acc: 0.9908\n",
      "Val Loss: 0.1893 Acc: 0.9660\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0088 Acc: 0.9969\n",
      "Val Loss: 0.1536 Acc: 0.9723\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0013 Acc: 0.9999\n",
      "Val Loss: 0.1517 Acc: 0.9735\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0007 Acc: 0.9999\n",
      "Val Loss: 0.1511 Acc: 0.9738\n",
      "\n",
      "Training complete in 6m 35s\n",
      "Best val Acc: 0.973816\n"
     ]
    }
   ],
   "source": [
    "best_net72, best_acc72, last_net72 = train_model(net72, train_x2_dl, test_dl, criterion, optimizer72, exp_lr_scheduler_72,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "id": "sxvSBbI95j3S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6429)\n",
      "Train Loss: 1.6486 Acc: 0.8036\n",
      "Val Loss: 0.1882 Acc: 0.9411\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7679)\n",
      "Train Loss: 0.1268 Acc: 0.9599\n",
      "Val Loss: 0.1219 Acc: 0.9616\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7800)\n",
      "Train Loss: 0.0733 Acc: 0.9750\n",
      "Val Loss: 0.1266 Acc: 0.9618\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7876)\n",
      "Train Loss: 0.0427 Acc: 0.9845\n",
      "Val Loss: 0.1815 Acc: 0.9520\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0372 Acc: 0.9886\n",
      "Val Loss: 0.1226 Acc: 0.9676\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0182 Acc: 0.9940\n",
      "Val Loss: 0.1296 Acc: 0.9697\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0152 Acc: 0.9941\n",
      "Val Loss: 0.1211 Acc: 0.9693\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0352 Acc: 0.9869\n",
      "Val Loss: 0.1485 Acc: 0.9646\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0247 Acc: 0.9911\n",
      "Val Loss: 0.1320 Acc: 0.9719\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0178 Acc: 0.9942\n",
      "Val Loss: 0.1684 Acc: 0.9651\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0322 Acc: 0.9904\n",
      "Val Loss: 0.1644 Acc: 0.9625\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0153 Acc: 0.9952\n",
      "Val Loss: 0.1430 Acc: 0.9711\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0092 Acc: 0.9968\n",
      "Val Loss: 0.1483 Acc: 0.9718\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0128 Acc: 0.9956\n",
      "Val Loss: 0.1486 Acc: 0.9713\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0121 Acc: 0.9964\n",
      "Val Loss: 0.1609 Acc: 0.9715\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0202 Acc: 0.9939\n",
      "Val Loss: 0.1931 Acc: 0.9663\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0334 Acc: 0.9914\n",
      "Val Loss: 0.1706 Acc: 0.9686\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0151 Acc: 0.9948\n",
      "Val Loss: 0.1618 Acc: 0.9709\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0270 Acc: 0.9928\n",
      "Val Loss: 0.2042 Acc: 0.9634\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0289 Acc: 0.9920\n",
      "Val Loss: 0.1992 Acc: 0.9672\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0091 Acc: 0.9975\n",
      "Val Loss: 0.1447 Acc: 0.9755\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1432 Acc: 0.9762\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1427 Acc: 0.9765\n",
      "\n",
      "Training complete in 6m 39s\n",
      "Best val Acc: 0.976452\n"
     ]
    }
   ],
   "source": [
    "best_net73, best_acc73, last_net73 = train_model(net73, train_x3_dl, test_dl, criterion, optimizer73, exp_lr_scheduler_73,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "id": "WBPW5XQO5jsD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6801)\n",
      "Train Loss: 0.8907 Acc: 0.8501\n",
      "Val Loss: 0.1386 Acc: 0.9585\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7732)\n",
      "Train Loss: 0.1094 Acc: 0.9665\n",
      "Val Loss: 0.1266 Acc: 0.9616\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7861)\n",
      "Train Loss: 0.0510 Acc: 0.9826\n",
      "Val Loss: 0.1328 Acc: 0.9649\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0324 Acc: 0.9900\n",
      "Val Loss: 0.1420 Acc: 0.9660\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0321 Acc: 0.9896\n",
      "Val Loss: 0.1144 Acc: 0.9713\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0145 Acc: 0.9958\n",
      "Val Loss: 0.1310 Acc: 0.9695\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0216 Acc: 0.9921\n",
      "Val Loss: 0.1281 Acc: 0.9741\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0377 Acc: 0.9888\n",
      "Val Loss: 0.1253 Acc: 0.9709\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0264 Acc: 0.9909\n",
      "Val Loss: 0.1273 Acc: 0.9708\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0220 Acc: 0.9932\n",
      "Val Loss: 0.1651 Acc: 0.9681\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0364 Acc: 0.9898\n",
      "Val Loss: 0.1192 Acc: 0.9726\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0124 Acc: 0.9959\n",
      "Val Loss: 0.1387 Acc: 0.9731\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0078 Acc: 0.9971\n",
      "Val Loss: 0.1110 Acc: 0.9793\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0045 Acc: 0.9986\n",
      "Val Loss: 0.1016 Acc: 0.9800\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0047 Acc: 0.9989\n",
      "Val Loss: 0.1157 Acc: 0.9776\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0027 Acc: 0.9994\n",
      "Val Loss: 0.1073 Acc: 0.9800\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0155 Acc: 0.9958\n",
      "Val Loss: 0.1940 Acc: 0.9656\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0132 Acc: 0.9961\n",
      "Val Loss: 0.1727 Acc: 0.9709\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7893)\n",
      "Train Loss: 0.0489 Acc: 0.9866\n",
      "Val Loss: 0.1312 Acc: 0.9743\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0194 Acc: 0.9934\n",
      "Val Loss: 0.1435 Acc: 0.9739\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0060 Acc: 0.9989\n",
      "Val Loss: 0.1119 Acc: 0.9791\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0008 Acc: 0.9999\n",
      "Val Loss: 0.1101 Acc: 0.9794\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1097 Acc: 0.9795\n",
      "\n",
      "Training complete in 6m 39s\n",
      "Best val Acc: 0.979998\n"
     ]
    }
   ],
   "source": [
    "best_net74, best_acc74, last_net74 = train_model(net74, train_x4_dl, test_dl, criterion, optimizer74, exp_lr_scheduler_74,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "id": "qmH9CZIb5jhm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6111)\n",
      "Train Loss: 1.9161 Acc: 0.7639\n",
      "Val Loss: 0.2292 Acc: 0.9298\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7563)\n",
      "Train Loss: 0.1745 Acc: 0.9454\n",
      "Val Loss: 0.1658 Acc: 0.9490\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7732)\n",
      "Train Loss: 0.1076 Acc: 0.9665\n",
      "Val Loss: 0.1404 Acc: 0.9578\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7803)\n",
      "Train Loss: 0.0756 Acc: 0.9754\n",
      "Val Loss: 0.1274 Acc: 0.9631\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7874)\n",
      "Train Loss: 0.0472 Acc: 0.9842\n",
      "Val Loss: 0.1238 Acc: 0.9668\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0282 Acc: 0.9909\n",
      "Val Loss: 0.1685 Acc: 0.9573\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0465 Acc: 0.9835\n",
      "Val Loss: 0.1592 Acc: 0.9626\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0281 Acc: 0.9898\n",
      "Val Loss: 0.1463 Acc: 0.9651\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0259 Acc: 0.9916\n",
      "Val Loss: 0.1671 Acc: 0.9672\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0164 Acc: 0.9941\n",
      "Val Loss: 0.1698 Acc: 0.9661\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0187 Acc: 0.9932\n",
      "Val Loss: 0.2091 Acc: 0.9618\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7892)\n",
      "Train Loss: 0.0446 Acc: 0.9865\n",
      "Val Loss: 0.1860 Acc: 0.9643\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0205 Acc: 0.9936\n",
      "Val Loss: 0.1630 Acc: 0.9690\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7900)\n",
      "Train Loss: 0.0396 Acc: 0.9875\n",
      "Val Loss: 0.2066 Acc: 0.9626\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0292 Acc: 0.9905\n",
      "Val Loss: 0.1454 Acc: 0.9746\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0232 Acc: 0.9919\n",
      "Val Loss: 0.1571 Acc: 0.9706\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0153 Acc: 0.9945\n",
      "Val Loss: 0.1478 Acc: 0.9744\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0228 Acc: 0.9934\n",
      "Val Loss: 0.1985 Acc: 0.9667\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0138 Acc: 0.9959\n",
      "Val Loss: 0.1972 Acc: 0.9705\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0195 Acc: 0.9940\n",
      "Val Loss: 0.1824 Acc: 0.9696\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7978)\n",
      "Train Loss: 0.0077 Acc: 0.9972\n",
      "Val Loss: 0.1639 Acc: 0.9735\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0011 Acc: 0.9999\n",
      "Val Loss: 0.1612 Acc: 0.9740\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1606 Acc: 0.9743\n",
      "\n",
      "Training complete in 6m 16s\n",
      "Best val Acc: 0.974634\n"
     ]
    }
   ],
   "source": [
    "best_net75, best_acc75, last_net75 = train_model(net75, train_x5_dl, test_dl, criterion, optimizer75, exp_lr_scheduler_75,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "ILHujxZ85jYg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6608)\n",
      "Train Loss: 1.4128 Acc: 0.8260\n",
      "Val Loss: 0.1881 Acc: 0.9414\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7694)\n",
      "Train Loss: 0.1192 Acc: 0.9617\n",
      "Val Loss: 0.1992 Acc: 0.9461\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7798)\n",
      "Train Loss: 0.0831 Acc: 0.9748\n",
      "Val Loss: 0.1390 Acc: 0.9627\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7846)\n",
      "Train Loss: 0.0577 Acc: 0.9808\n",
      "Val Loss: 0.1416 Acc: 0.9655\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7830)\n",
      "Train Loss: 0.0634 Acc: 0.9788\n",
      "Val Loss: 0.1448 Acc: 0.9649\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0428 Acc: 0.9860\n",
      "Val Loss: 0.1707 Acc: 0.9638\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0339 Acc: 0.9879\n",
      "Val Loss: 0.1479 Acc: 0.9686\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0210 Acc: 0.9936\n",
      "Val Loss: 0.1578 Acc: 0.9666\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0187 Acc: 0.9932\n",
      "Val Loss: 0.1879 Acc: 0.9595\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7915)\n",
      "Train Loss: 0.0339 Acc: 0.9894\n",
      "Val Loss: 0.1575 Acc: 0.9699\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0202 Acc: 0.9941\n",
      "Val Loss: 0.1460 Acc: 0.9713\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0213 Acc: 0.9934\n",
      "Val Loss: 0.1437 Acc: 0.9713\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0111 Acc: 0.9952\n",
      "Val Loss: 0.1758 Acc: 0.9715\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0111 Acc: 0.9970\n",
      "Val Loss: 0.1691 Acc: 0.9717\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0297 Acc: 0.9912\n",
      "Val Loss: 0.2186 Acc: 0.9629\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0388 Acc: 0.9902\n",
      "Val Loss: 0.1552 Acc: 0.9730\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0259 Acc: 0.9929\n",
      "Val Loss: 0.1775 Acc: 0.9682\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7973)\n",
      "Train Loss: 0.0098 Acc: 0.9966\n",
      "Val Loss: 0.1769 Acc: 0.9710\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0261 Acc: 0.9946\n",
      "Val Loss: 0.1939 Acc: 0.9672\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0222 Acc: 0.9936\n",
      "Val Loss: 0.1918 Acc: 0.9689\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0073 Acc: 0.9981\n",
      "Val Loss: 0.1453 Acc: 0.9766\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0008 Acc: 0.9999\n",
      "Val Loss: 0.1426 Acc: 0.9767\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1415 Acc: 0.9767\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.976725\n"
     ]
    }
   ],
   "source": [
    "best_net76, best_acc76, last_net76 = train_model(net76, train_x6_dl, test_dl, criterion, optimizer76, exp_lr_scheduler_76,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "id": "idioxv2S5jNJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6643)\n",
      "Train Loss: 1.2754 Acc: 0.8304\n",
      "Val Loss: 0.2298 Acc: 0.9259\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7637)\n",
      "Train Loss: 0.1421 Acc: 0.9546\n",
      "Val Loss: 0.1590 Acc: 0.9515\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7788)\n",
      "Train Loss: 0.0772 Acc: 0.9735\n",
      "Val Loss: 0.1121 Acc: 0.9668\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7856)\n",
      "Train Loss: 0.0502 Acc: 0.9820\n",
      "Val Loss: 0.1033 Acc: 0.9708\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0305 Acc: 0.9896\n",
      "Val Loss: 0.1339 Acc: 0.9670\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0323 Acc: 0.9888\n",
      "Val Loss: 0.1270 Acc: 0.9689\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7905)\n",
      "Train Loss: 0.0355 Acc: 0.9881\n",
      "Val Loss: 0.1474 Acc: 0.9656\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0312 Acc: 0.9889\n",
      "Val Loss: 0.1264 Acc: 0.9713\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0218 Acc: 0.9924\n",
      "Val Loss: 0.1278 Acc: 0.9730\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0311 Acc: 0.9902\n",
      "Val Loss: 0.1255 Acc: 0.9720\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0262 Acc: 0.9912\n",
      "Val Loss: 0.1358 Acc: 0.9726\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0166 Acc: 0.9949\n",
      "Val Loss: 0.1680 Acc: 0.9654\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0161 Acc: 0.9960\n",
      "Val Loss: 0.1464 Acc: 0.9713\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0118 Acc: 0.9962\n",
      "Val Loss: 0.1404 Acc: 0.9732\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0237 Acc: 0.9934\n",
      "Val Loss: 0.1601 Acc: 0.9684\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0314 Acc: 0.9904\n",
      "Val Loss: 0.1712 Acc: 0.9676\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0139 Acc: 0.9951\n",
      "Val Loss: 0.1607 Acc: 0.9729\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0241 Acc: 0.9930\n",
      "Val Loss: 0.1562 Acc: 0.9705\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0086 Acc: 0.9970\n",
      "Val Loss: 0.1650 Acc: 0.9748\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0137 Acc: 0.9959\n",
      "Val Loss: 0.1936 Acc: 0.9695\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0042 Acc: 0.9985\n",
      "Val Loss: 0.1564 Acc: 0.9758\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1540 Acc: 0.9765\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1530 Acc: 0.9766\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.976634\n"
     ]
    }
   ],
   "source": [
    "best_net77, best_acc77, last_net77 = train_model(net77, train_x7_dl, test_dl, criterion, optimizer77, exp_lr_scheduler_77,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "id": "1lCBbJm45jCq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6179)\n",
      "Train Loss: 1.6283 Acc: 0.7724\n",
      "Val Loss: 0.2054 Acc: 0.9362\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7573)\n",
      "Train Loss: 0.1708 Acc: 0.9466\n",
      "Val Loss: 0.1547 Acc: 0.9524\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7732)\n",
      "Train Loss: 0.1040 Acc: 0.9665\n",
      "Val Loss: 0.1256 Acc: 0.9623\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7808)\n",
      "Train Loss: 0.0725 Acc: 0.9760\n",
      "Val Loss: 0.1418 Acc: 0.9625\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7852)\n",
      "Train Loss: 0.0542 Acc: 0.9815\n",
      "Val Loss: 0.1139 Acc: 0.9679\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0356 Acc: 0.9892\n",
      "Val Loss: 0.1467 Acc: 0.9647\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0331 Acc: 0.9895\n",
      "Val Loss: 0.1731 Acc: 0.9535\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0310 Acc: 0.9902\n",
      "Val Loss: 0.1347 Acc: 0.9689\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0273 Acc: 0.9904\n",
      "Val Loss: 0.1654 Acc: 0.9665\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0340 Acc: 0.9874\n",
      "Val Loss: 0.1558 Acc: 0.9666\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0279 Acc: 0.9916\n",
      "Val Loss: 0.1488 Acc: 0.9697\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0118 Acc: 0.9960\n",
      "Val Loss: 0.1616 Acc: 0.9712\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0167 Acc: 0.9951\n",
      "Val Loss: 0.2321 Acc: 0.9576\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0130 Acc: 0.9951\n",
      "Val Loss: 0.1588 Acc: 0.9705\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0163 Acc: 0.9949\n",
      "Val Loss: 0.1701 Acc: 0.9703\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0415 Acc: 0.9885\n",
      "Val Loss: 0.2149 Acc: 0.9587\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0393 Acc: 0.9886\n",
      "Val Loss: 0.1924 Acc: 0.9657\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0272 Acc: 0.9916\n",
      "Val Loss: 0.1963 Acc: 0.9655\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0292 Acc: 0.9920\n",
      "Val Loss: 0.1825 Acc: 0.9650\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0288 Acc: 0.9922\n",
      "Val Loss: 0.1544 Acc: 0.9730\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0040 Acc: 0.9982\n",
      "Val Loss: 0.1344 Acc: 0.9758\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0010 Acc: 1.0000\n",
      "Val Loss: 0.1345 Acc: 0.9760\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0008 Acc: 1.0000\n",
      "Val Loss: 0.1350 Acc: 0.9760\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.975998\n"
     ]
    }
   ],
   "source": [
    "best_net78, best_acc78, last_net78 = train_model(net78, train_x8_dl, test_dl, criterion, optimizer78, exp_lr_scheduler_78,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "id": "aQrCZXNh5i3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6626)\n",
      "Train Loss: 1.5718 Acc: 0.8283\n",
      "Val Loss: 0.1487 Acc: 0.9545\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7648)\n",
      "Train Loss: 0.1422 Acc: 0.9560\n",
      "Val Loss: 0.1368 Acc: 0.9583\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7782)\n",
      "Train Loss: 0.0830 Acc: 0.9728\n",
      "Val Loss: 0.1344 Acc: 0.9624\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7841)\n",
      "Train Loss: 0.0612 Acc: 0.9801\n",
      "Val Loss: 0.1273 Acc: 0.9663\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0391 Acc: 0.9861\n",
      "Val Loss: 0.1101 Acc: 0.9703\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0380 Acc: 0.9871\n",
      "Val Loss: 0.1323 Acc: 0.9675\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0211 Acc: 0.9930\n",
      "Val Loss: 0.1200 Acc: 0.9693\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0293 Acc: 0.9906\n",
      "Val Loss: 0.1108 Acc: 0.9742\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0293 Acc: 0.9911\n",
      "Val Loss: 0.1768 Acc: 0.9607\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0234 Acc: 0.9915\n",
      "Val Loss: 0.1607 Acc: 0.9697\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0226 Acc: 0.9922\n",
      "Val Loss: 0.1577 Acc: 0.9701\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7905)\n",
      "Train Loss: 0.0412 Acc: 0.9881\n",
      "Val Loss: 0.1759 Acc: 0.9665\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0188 Acc: 0.9940\n",
      "Val Loss: 0.1546 Acc: 0.9695\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0096 Acc: 0.9964\n",
      "Val Loss: 0.1574 Acc: 0.9719\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0216 Acc: 0.9930\n",
      "Val Loss: 0.1439 Acc: 0.9727\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0222 Acc: 0.9929\n",
      "Val Loss: 0.2131 Acc: 0.9609\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0164 Acc: 0.9954\n",
      "Val Loss: 0.1693 Acc: 0.9693\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0175 Acc: 0.9955\n",
      "Val Loss: 0.2292 Acc: 0.9635\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0306 Acc: 0.9911\n",
      "Val Loss: 0.2150 Acc: 0.9625\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0415 Acc: 0.9892\n",
      "Val Loss: 0.2214 Acc: 0.9662\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0118 Acc: 0.9960\n",
      "Val Loss: 0.1690 Acc: 0.9738\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0016 Acc: 0.9995\n",
      "Val Loss: 0.1619 Acc: 0.9747\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0008 Acc: 1.0000\n",
      "Val Loss: 0.1599 Acc: 0.9752\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.975180\n"
     ]
    }
   ],
   "source": [
    "best_net79, best_acc79, last_net79 = train_model(net79, train_x9_dl, test_dl, criterion, optimizer79, exp_lr_scheduler_79,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "id": "5k-kCUYk5ira"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6750)\n",
      "Train Loss: 1.3078 Acc: 0.8438\n",
      "Val Loss: 0.1883 Acc: 0.9414\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7635)\n",
      "Train Loss: 0.1396 Acc: 0.9544\n",
      "Val Loss: 0.1324 Acc: 0.9600\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7798)\n",
      "Train Loss: 0.0752 Acc: 0.9748\n",
      "Val Loss: 0.1413 Acc: 0.9593\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0503 Acc: 0.9835\n",
      "Val Loss: 0.1488 Acc: 0.9605\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7887)\n",
      "Train Loss: 0.0417 Acc: 0.9859\n",
      "Val Loss: 0.1421 Acc: 0.9633\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0295 Acc: 0.9898\n",
      "Val Loss: 0.1225 Acc: 0.9685\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0303 Acc: 0.9901\n",
      "Val Loss: 0.1667 Acc: 0.9620\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7919)\n",
      "Train Loss: 0.0281 Acc: 0.9899\n",
      "Val Loss: 0.1321 Acc: 0.9689\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0330 Acc: 0.9891\n",
      "Val Loss: 0.1404 Acc: 0.9700\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0150 Acc: 0.9952\n",
      "Val Loss: 0.2020 Acc: 0.9611\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0269 Acc: 0.9914\n",
      "Val Loss: 0.1596 Acc: 0.9655\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0205 Acc: 0.9929\n",
      "Val Loss: 0.2050 Acc: 0.9667\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0215 Acc: 0.9934\n",
      "Val Loss: 0.1835 Acc: 0.9675\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0245 Acc: 0.9919\n",
      "Val Loss: 0.1706 Acc: 0.9711\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0109 Acc: 0.9968\n",
      "Val Loss: 0.1677 Acc: 0.9709\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0180 Acc: 0.9938\n",
      "Val Loss: 0.1858 Acc: 0.9700\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0232 Acc: 0.9939\n",
      "Val Loss: 0.2002 Acc: 0.9665\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0366 Acc: 0.9891\n",
      "Val Loss: 0.1759 Acc: 0.9718\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0282 Acc: 0.9920\n",
      "Val Loss: 0.2129 Acc: 0.9681\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0189 Acc: 0.9949\n",
      "Val Loss: 0.1979 Acc: 0.9716\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0043 Acc: 0.9988\n",
      "Val Loss: 0.1940 Acc: 0.9737\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1927 Acc: 0.9737\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1921 Acc: 0.9740\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.973998\n"
     ]
    }
   ],
   "source": [
    "best_net80, best_acc80, last_net80 = train_model(net80, train_x10_dl, test_dl, criterion, optimizer80, exp_lr_scheduler_80,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "id": "Eb0Ttoct5icq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6499)\n",
      "Train Loss: 1.2081 Acc: 0.8124\n",
      "Val Loss: 0.1817 Acc: 0.9432\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7699)\n",
      "Train Loss: 0.1230 Acc: 0.9624\n",
      "Val Loss: 0.1514 Acc: 0.9560\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7796)\n",
      "Train Loss: 0.0747 Acc: 0.9745\n",
      "Val Loss: 0.1262 Acc: 0.9609\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0412 Acc: 0.9864\n",
      "Val Loss: 0.1280 Acc: 0.9665\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0365 Acc: 0.9889\n",
      "Val Loss: 0.1439 Acc: 0.9675\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0300 Acc: 0.9902\n",
      "Val Loss: 0.1671 Acc: 0.9555\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0390 Acc: 0.9869\n",
      "Val Loss: 0.1407 Acc: 0.9651\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0295 Acc: 0.9892\n",
      "Val Loss: 0.1424 Acc: 0.9655\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0214 Acc: 0.9935\n",
      "Val Loss: 0.1750 Acc: 0.9634\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0132 Acc: 0.9958\n",
      "Val Loss: 0.1228 Acc: 0.9735\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0121 Acc: 0.9965\n",
      "Val Loss: 0.1358 Acc: 0.9720\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0222 Acc: 0.9929\n",
      "Val Loss: 0.1812 Acc: 0.9655\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0269 Acc: 0.9904\n",
      "Val Loss: 0.2079 Acc: 0.9640\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0396 Acc: 0.9891\n",
      "Val Loss: 0.1562 Acc: 0.9680\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0283 Acc: 0.9914\n",
      "Val Loss: 0.1796 Acc: 0.9667\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0120 Acc: 0.9959\n",
      "Val Loss: 0.1349 Acc: 0.9739\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0023 Acc: 0.9995\n",
      "Val Loss: 0.1205 Acc: 0.9775\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7992)\n",
      "Train Loss: 0.0025 Acc: 0.9990\n",
      "Val Loss: 0.1328 Acc: 0.9751\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0069 Acc: 0.9979\n",
      "Val Loss: 0.1455 Acc: 0.9741\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0064 Acc: 0.9985\n",
      "Val Loss: 0.1454 Acc: 0.9757\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0043 Acc: 0.9991\n",
      "Val Loss: 0.1339 Acc: 0.9777\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1320 Acc: 0.9782\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1316 Acc: 0.9784\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.978362\n"
     ]
    }
   ],
   "source": [
    "best_net81, best_acc81, last_net81 = train_model(net81, train_y1_dl, test_dl, criterion, optimizer81, exp_lr_scheduler_81,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "id": "aoiDHYdC6xYm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6545)\n",
      "Train Loss: 1.3976 Acc: 0.8181\n",
      "Val Loss: 0.1869 Acc: 0.9396\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7680)\n",
      "Train Loss: 0.1220 Acc: 0.9600\n",
      "Val Loss: 0.1360 Acc: 0.9605\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7801)\n",
      "Train Loss: 0.0801 Acc: 0.9751\n",
      "Val Loss: 0.1180 Acc: 0.9664\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7886)\n",
      "Train Loss: 0.0437 Acc: 0.9858\n",
      "Val Loss: 0.1319 Acc: 0.9656\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0373 Acc: 0.9871\n",
      "Val Loss: 0.1137 Acc: 0.9699\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0314 Acc: 0.9888\n",
      "Val Loss: 0.1429 Acc: 0.9653\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0290 Acc: 0.9900\n",
      "Val Loss: 0.1718 Acc: 0.9630\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0344 Acc: 0.9895\n",
      "Val Loss: 0.1322 Acc: 0.9712\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0189 Acc: 0.9930\n",
      "Val Loss: 0.1230 Acc: 0.9742\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0172 Acc: 0.9954\n",
      "Val Loss: 0.1834 Acc: 0.9632\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0204 Acc: 0.9931\n",
      "Val Loss: 0.1450 Acc: 0.9706\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0398 Acc: 0.9874\n",
      "Val Loss: 0.1404 Acc: 0.9725\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0143 Acc: 0.9948\n",
      "Val Loss: 0.1266 Acc: 0.9766\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0101 Acc: 0.9965\n",
      "Val Loss: 0.1263 Acc: 0.9759\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0035 Acc: 0.9986\n",
      "Val Loss: 0.1425 Acc: 0.9760\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0082 Acc: 0.9976\n",
      "Val Loss: 0.1485 Acc: 0.9735\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0186 Acc: 0.9945\n",
      "Val Loss: 0.1653 Acc: 0.9720\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0328 Acc: 0.9906\n",
      "Val Loss: 0.1403 Acc: 0.9730\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0215 Acc: 0.9938\n",
      "Val Loss: 0.1803 Acc: 0.9723\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0361 Acc: 0.9908\n",
      "Val Loss: 0.1410 Acc: 0.9749\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0055 Acc: 0.9979\n",
      "Val Loss: 0.1215 Acc: 0.9785\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0009 Acc: 0.9999\n",
      "Val Loss: 0.1214 Acc: 0.9787\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1215 Acc: 0.9790\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.978998\n"
     ]
    }
   ],
   "source": [
    "best_net82, best_acc82, last_net82 = train_model(net82, train_y2_dl, test_dl, criterion, optimizer82, exp_lr_scheduler_82,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "id": "Q6ZHqXKq6xQR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6634)\n",
      "Train Loss: 1.0311 Acc: 0.8293\n",
      "Val Loss: 0.1384 Acc: 0.9554\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7699)\n",
      "Train Loss: 0.1137 Acc: 0.9624\n",
      "Val Loss: 0.1136 Acc: 0.9667\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7831)\n",
      "Train Loss: 0.0603 Acc: 0.9789\n",
      "Val Loss: 0.1326 Acc: 0.9615\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0410 Acc: 0.9869\n",
      "Val Loss: 0.1239 Acc: 0.9673\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0341 Acc: 0.9890\n",
      "Val Loss: 0.1004 Acc: 0.9741\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0219 Acc: 0.9922\n",
      "Val Loss: 0.1320 Acc: 0.9709\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0231 Acc: 0.9928\n",
      "Val Loss: 0.1113 Acc: 0.9761\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0190 Acc: 0.9935\n",
      "Val Loss: 0.1184 Acc: 0.9760\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0327 Acc: 0.9898\n",
      "Val Loss: 0.1399 Acc: 0.9662\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0209 Acc: 0.9920\n",
      "Val Loss: 0.1220 Acc: 0.9759\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0075 Acc: 0.9969\n",
      "Val Loss: 0.1424 Acc: 0.9738\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0246 Acc: 0.9930\n",
      "Val Loss: 0.1542 Acc: 0.9701\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0189 Acc: 0.9946\n",
      "Val Loss: 0.1638 Acc: 0.9700\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0168 Acc: 0.9946\n",
      "Val Loss: 0.1464 Acc: 0.9735\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7978)\n",
      "Train Loss: 0.0094 Acc: 0.9972\n",
      "Val Loss: 0.1502 Acc: 0.9720\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0060 Acc: 0.9986\n",
      "Val Loss: 0.1722 Acc: 0.9748\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0155 Acc: 0.9954\n",
      "Val Loss: 0.1662 Acc: 0.9741\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7919)\n",
      "Train Loss: 0.0410 Acc: 0.9899\n",
      "Val Loss: 0.2186 Acc: 0.9645\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0243 Acc: 0.9925\n",
      "Val Loss: 0.1703 Acc: 0.9725\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0326 Acc: 0.9924\n",
      "Val Loss: 0.1462 Acc: 0.9772\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7994)\n",
      "Train Loss: 0.0026 Acc: 0.9992\n",
      "Val Loss: 0.1370 Acc: 0.9792\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1360 Acc: 0.9791\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1356 Acc: 0.9791\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.979180\n"
     ]
    }
   ],
   "source": [
    "best_net83, best_acc83, last_net83 = train_model(net83, train_y3_dl, test_dl, criterion, optimizer83, exp_lr_scheduler_83,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "id": "jDxO8HPU6xIU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6693)\n",
      "Train Loss: 1.4842 Acc: 0.8366\n",
      "Val Loss: 0.1968 Acc: 0.9402\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7682)\n",
      "Train Loss: 0.1354 Acc: 0.9603\n",
      "Val Loss: 0.1624 Acc: 0.9540\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7781)\n",
      "Train Loss: 0.0829 Acc: 0.9726\n",
      "Val Loss: 0.1314 Acc: 0.9591\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7871)\n",
      "Train Loss: 0.0491 Acc: 0.9839\n",
      "Val Loss: 0.1257 Acc: 0.9675\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0272 Acc: 0.9898\n",
      "Val Loss: 0.1282 Acc: 0.9704\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0322 Acc: 0.9891\n",
      "Val Loss: 0.1166 Acc: 0.9688\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0489 Acc: 0.9835\n",
      "Val Loss: 0.1560 Acc: 0.9643\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7880)\n",
      "Train Loss: 0.0459 Acc: 0.9850\n",
      "Val Loss: 0.1423 Acc: 0.9674\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0240 Acc: 0.9934\n",
      "Val Loss: 0.1171 Acc: 0.9751\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0070 Acc: 0.9974\n",
      "Val Loss: 0.1168 Acc: 0.9771\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0020 Acc: 0.9994\n",
      "Val Loss: 0.1079 Acc: 0.9785\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1081 Acc: 0.9795\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1091 Acc: 0.9798\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1099 Acc: 0.9796\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1104 Acc: 0.9795\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1110 Acc: 0.9796\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1116 Acc: 0.9796\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1122 Acc: 0.9799\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1128 Acc: 0.9796\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1134 Acc: 0.9796\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1134 Acc: 0.9796\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1135 Acc: 0.9796\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1135 Acc: 0.9796\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.979907\n"
     ]
    }
   ],
   "source": [
    "best_net84, best_acc84, last_net84 = train_model(net84, train_y4_dl, test_dl, criterion, optimizer84, exp_lr_scheduler_84,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "2U9LH3hA6xAG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6536)\n",
      "Train Loss: 1.4036 Acc: 0.8170\n",
      "Val Loss: 0.2036 Acc: 0.9373\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7609)\n",
      "Train Loss: 0.1540 Acc: 0.9511\n",
      "Val Loss: 0.1344 Acc: 0.9591\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7732)\n",
      "Train Loss: 0.1033 Acc: 0.9665\n",
      "Val Loss: 0.1277 Acc: 0.9633\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7861)\n",
      "Train Loss: 0.0533 Acc: 0.9826\n",
      "Val Loss: 0.1196 Acc: 0.9661\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7904)\n",
      "Train Loss: 0.0362 Acc: 0.9880\n",
      "Val Loss: 0.1306 Acc: 0.9677\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0389 Acc: 0.9871\n",
      "Val Loss: 0.1563 Acc: 0.9643\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7896)\n",
      "Train Loss: 0.0400 Acc: 0.9870\n",
      "Val Loss: 0.1579 Acc: 0.9659\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0243 Acc: 0.9909\n",
      "Val Loss: 0.1248 Acc: 0.9719\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0219 Acc: 0.9925\n",
      "Val Loss: 0.1345 Acc: 0.9695\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0212 Acc: 0.9934\n",
      "Val Loss: 0.1809 Acc: 0.9661\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0121 Acc: 0.9958\n",
      "Val Loss: 0.1773 Acc: 0.9693\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0265 Acc: 0.9930\n",
      "Val Loss: 0.1572 Acc: 0.9676\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0294 Acc: 0.9910\n",
      "Val Loss: 0.2071 Acc: 0.9645\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0227 Acc: 0.9919\n",
      "Val Loss: 0.1516 Acc: 0.9707\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0111 Acc: 0.9956\n",
      "Val Loss: 0.1909 Acc: 0.9660\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0105 Acc: 0.9960\n",
      "Val Loss: 0.1752 Acc: 0.9709\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0343 Acc: 0.9908\n",
      "Val Loss: 0.2103 Acc: 0.9613\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7905)\n",
      "Train Loss: 0.0447 Acc: 0.9881\n",
      "Val Loss: 0.1620 Acc: 0.9645\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0173 Acc: 0.9939\n",
      "Val Loss: 0.1546 Acc: 0.9720\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0167 Acc: 0.9958\n",
      "Val Loss: 0.2287 Acc: 0.9645\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0132 Acc: 0.9954\n",
      "Val Loss: 0.1453 Acc: 0.9757\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0018 Acc: 0.9999\n",
      "Val Loss: 0.1441 Acc: 0.9765\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1435 Acc: 0.9767\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.976725\n"
     ]
    }
   ],
   "source": [
    "best_net85, best_acc85, last_net85 = train_model(net85, train_y5_dl, test_dl, criterion, optimizer85, exp_lr_scheduler_85,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "id": "qQGzQ_9u6w17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6309)\n",
      "Train Loss: 1.3751 Acc: 0.7886\n",
      "Val Loss: 0.1859 Acc: 0.9430\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7692)\n",
      "Train Loss: 0.1330 Acc: 0.9615\n",
      "Val Loss: 0.1317 Acc: 0.9560\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7776)\n",
      "Train Loss: 0.0899 Acc: 0.9720\n",
      "Val Loss: 0.1222 Acc: 0.9649\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7849)\n",
      "Train Loss: 0.0561 Acc: 0.9811\n",
      "Val Loss: 0.1091 Acc: 0.9693\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7894)\n",
      "Train Loss: 0.0352 Acc: 0.9868\n",
      "Val Loss: 0.1137 Acc: 0.9716\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0255 Acc: 0.9912\n",
      "Val Loss: 0.1325 Acc: 0.9705\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0285 Acc: 0.9910\n",
      "Val Loss: 0.1437 Acc: 0.9693\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0182 Acc: 0.9936\n",
      "Val Loss: 0.1278 Acc: 0.9758\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0175 Acc: 0.9939\n",
      "Val Loss: 0.1347 Acc: 0.9714\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0190 Acc: 0.9936\n",
      "Val Loss: 0.1545 Acc: 0.9677\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0366 Acc: 0.9884\n",
      "Val Loss: 0.1836 Acc: 0.9651\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0207 Acc: 0.9922\n",
      "Val Loss: 0.1536 Acc: 0.9695\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0170 Acc: 0.9946\n",
      "Val Loss: 0.1875 Acc: 0.9673\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0247 Acc: 0.9928\n",
      "Val Loss: 0.1631 Acc: 0.9728\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0156 Acc: 0.9949\n",
      "Val Loss: 0.1996 Acc: 0.9681\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0270 Acc: 0.9924\n",
      "Val Loss: 0.2786 Acc: 0.9509\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0409 Acc: 0.9876\n",
      "Val Loss: 0.1630 Acc: 0.9712\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0171 Acc: 0.9942\n",
      "Val Loss: 0.1454 Acc: 0.9761\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0078 Acc: 0.9976\n",
      "Val Loss: 0.1447 Acc: 0.9738\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0054 Acc: 0.9986\n",
      "Val Loss: 0.1892 Acc: 0.9711\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0013 Acc: 0.9998\n",
      "Val Loss: 0.1754 Acc: 0.9727\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1730 Acc: 0.9734\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1714 Acc: 0.9738\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.976089\n"
     ]
    }
   ],
   "source": [
    "best_net86, best_acc86, last_net86 = train_model(net86, train_y6_dl, test_dl, criterion, optimizer86, exp_lr_scheduler_86,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "id": "W5yk4ghn6wtp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6567)\n",
      "Train Loss: 1.1854 Acc: 0.8209\n",
      "Val Loss: 0.1412 Acc: 0.9574\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7696)\n",
      "Train Loss: 0.1194 Acc: 0.9620\n",
      "Val Loss: 0.1344 Acc: 0.9590\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7795)\n",
      "Train Loss: 0.0732 Acc: 0.9744\n",
      "Val Loss: 0.1252 Acc: 0.9628\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7896)\n",
      "Train Loss: 0.0369 Acc: 0.9870\n",
      "Val Loss: 0.1192 Acc: 0.9691\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0217 Acc: 0.9930\n",
      "Val Loss: 0.1749 Acc: 0.9596\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0344 Acc: 0.9888\n",
      "Val Loss: 0.1505 Acc: 0.9649\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0263 Acc: 0.9915\n",
      "Val Loss: 0.1267 Acc: 0.9680\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0287 Acc: 0.9908\n",
      "Val Loss: 0.1404 Acc: 0.9656\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0344 Acc: 0.9879\n",
      "Val Loss: 0.1275 Acc: 0.9726\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0299 Acc: 0.9915\n",
      "Val Loss: 0.1387 Acc: 0.9693\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7958)\n",
      "Train Loss: 0.0153 Acc: 0.9948\n",
      "Val Loss: 0.1629 Acc: 0.9695\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7973)\n",
      "Train Loss: 0.0113 Acc: 0.9966\n",
      "Val Loss: 0.1514 Acc: 0.9721\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0111 Acc: 0.9968\n",
      "Val Loss: 0.1338 Acc: 0.9753\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0059 Acc: 0.9986\n",
      "Val Loss: 0.1604 Acc: 0.9701\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0011 Acc: 0.9998\n",
      "Val Loss: 0.1291 Acc: 0.9776\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1333 Acc: 0.9775\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1288 Acc: 0.9772\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1295 Acc: 0.9776\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1300 Acc: 0.9777\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1303 Acc: 0.9779\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1303 Acc: 0.9780\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1303 Acc: 0.9780\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1303 Acc: 0.9781\n",
      "\n",
      "Training complete in 6m 8s\n",
      "Best val Acc: 0.978089\n"
     ]
    }
   ],
   "source": [
    "best_net87, best_acc87, last_net87 = train_model(net87, train_y7_dl, test_dl, criterion, optimizer87, exp_lr_scheduler_87,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "id": "_yHcIibi6wjx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6745)\n",
      "Train Loss: 1.2121 Acc: 0.8431\n",
      "Val Loss: 0.1734 Acc: 0.9495\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7635)\n",
      "Train Loss: 0.1433 Acc: 0.9544\n",
      "Val Loss: 0.1759 Acc: 0.9449\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7774)\n",
      "Train Loss: 0.0858 Acc: 0.9718\n",
      "Val Loss: 0.1239 Acc: 0.9625\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0474 Acc: 0.9835\n",
      "Val Loss: 0.1092 Acc: 0.9690\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7882)\n",
      "Train Loss: 0.0421 Acc: 0.9852\n",
      "Val Loss: 0.1206 Acc: 0.9695\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0283 Acc: 0.9906\n",
      "Val Loss: 0.1290 Acc: 0.9687\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0239 Acc: 0.9915\n",
      "Val Loss: 0.1463 Acc: 0.9651\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0272 Acc: 0.9902\n",
      "Val Loss: 0.1257 Acc: 0.9707\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0259 Acc: 0.9905\n",
      "Val Loss: 0.1326 Acc: 0.9700\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0216 Acc: 0.9920\n",
      "Val Loss: 0.1698 Acc: 0.9648\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0225 Acc: 0.9924\n",
      "Val Loss: 0.1409 Acc: 0.9720\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0267 Acc: 0.9926\n",
      "Val Loss: 0.1774 Acc: 0.9678\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7915)\n",
      "Train Loss: 0.0319 Acc: 0.9894\n",
      "Val Loss: 0.1514 Acc: 0.9684\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0220 Acc: 0.9934\n",
      "Val Loss: 0.1881 Acc: 0.9639\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0120 Acc: 0.9959\n",
      "Val Loss: 0.1448 Acc: 0.9723\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0026 Acc: 0.9991\n",
      "Val Loss: 0.1334 Acc: 0.9770\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0012 Acc: 0.9996\n",
      "Val Loss: 0.1320 Acc: 0.9772\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0019 Acc: 0.9996\n",
      "Val Loss: 0.1411 Acc: 0.9757\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7992)\n",
      "Train Loss: 0.0041 Acc: 0.9990\n",
      "Val Loss: 0.1760 Acc: 0.9695\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0458 Acc: 0.9876\n",
      "Val Loss: 0.2424 Acc: 0.9581\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0209 Acc: 0.9931\n",
      "Val Loss: 0.1476 Acc: 0.9742\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0018 Acc: 0.9999\n",
      "Val Loss: 0.1458 Acc: 0.9754\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0010 Acc: 1.0000\n",
      "Val Loss: 0.1454 Acc: 0.9756\n",
      "\n",
      "Training complete in 6m 10s\n",
      "Best val Acc: 0.977180\n"
     ]
    }
   ],
   "source": [
    "best_net88, best_acc88, last_net88 = train_model(net88, train_y8_dl, test_dl, criterion, optimizer88, exp_lr_scheduler_88,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "id": "a4S7nGSE6wZJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6546)\n",
      "Train Loss: 1.1768 Acc: 0.8183\n",
      "Val Loss: 0.1911 Acc: 0.9394\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7657)\n",
      "Train Loss: 0.1504 Acc: 0.9571\n",
      "Val Loss: 0.1332 Acc: 0.9595\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7758)\n",
      "Train Loss: 0.0982 Acc: 0.9698\n",
      "Val Loss: 0.1230 Acc: 0.9642\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7835)\n",
      "Train Loss: 0.0606 Acc: 0.9794\n",
      "Val Loss: 0.1782 Acc: 0.9521\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7876)\n",
      "Train Loss: 0.0480 Acc: 0.9845\n",
      "Val Loss: 0.1563 Acc: 0.9590\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7893)\n",
      "Train Loss: 0.0405 Acc: 0.9866\n",
      "Val Loss: 0.1284 Acc: 0.9678\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7915)\n",
      "Train Loss: 0.0290 Acc: 0.9894\n",
      "Val Loss: 0.1270 Acc: 0.9702\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0234 Acc: 0.9920\n",
      "Val Loss: 0.1588 Acc: 0.9641\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0226 Acc: 0.9910\n",
      "Val Loss: 0.1515 Acc: 0.9696\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0117 Acc: 0.9960\n",
      "Val Loss: 0.1655 Acc: 0.9676\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0266 Acc: 0.9912\n",
      "Val Loss: 0.1979 Acc: 0.9637\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0305 Acc: 0.9892\n",
      "Val Loss: 0.1820 Acc: 0.9629\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7900)\n",
      "Train Loss: 0.0453 Acc: 0.9875\n",
      "Val Loss: 0.1723 Acc: 0.9646\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7920)\n",
      "Train Loss: 0.0328 Acc: 0.9900\n",
      "Val Loss: 0.1899 Acc: 0.9639\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0153 Acc: 0.9951\n",
      "Val Loss: 0.1480 Acc: 0.9725\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0079 Acc: 0.9978\n",
      "Val Loss: 0.1692 Acc: 0.9723\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0102 Acc: 0.9971\n",
      "Val Loss: 0.1926 Acc: 0.9655\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0059 Acc: 0.9985\n",
      "Val Loss: 0.1681 Acc: 0.9719\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0210 Acc: 0.9929\n",
      "Val Loss: 0.2252 Acc: 0.9659\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0416 Acc: 0.9889\n",
      "Val Loss: 0.1878 Acc: 0.9652\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0127 Acc: 0.9956\n",
      "Val Loss: 0.1585 Acc: 0.9709\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0020 Acc: 0.9999\n",
      "Val Loss: 0.1561 Acc: 0.9712\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0011 Acc: 1.0000\n",
      "Val Loss: 0.1549 Acc: 0.9713\n",
      "\n",
      "Training complete in 6m 8s\n",
      "Best val Acc: 0.972543\n"
     ]
    }
   ],
   "source": [
    "best_net89, best_acc89, last_net89 = train_model(net89, train_y9_dl, test_dl, criterion, optimizer89, exp_lr_scheduler_89,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "id": "8cRXCreC6wM0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6549)\n",
      "Train Loss: 1.1866 Acc: 0.8186\n",
      "Val Loss: 0.2077 Acc: 0.9331\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7652)\n",
      "Train Loss: 0.1381 Acc: 0.9565\n",
      "Val Loss: 0.1350 Acc: 0.9605\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7780)\n",
      "Train Loss: 0.0875 Acc: 0.9725\n",
      "Val Loss: 0.1215 Acc: 0.9668\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7840)\n",
      "Train Loss: 0.0640 Acc: 0.9800\n",
      "Val Loss: 0.1296 Acc: 0.9613\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7899)\n",
      "Train Loss: 0.0404 Acc: 0.9874\n",
      "Val Loss: 0.1483 Acc: 0.9636\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7897)\n",
      "Train Loss: 0.0379 Acc: 0.9871\n",
      "Val Loss: 0.1198 Acc: 0.9702\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0217 Acc: 0.9929\n",
      "Val Loss: 0.1502 Acc: 0.9648\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0255 Acc: 0.9911\n",
      "Val Loss: 0.1587 Acc: 0.9668\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0420 Acc: 0.9869\n",
      "Val Loss: 0.1247 Acc: 0.9698\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0167 Acc: 0.9945\n",
      "Val Loss: 0.1390 Acc: 0.9695\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7966)\n",
      "Train Loss: 0.0120 Acc: 0.9958\n",
      "Val Loss: 0.1447 Acc: 0.9722\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0072 Acc: 0.9979\n",
      "Val Loss: 0.1453 Acc: 0.9715\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0032 Acc: 0.9986\n",
      "Val Loss: 0.1593 Acc: 0.9713\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0247 Acc: 0.9920\n",
      "Val Loss: 0.2052 Acc: 0.9649\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0507 Acc: 0.9854\n",
      "Val Loss: 0.2138 Acc: 0.9654\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0413 Acc: 0.9892\n",
      "Val Loss: 0.1623 Acc: 0.9675\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0140 Acc: 0.9954\n",
      "Val Loss: 0.1333 Acc: 0.9751\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0103 Acc: 0.9970\n",
      "Val Loss: 0.1467 Acc: 0.9740\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0112 Acc: 0.9970\n",
      "Val Loss: 0.1571 Acc: 0.9742\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0069 Acc: 0.9978\n",
      "Val Loss: 0.1831 Acc: 0.9721\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0034 Acc: 0.9985\n",
      "Val Loss: 0.1549 Acc: 0.9758\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1544 Acc: 0.9762\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1540 Acc: 0.9762\n",
      "\n",
      "Training complete in 6m 6s\n",
      "Best val Acc: 0.976180\n"
     ]
    }
   ],
   "source": [
    "best_net90, best_acc90, last_net90 = train_model(net90, train_y10_dl, test_dl, criterion, optimizer90, exp_lr_scheduler_90,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "id": "7BrwEhF08zxF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6632)\n",
      "Train Loss: 1.4673 Acc: 0.8290\n",
      "Val Loss: 0.2273 Acc: 0.9284\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7594)\n",
      "Train Loss: 0.1552 Acc: 0.9493\n",
      "Val Loss: 0.1589 Acc: 0.9513\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7761)\n",
      "Train Loss: 0.0883 Acc: 0.9701\n",
      "Val Loss: 0.1326 Acc: 0.9592\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7873)\n",
      "Train Loss: 0.0509 Acc: 0.9841\n",
      "Val Loss: 0.1363 Acc: 0.9646\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7908)\n",
      "Train Loss: 0.0335 Acc: 0.9885\n",
      "Val Loss: 0.1355 Acc: 0.9704\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0294 Acc: 0.9905\n",
      "Val Loss: 0.1539 Acc: 0.9629\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0295 Acc: 0.9911\n",
      "Val Loss: 0.1930 Acc: 0.9548\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7887)\n",
      "Train Loss: 0.0400 Acc: 0.9859\n",
      "Val Loss: 0.1431 Acc: 0.9673\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0269 Acc: 0.9902\n",
      "Val Loss: 0.1978 Acc: 0.9572\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0245 Acc: 0.9922\n",
      "Val Loss: 0.1989 Acc: 0.9577\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0230 Acc: 0.9928\n",
      "Val Loss: 0.1635 Acc: 0.9675\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0206 Acc: 0.9945\n",
      "Val Loss: 0.1499 Acc: 0.9716\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0062 Acc: 0.9981\n",
      "Val Loss: 0.1645 Acc: 0.9699\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7967)\n",
      "Train Loss: 0.0127 Acc: 0.9959\n",
      "Val Loss: 0.1996 Acc: 0.9675\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0101 Acc: 0.9969\n",
      "Val Loss: 0.1775 Acc: 0.9709\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0346 Acc: 0.9902\n",
      "Val Loss: 0.2572 Acc: 0.9604\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7893)\n",
      "Train Loss: 0.0490 Acc: 0.9866\n",
      "Val Loss: 0.2137 Acc: 0.9620\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0244 Acc: 0.9911\n",
      "Val Loss: 0.2449 Acc: 0.9603\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0211 Acc: 0.9942\n",
      "Val Loss: 0.1789 Acc: 0.9697\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0200 Acc: 0.9940\n",
      "Val Loss: 0.2130 Acc: 0.9696\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7989)\n",
      "Train Loss: 0.0048 Acc: 0.9986\n",
      "Val Loss: 0.1962 Acc: 0.9726\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0011 Acc: 0.9999\n",
      "Val Loss: 0.1952 Acc: 0.9728\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1945 Acc: 0.9729\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.972907\n"
     ]
    }
   ],
   "source": [
    "best_net91, best_acc91, last_net91 = train_model(net91, train_z1_dl, test_dl, criterion, optimizer91, exp_lr_scheduler_91,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "id": "p29zbKXz8-AT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6617)\n",
      "Train Loss: 1.2717 Acc: 0.8271\n",
      "Val Loss: 0.1935 Acc: 0.9383\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7612)\n",
      "Train Loss: 0.1460 Acc: 0.9515\n",
      "Val Loss: 0.1473 Acc: 0.9566\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7796)\n",
      "Train Loss: 0.0756 Acc: 0.9745\n",
      "Val Loss: 0.1564 Acc: 0.9579\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7813)\n",
      "Train Loss: 0.0695 Acc: 0.9766\n",
      "Val Loss: 0.1741 Acc: 0.9530\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7866)\n",
      "Train Loss: 0.0483 Acc: 0.9832\n",
      "Val Loss: 0.1542 Acc: 0.9603\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7915)\n",
      "Train Loss: 0.0295 Acc: 0.9894\n",
      "Val Loss: 0.1511 Acc: 0.9656\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0349 Acc: 0.9884\n",
      "Val Loss: 0.1839 Acc: 0.9612\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7906)\n",
      "Train Loss: 0.0363 Acc: 0.9882\n",
      "Val Loss: 0.1599 Acc: 0.9657\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0180 Acc: 0.9941\n",
      "Val Loss: 0.1463 Acc: 0.9722\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0162 Acc: 0.9960\n",
      "Val Loss: 0.1502 Acc: 0.9707\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0306 Acc: 0.9896\n",
      "Val Loss: 0.1772 Acc: 0.9626\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0345 Acc: 0.9878\n",
      "Val Loss: 0.1742 Acc: 0.9683\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0307 Acc: 0.9890\n",
      "Val Loss: 0.1840 Acc: 0.9693\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0381 Acc: 0.9895\n",
      "Val Loss: 0.1678 Acc: 0.9669\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0205 Acc: 0.9931\n",
      "Val Loss: 0.1935 Acc: 0.9675\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0168 Acc: 0.9949\n",
      "Val Loss: 0.1571 Acc: 0.9753\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0138 Acc: 0.9962\n",
      "Val Loss: 0.1597 Acc: 0.9745\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0178 Acc: 0.9949\n",
      "Val Loss: 0.2141 Acc: 0.9666\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0271 Acc: 0.9924\n",
      "Val Loss: 0.1706 Acc: 0.9729\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0054 Acc: 0.9985\n",
      "Val Loss: 0.1399 Acc: 0.9772\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0013 Acc: 0.9994\n",
      "Val Loss: 0.1301 Acc: 0.9779\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1302 Acc: 0.9783\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1305 Acc: 0.9785\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.978453\n"
     ]
    }
   ],
   "source": [
    "best_net92, best_acc92, last_net92 = train_model(net92, train_z2_dl, test_dl, criterion, optimizer92, exp_lr_scheduler_92,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "id": "BVDeim7W89yg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6519)\n",
      "Train Loss: 1.4355 Acc: 0.8149\n",
      "Val Loss: 0.1900 Acc: 0.9394\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7598)\n",
      "Train Loss: 0.1598 Acc: 0.9497\n",
      "Val Loss: 0.1464 Acc: 0.9544\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7768)\n",
      "Train Loss: 0.0886 Acc: 0.9710\n",
      "Val Loss: 0.1588 Acc: 0.9537\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7828)\n",
      "Train Loss: 0.0637 Acc: 0.9785\n",
      "Val Loss: 0.1205 Acc: 0.9655\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7892)\n",
      "Train Loss: 0.0404 Acc: 0.9865\n",
      "Val Loss: 0.1509 Acc: 0.9627\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0352 Acc: 0.9890\n",
      "Val Loss: 0.1148 Acc: 0.9710\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0358 Acc: 0.9888\n",
      "Val Loss: 0.1421 Acc: 0.9641\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0304 Acc: 0.9891\n",
      "Val Loss: 0.1418 Acc: 0.9680\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0309 Acc: 0.9909\n",
      "Val Loss: 0.1337 Acc: 0.9691\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0127 Acc: 0.9950\n",
      "Val Loss: 0.1241 Acc: 0.9727\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0152 Acc: 0.9940\n",
      "Val Loss: 0.1464 Acc: 0.9705\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0129 Acc: 0.9954\n",
      "Val Loss: 0.1406 Acc: 0.9705\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0167 Acc: 0.9942\n",
      "Val Loss: 0.1352 Acc: 0.9714\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0210 Acc: 0.9924\n",
      "Val Loss: 0.2108 Acc: 0.9591\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7877)\n",
      "Train Loss: 0.0536 Acc: 0.9846\n",
      "Val Loss: 0.1654 Acc: 0.9642\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0226 Acc: 0.9932\n",
      "Val Loss: 0.1374 Acc: 0.9734\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0227 Acc: 0.9932\n",
      "Val Loss: 0.1718 Acc: 0.9678\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0145 Acc: 0.9952\n",
      "Val Loss: 0.1588 Acc: 0.9733\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0250 Acc: 0.9938\n",
      "Val Loss: 0.2511 Acc: 0.9549\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0324 Acc: 0.9905\n",
      "Val Loss: 0.1900 Acc: 0.9649\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0099 Acc: 0.9970\n",
      "Val Loss: 0.1471 Acc: 0.9735\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0018 Acc: 0.9998\n",
      "Val Loss: 0.1448 Acc: 0.9735\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0007 Acc: 1.0000\n",
      "Val Loss: 0.1437 Acc: 0.9743\n",
      "\n",
      "Training complete in 6m 14s\n",
      "Best val Acc: 0.974270\n"
     ]
    }
   ],
   "source": [
    "best_net93, best_acc93, last_net93 = train_model(net93, train_z3_dl, test_dl, criterion, optimizer93, exp_lr_scheduler_93,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "id": "fw7vjFuK89pH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(5908)\n",
      "Train Loss: 1.5932 Acc: 0.7385\n",
      "Val Loss: 0.2041 Acc: 0.9384\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7558)\n",
      "Train Loss: 0.1723 Acc: 0.9447\n",
      "Val Loss: 0.1629 Acc: 0.9525\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7710)\n",
      "Train Loss: 0.1038 Acc: 0.9637\n",
      "Val Loss: 0.1399 Acc: 0.9573\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7808)\n",
      "Train Loss: 0.0780 Acc: 0.9760\n",
      "Val Loss: 0.1320 Acc: 0.9636\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0399 Acc: 0.9876\n",
      "Val Loss: 0.1185 Acc: 0.9698\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0291 Acc: 0.9902\n",
      "Val Loss: 0.1378 Acc: 0.9649\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7900)\n",
      "Train Loss: 0.0333 Acc: 0.9875\n",
      "Val Loss: 0.2682 Acc: 0.9348\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7895)\n",
      "Train Loss: 0.0371 Acc: 0.9869\n",
      "Val Loss: 0.1295 Acc: 0.9689\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0225 Acc: 0.9909\n",
      "Val Loss: 0.2054 Acc: 0.9590\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0208 Acc: 0.9926\n",
      "Val Loss: 0.1335 Acc: 0.9721\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0072 Acc: 0.9979\n",
      "Val Loss: 0.1444 Acc: 0.9708\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0067 Acc: 0.9982\n",
      "Val Loss: 0.1444 Acc: 0.9706\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0088 Acc: 0.9976\n",
      "Val Loss: 0.1502 Acc: 0.9726\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7997)\n",
      "Train Loss: 0.0017 Acc: 0.9996\n",
      "Val Loss: 0.1638 Acc: 0.9712\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0008 Acc: 0.9999\n",
      "Val Loss: 0.1449 Acc: 0.9754\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1416 Acc: 0.9756\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1421 Acc: 0.9760\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0001 Acc: 1.0000\n",
      "Val Loss: 0.1424 Acc: 0.9760\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1427 Acc: 0.9761\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1430 Acc: 0.9765\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1431 Acc: 0.9765\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1432 Acc: 0.9765\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0000 Acc: 1.0000\n",
      "Val Loss: 0.1432 Acc: 0.9765\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.976543\n"
     ]
    }
   ],
   "source": [
    "best_net94, best_acc94, last_net94 = train_model(net94, train_z4_dl, test_dl, criterion, optimizer94, exp_lr_scheduler_94,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "id": "4TXWqtLx89dl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6747)\n",
      "Train Loss: 1.0001 Acc: 0.8434\n",
      "Val Loss: 0.1722 Acc: 0.9506\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7718)\n",
      "Train Loss: 0.1156 Acc: 0.9647\n",
      "Val Loss: 0.1592 Acc: 0.9543\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7836)\n",
      "Train Loss: 0.0641 Acc: 0.9795\n",
      "Val Loss: 0.1490 Acc: 0.9568\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0434 Acc: 0.9854\n",
      "Val Loss: 0.1260 Acc: 0.9687\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0264 Acc: 0.9911\n",
      "Val Loss: 0.1194 Acc: 0.9727\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0255 Acc: 0.9911\n",
      "Val Loss: 0.1574 Acc: 0.9657\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0256 Acc: 0.9925\n",
      "Val Loss: 0.1270 Acc: 0.9711\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0252 Acc: 0.9916\n",
      "Val Loss: 0.2433 Acc: 0.9561\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0346 Acc: 0.9889\n",
      "Val Loss: 0.1535 Acc: 0.9652\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7949)\n",
      "Train Loss: 0.0171 Acc: 0.9936\n",
      "Val Loss: 0.1148 Acc: 0.9772\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0152 Acc: 0.9954\n",
      "Val Loss: 0.1665 Acc: 0.9715\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0204 Acc: 0.9931\n",
      "Val Loss: 0.1489 Acc: 0.9705\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0088 Acc: 0.9978\n",
      "Val Loss: 0.1454 Acc: 0.9734\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0235 Acc: 0.9940\n",
      "Val Loss: 0.1662 Acc: 0.9673\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0186 Acc: 0.9930\n",
      "Val Loss: 0.1637 Acc: 0.9703\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0217 Acc: 0.9932\n",
      "Val Loss: 0.1649 Acc: 0.9750\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0392 Acc: 0.9898\n",
      "Val Loss: 0.2011 Acc: 0.9647\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7898)\n",
      "Train Loss: 0.0433 Acc: 0.9872\n",
      "Val Loss: 0.2040 Acc: 0.9665\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0166 Acc: 0.9955\n",
      "Val Loss: 0.1624 Acc: 0.9764\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0186 Acc: 0.9952\n",
      "Val Loss: 0.1730 Acc: 0.9716\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0049 Acc: 0.9984\n",
      "Val Loss: 0.1382 Acc: 0.9769\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1372 Acc: 0.9774\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1373 Acc: 0.9780\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.977998\n"
     ]
    }
   ],
   "source": [
    "best_net95, best_acc95, last_net95 = train_model(net95, train_z5_dl, test_dl, criterion, optimizer95, exp_lr_scheduler_95,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "id": "r9aAMwKT89Ry"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6552)\n",
      "Train Loss: 1.1785 Acc: 0.8190\n",
      "Val Loss: 0.1927 Acc: 0.9415\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7682)\n",
      "Train Loss: 0.1316 Acc: 0.9603\n",
      "Val Loss: 0.1278 Acc: 0.9595\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7813)\n",
      "Train Loss: 0.0724 Acc: 0.9766\n",
      "Val Loss: 0.1640 Acc: 0.9499\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0489 Acc: 0.9835\n",
      "Val Loss: 0.1189 Acc: 0.9662\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7913)\n",
      "Train Loss: 0.0356 Acc: 0.9891\n",
      "Val Loss: 0.1264 Acc: 0.9641\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0290 Acc: 0.9896\n",
      "Val Loss: 0.1372 Acc: 0.9658\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0214 Acc: 0.9929\n",
      "Val Loss: 0.1449 Acc: 0.9673\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0197 Acc: 0.9945\n",
      "Val Loss: 0.1841 Acc: 0.9596\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7914)\n",
      "Train Loss: 0.0326 Acc: 0.9892\n",
      "Val Loss: 0.1439 Acc: 0.9655\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0238 Acc: 0.9926\n",
      "Val Loss: 0.1655 Acc: 0.9665\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0204 Acc: 0.9930\n",
      "Val Loss: 0.1508 Acc: 0.9679\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0134 Acc: 0.9946\n",
      "Val Loss: 0.1588 Acc: 0.9696\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0184 Acc: 0.9932\n",
      "Val Loss: 0.1970 Acc: 0.9648\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0262 Acc: 0.9914\n",
      "Val Loss: 0.2016 Acc: 0.9648\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0297 Acc: 0.9915\n",
      "Val Loss: 0.1923 Acc: 0.9662\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0240 Acc: 0.9925\n",
      "Val Loss: 0.1970 Acc: 0.9686\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0153 Acc: 0.9952\n",
      "Val Loss: 0.1799 Acc: 0.9694\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0231 Acc: 0.9924\n",
      "Val Loss: 0.3338 Acc: 0.9479\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0298 Acc: 0.9925\n",
      "Val Loss: 0.2525 Acc: 0.9619\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0376 Acc: 0.9895\n",
      "Val Loss: 0.2131 Acc: 0.9645\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0099 Acc: 0.9968\n",
      "Val Loss: 0.1581 Acc: 0.9720\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0009 Acc: 0.9999\n",
      "Val Loss: 0.1564 Acc: 0.9731\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1558 Acc: 0.9735\n",
      "\n",
      "Training complete in 6m 13s\n",
      "Best val Acc: 0.973452\n"
     ]
    }
   ],
   "source": [
    "best_net96, best_acc96, last_net96 = train_model(net96, train_z6_dl, test_dl, criterion, optimizer96, exp_lr_scheduler_96,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "id": "FDUr4u1489G9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6541)\n",
      "Train Loss: 1.3782 Acc: 0.8176\n",
      "Val Loss: 0.1958 Acc: 0.9380\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7667)\n",
      "Train Loss: 0.1358 Acc: 0.9584\n",
      "Val Loss: 0.1720 Acc: 0.9466\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7779)\n",
      "Train Loss: 0.0820 Acc: 0.9724\n",
      "Val Loss: 0.1196 Acc: 0.9639\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0439 Acc: 0.9861\n",
      "Val Loss: 0.1206 Acc: 0.9663\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7877)\n",
      "Train Loss: 0.0477 Acc: 0.9846\n",
      "Val Loss: 0.1521 Acc: 0.9594\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7891)\n",
      "Train Loss: 0.0410 Acc: 0.9864\n",
      "Val Loss: 0.1738 Acc: 0.9605\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7894)\n",
      "Train Loss: 0.0454 Acc: 0.9868\n",
      "Val Loss: 0.1221 Acc: 0.9686\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0208 Acc: 0.9926\n",
      "Val Loss: 0.1167 Acc: 0.9710\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0037 Acc: 0.9991\n",
      "Val Loss: 0.1155 Acc: 0.9751\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0023 Acc: 0.9994\n",
      "Val Loss: 0.1320 Acc: 0.9725\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0235 Acc: 0.9918\n",
      "Val Loss: 0.1908 Acc: 0.9615\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7915)\n",
      "Train Loss: 0.0367 Acc: 0.9894\n",
      "Val Loss: 0.2251 Acc: 0.9523\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7880)\n",
      "Train Loss: 0.0507 Acc: 0.9850\n",
      "Val Loss: 0.1791 Acc: 0.9623\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0119 Acc: 0.9954\n",
      "Val Loss: 0.1344 Acc: 0.9737\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0073 Acc: 0.9978\n",
      "Val Loss: 0.1563 Acc: 0.9725\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0142 Acc: 0.9949\n",
      "Val Loss: 0.2058 Acc: 0.9668\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0282 Acc: 0.9924\n",
      "Val Loss: 0.1973 Acc: 0.9651\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0305 Acc: 0.9910\n",
      "Val Loss: 0.2168 Acc: 0.9580\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0239 Acc: 0.9930\n",
      "Val Loss: 0.1610 Acc: 0.9693\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0173 Acc: 0.9946\n",
      "Val Loss: 0.1699 Acc: 0.9707\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7990)\n",
      "Train Loss: 0.0033 Acc: 0.9988\n",
      "Val Loss: 0.1533 Acc: 0.9751\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1532 Acc: 0.9750\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1531 Acc: 0.9747\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.975089\n"
     ]
    }
   ],
   "source": [
    "best_net97, best_acc97, last_net97 = train_model(net97, train_z7_dl, test_dl, criterion, optimizer97, exp_lr_scheduler_97,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "id": "JZf6IARh887k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6467)\n",
      "Train Loss: 1.4935 Acc: 0.8084\n",
      "Val Loss: 0.1581 Acc: 0.9537\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7692)\n",
      "Train Loss: 0.1236 Acc: 0.9615\n",
      "Val Loss: 0.1253 Acc: 0.9599\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7825)\n",
      "Train Loss: 0.0614 Acc: 0.9781\n",
      "Val Loss: 0.1497 Acc: 0.9596\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7815)\n",
      "Train Loss: 0.0660 Acc: 0.9769\n",
      "Val Loss: 0.1348 Acc: 0.9618\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7887)\n",
      "Train Loss: 0.0430 Acc: 0.9859\n",
      "Val Loss: 0.1132 Acc: 0.9713\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0234 Acc: 0.9922\n",
      "Val Loss: 0.1811 Acc: 0.9629\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7924)\n",
      "Train Loss: 0.0262 Acc: 0.9905\n",
      "Val Loss: 0.1560 Acc: 0.9655\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0211 Acc: 0.9931\n",
      "Val Loss: 0.1436 Acc: 0.9695\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0393 Acc: 0.9884\n",
      "Val Loss: 0.1561 Acc: 0.9635\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0212 Acc: 0.9929\n",
      "Val Loss: 0.1770 Acc: 0.9678\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0163 Acc: 0.9951\n",
      "Val Loss: 0.1540 Acc: 0.9706\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0072 Acc: 0.9971\n",
      "Val Loss: 0.1387 Acc: 0.9740\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0098 Acc: 0.9970\n",
      "Val Loss: 0.1536 Acc: 0.9694\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0298 Acc: 0.9908\n",
      "Val Loss: 0.2081 Acc: 0.9589\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0549 Acc: 0.9854\n",
      "Val Loss: 0.1494 Acc: 0.9725\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0177 Acc: 0.9955\n",
      "Val Loss: 0.1516 Acc: 0.9730\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0147 Acc: 0.9950\n",
      "Val Loss: 0.1634 Acc: 0.9714\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0089 Acc: 0.9978\n",
      "Val Loss: 0.1545 Acc: 0.9748\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0163 Acc: 0.9949\n",
      "Val Loss: 0.1996 Acc: 0.9688\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7928)\n",
      "Train Loss: 0.0310 Acc: 0.9910\n",
      "Val Loss: 0.1582 Acc: 0.9718\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0070 Acc: 0.9982\n",
      "Val Loss: 0.1334 Acc: 0.9756\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0009 Acc: 0.9999\n",
      "Val Loss: 0.1309 Acc: 0.9762\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Loss: 0.1302 Acc: 0.9768\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.976816\n"
     ]
    }
   ],
   "source": [
    "best_net98, best_acc98, last_net98 = train_model(net98, train_z8_dl, test_dl, criterion, optimizer98, exp_lr_scheduler_98,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "id": "VI0pV_Bg88vW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6726)\n",
      "Train Loss: 1.3700 Acc: 0.8407\n",
      "Val Loss: 0.2049 Acc: 0.9349\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7689)\n",
      "Train Loss: 0.1271 Acc: 0.9611\n",
      "Val Loss: 0.1263 Acc: 0.9625\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7843)\n",
      "Train Loss: 0.0644 Acc: 0.9804\n",
      "Val Loss: 0.1257 Acc: 0.9656\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7855)\n",
      "Train Loss: 0.0533 Acc: 0.9819\n",
      "Val Loss: 0.1769 Acc: 0.9518\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7910)\n",
      "Train Loss: 0.0320 Acc: 0.9888\n",
      "Val Loss: 0.1315 Acc: 0.9682\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0131 Acc: 0.9955\n",
      "Val Loss: 0.1409 Acc: 0.9675\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0100 Acc: 0.9971\n",
      "Val Loss: 0.1166 Acc: 0.9730\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0117 Acc: 0.9956\n",
      "Val Loss: 0.1574 Acc: 0.9672\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7917)\n",
      "Train Loss: 0.0351 Acc: 0.9896\n",
      "Val Loss: 0.1574 Acc: 0.9666\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0315 Acc: 0.9904\n",
      "Val Loss: 0.1861 Acc: 0.9645\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0195 Acc: 0.9926\n",
      "Val Loss: 0.1403 Acc: 0.9687\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0130 Acc: 0.9955\n",
      "Val Loss: 0.1624 Acc: 0.9710\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0181 Acc: 0.9935\n",
      "Val Loss: 0.2246 Acc: 0.9630\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0203 Acc: 0.9940\n",
      "Val Loss: 0.1707 Acc: 0.9693\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0179 Acc: 0.9944\n",
      "Val Loss: 0.1765 Acc: 0.9696\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0211 Acc: 0.9939\n",
      "Val Loss: 0.2111 Acc: 0.9685\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0230 Acc: 0.9929\n",
      "Val Loss: 0.1881 Acc: 0.9682\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0252 Acc: 0.9925\n",
      "Val Loss: 0.2067 Acc: 0.9710\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0251 Acc: 0.9931\n",
      "Val Loss: 0.1591 Acc: 0.9718\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0066 Acc: 0.9980\n",
      "Val Loss: 0.1680 Acc: 0.9742\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0043 Acc: 0.9994\n",
      "Val Loss: 0.1554 Acc: 0.9754\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0010 Acc: 0.9998\n",
      "Val Loss: 0.1513 Acc: 0.9758\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1512 Acc: 0.9759\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.975907\n"
     ]
    }
   ],
   "source": [
    "best_net99, best_acc99, last_net99 = train_model(net99, train_z9_dl, test_dl, criterion, optimizer99, exp_lr_scheduler_99,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "id": "OSWQXB-L88kl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6405)\n",
      "Train Loss: 1.4579 Acc: 0.8006\n",
      "Val Loss: 0.1996 Acc: 0.9365\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7622)\n",
      "Train Loss: 0.1479 Acc: 0.9527\n",
      "Val Loss: 0.1746 Acc: 0.9445\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7755)\n",
      "Train Loss: 0.0881 Acc: 0.9694\n",
      "Val Loss: 0.1260 Acc: 0.9634\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7873)\n",
      "Train Loss: 0.0487 Acc: 0.9841\n",
      "Val Loss: 0.1004 Acc: 0.9732\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0353 Acc: 0.9889\n",
      "Val Loss: 0.1466 Acc: 0.9609\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0235 Acc: 0.9926\n",
      "Val Loss: 0.1086 Acc: 0.9704\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0170 Acc: 0.9940\n",
      "Val Loss: 0.1410 Acc: 0.9665\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0233 Acc: 0.9916\n",
      "Val Loss: 0.1114 Acc: 0.9728\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0330 Acc: 0.9902\n",
      "Val Loss: 0.1662 Acc: 0.9582\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0263 Acc: 0.9912\n",
      "Val Loss: 0.1292 Acc: 0.9725\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0256 Acc: 0.9906\n",
      "Val Loss: 0.1537 Acc: 0.9665\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0200 Acc: 0.9929\n",
      "Val Loss: 0.1340 Acc: 0.9731\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7991)\n",
      "Train Loss: 0.0054 Acc: 0.9989\n",
      "Val Loss: 0.1382 Acc: 0.9742\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7942)\n",
      "Train Loss: 0.0230 Acc: 0.9928\n",
      "Val Loss: 0.1559 Acc: 0.9685\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0206 Acc: 0.9940\n",
      "Val Loss: 0.1634 Acc: 0.9691\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0183 Acc: 0.9949\n",
      "Val Loss: 0.1637 Acc: 0.9715\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0224 Acc: 0.9940\n",
      "Val Loss: 0.1924 Acc: 0.9686\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0303 Acc: 0.9915\n",
      "Val Loss: 0.1529 Acc: 0.9705\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0198 Acc: 0.9929\n",
      "Val Loss: 0.1988 Acc: 0.9677\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0261 Acc: 0.9926\n",
      "Val Loss: 0.2027 Acc: 0.9650\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0162 Acc: 0.9956\n",
      "Val Loss: 0.1490 Acc: 0.9737\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7996)\n",
      "Train Loss: 0.0021 Acc: 0.9995\n",
      "Val Loss: 0.1461 Acc: 0.9737\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0008 Acc: 1.0000\n",
      "Val Loss: 0.1458 Acc: 0.9738\n",
      "\n",
      "Training complete in 6m 9s\n",
      "Best val Acc: 0.974179\n"
     ]
    }
   ],
   "source": [
    "best_net100, best_acc100, last_net100 = train_model(net100, train_z10_dl, test_dl, criterion, optimizer100, exp_lr_scheduler_100,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "id": "AibJyO8BLaMK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6598)\n",
      "Train Loss: 1.3481 Acc: 0.8247\n",
      "Val Loss: 0.1858 Acc: 0.9437\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7669)\n",
      "Train Loss: 0.1344 Acc: 0.9586\n",
      "Val Loss: 0.1913 Acc: 0.9449\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7788)\n",
      "Train Loss: 0.0803 Acc: 0.9735\n",
      "Val Loss: 0.1296 Acc: 0.9617\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7859)\n",
      "Train Loss: 0.0558 Acc: 0.9824\n",
      "Val Loss: 0.1560 Acc: 0.9579\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0337 Acc: 0.9898\n",
      "Val Loss: 0.1159 Acc: 0.9685\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7911)\n",
      "Train Loss: 0.0321 Acc: 0.9889\n",
      "Val Loss: 0.1921 Acc: 0.9547\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0289 Acc: 0.9914\n",
      "Val Loss: 0.1504 Acc: 0.9647\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0207 Acc: 0.9935\n",
      "Val Loss: 0.1346 Acc: 0.9672\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0155 Acc: 0.9949\n",
      "Val Loss: 0.1449 Acc: 0.9702\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7929)\n",
      "Train Loss: 0.0280 Acc: 0.9911\n",
      "Val Loss: 0.1610 Acc: 0.9665\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0237 Acc: 0.9920\n",
      "Val Loss: 0.1765 Acc: 0.9660\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7907)\n",
      "Train Loss: 0.0356 Acc: 0.9884\n",
      "Val Loss: 0.1783 Acc: 0.9682\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0130 Acc: 0.9952\n",
      "Val Loss: 0.1396 Acc: 0.9735\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0154 Acc: 0.9949\n",
      "Val Loss: 0.1679 Acc: 0.9702\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0349 Acc: 0.9898\n",
      "Val Loss: 0.1429 Acc: 0.9712\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0184 Acc: 0.9942\n",
      "Val Loss: 0.1567 Acc: 0.9716\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0250 Acc: 0.9939\n",
      "Val Loss: 0.1332 Acc: 0.9755\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0101 Acc: 0.9968\n",
      "Val Loss: 0.1640 Acc: 0.9734\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0194 Acc: 0.9925\n",
      "Val Loss: 0.1419 Acc: 0.9747\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0103 Acc: 0.9971\n",
      "Val Loss: 0.1525 Acc: 0.9749\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7994)\n",
      "Train Loss: 0.0033 Acc: 0.9992\n",
      "Val Loss: 0.1280 Acc: 0.9776\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1257 Acc: 0.9786\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1256 Acc: 0.9787\n",
      "\n",
      "Training complete in 6m 11s\n",
      "Best val Acc: 0.978725\n"
     ]
    }
   ],
   "source": [
    "best_net101, best_acc101, last_net101 = train_model(net101, train_zz_dl, test_dl, criterion, optimizer101, exp_lr_scheduler_101,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "id": "ZJKb7XDAL3Fj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6772)\n",
      "Train Loss: 1.3710 Acc: 0.8465\n",
      "Val Loss: 0.1582 Acc: 0.9517\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7702)\n",
      "Train Loss: 0.1174 Acc: 0.9627\n",
      "Val Loss: 0.1135 Acc: 0.9633\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7881)\n",
      "Train Loss: 0.0524 Acc: 0.9851\n",
      "Val Loss: 0.1192 Acc: 0.9666\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7883)\n",
      "Train Loss: 0.0419 Acc: 0.9854\n",
      "Val Loss: 0.1334 Acc: 0.9676\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0480 Acc: 0.9835\n",
      "Val Loss: 0.1194 Acc: 0.9698\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0268 Acc: 0.9924\n",
      "Val Loss: 0.1099 Acc: 0.9735\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0208 Acc: 0.9930\n",
      "Val Loss: 0.1324 Acc: 0.9705\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0098 Acc: 0.9975\n",
      "Val Loss: 0.1107 Acc: 0.9758\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0160 Acc: 0.9946\n",
      "Val Loss: 0.1449 Acc: 0.9693\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0371 Acc: 0.9879\n",
      "Val Loss: 0.1572 Acc: 0.9697\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7889)\n",
      "Train Loss: 0.0446 Acc: 0.9861\n",
      "Val Loss: 0.1294 Acc: 0.9708\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7951)\n",
      "Train Loss: 0.0203 Acc: 0.9939\n",
      "Val Loss: 0.1155 Acc: 0.9740\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0173 Acc: 0.9950\n",
      "Val Loss: 0.1615 Acc: 0.9689\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0107 Acc: 0.9968\n",
      "Val Loss: 0.1918 Acc: 0.9684\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0026 Acc: 0.9991\n",
      "Val Loss: 0.1147 Acc: 0.9794\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0114 Acc: 0.9965\n",
      "Val Loss: 0.1547 Acc: 0.9714\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0285 Acc: 0.9920\n",
      "Val Loss: 0.2407 Acc: 0.9613\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0364 Acc: 0.9890\n",
      "Val Loss: 0.2400 Acc: 0.9662\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0280 Acc: 0.9915\n",
      "Val Loss: 0.1975 Acc: 0.9698\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0310 Acc: 0.9916\n",
      "Val Loss: 0.1577 Acc: 0.9738\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7986)\n",
      "Train Loss: 0.0056 Acc: 0.9982\n",
      "Val Loss: 0.1300 Acc: 0.9783\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0005 Acc: 0.9999\n",
      "Val Loss: 0.1327 Acc: 0.9778\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1320 Acc: 0.9778\n",
      "\n",
      "Training complete in 6m 1s\n",
      "Best val Acc: 0.979362\n"
     ]
    }
   ],
   "source": [
    "best_net102, best_acc102, last_net102 = train_model(net102, train_zz_dl, test_dl, criterion, optimizer102, exp_lr_scheduler_102,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "id": "4Ep85PYxMANw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6387)\n",
      "Train Loss: 1.2584 Acc: 0.7984\n",
      "Val Loss: 0.2303 Acc: 0.9288\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7667)\n",
      "Train Loss: 0.1421 Acc: 0.9584\n",
      "Val Loss: 0.1500 Acc: 0.9546\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7785)\n",
      "Train Loss: 0.0826 Acc: 0.9731\n",
      "Val Loss: 0.1552 Acc: 0.9568\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7877)\n",
      "Train Loss: 0.0438 Acc: 0.9846\n",
      "Val Loss: 0.1228 Acc: 0.9673\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7922)\n",
      "Train Loss: 0.0309 Acc: 0.9902\n",
      "Val Loss: 0.1200 Acc: 0.9672\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7921)\n",
      "Train Loss: 0.0287 Acc: 0.9901\n",
      "Val Loss: 0.2239 Acc: 0.9507\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0234 Acc: 0.9924\n",
      "Val Loss: 0.1378 Acc: 0.9673\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0188 Acc: 0.9942\n",
      "Val Loss: 0.1493 Acc: 0.9665\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0271 Acc: 0.9912\n",
      "Val Loss: 0.1442 Acc: 0.9693\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0349 Acc: 0.9895\n",
      "Val Loss: 0.1412 Acc: 0.9685\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7934)\n",
      "Train Loss: 0.0253 Acc: 0.9918\n",
      "Val Loss: 0.1897 Acc: 0.9633\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0194 Acc: 0.9930\n",
      "Val Loss: 0.1490 Acc: 0.9705\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7962)\n",
      "Train Loss: 0.0138 Acc: 0.9952\n",
      "Val Loss: 0.1483 Acc: 0.9709\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7974)\n",
      "Train Loss: 0.0115 Acc: 0.9968\n",
      "Val Loss: 0.1801 Acc: 0.9668\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0126 Acc: 0.9965\n",
      "Val Loss: 0.1588 Acc: 0.9725\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0190 Acc: 0.9946\n",
      "Val Loss: 0.2401 Acc: 0.9592\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0227 Acc: 0.9931\n",
      "Val Loss: 0.2474 Acc: 0.9602\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0289 Acc: 0.9908\n",
      "Val Loss: 0.1830 Acc: 0.9676\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7916)\n",
      "Train Loss: 0.0378 Acc: 0.9895\n",
      "Val Loss: 0.1918 Acc: 0.9677\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0210 Acc: 0.9930\n",
      "Val Loss: 0.1647 Acc: 0.9705\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7983)\n",
      "Train Loss: 0.0076 Acc: 0.9979\n",
      "Val Loss: 0.1445 Acc: 0.9754\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0007 Acc: 1.0000\n",
      "Val Loss: 0.1438 Acc: 0.9759\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1433 Acc: 0.9761\n",
      "\n",
      "Training complete in 6m 2s\n",
      "Best val Acc: 0.976089\n"
     ]
    }
   ],
   "source": [
    "best_net103, best_acc103, last_net103 = train_model(net103, train_zz_dl, test_dl, criterion, optimizer103, exp_lr_scheduler_103,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "id": "ZaXPYLAbOIxY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6578)\n",
      "Train Loss: 1.0766 Acc: 0.8223\n",
      "Val Loss: 0.1887 Acc: 0.9434\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7670)\n",
      "Train Loss: 0.1303 Acc: 0.9587\n",
      "Val Loss: 0.1417 Acc: 0.9575\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7838)\n",
      "Train Loss: 0.0624 Acc: 0.9798\n",
      "Val Loss: 0.1258 Acc: 0.9632\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7867)\n",
      "Train Loss: 0.0500 Acc: 0.9834\n",
      "Val Loss: 0.1125 Acc: 0.9686\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7909)\n",
      "Train Loss: 0.0335 Acc: 0.9886\n",
      "Val Loss: 0.1775 Acc: 0.9583\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0353 Acc: 0.9878\n",
      "Val Loss: 0.1358 Acc: 0.9660\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0211 Acc: 0.9926\n",
      "Val Loss: 0.1950 Acc: 0.9541\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0194 Acc: 0.9924\n",
      "Val Loss: 0.1495 Acc: 0.9668\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0181 Acc: 0.9942\n",
      "Val Loss: 0.1362 Acc: 0.9706\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0143 Acc: 0.9950\n",
      "Val Loss: 0.1675 Acc: 0.9686\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7941)\n",
      "Train Loss: 0.0268 Acc: 0.9926\n",
      "Val Loss: 0.1843 Acc: 0.9667\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0293 Acc: 0.9919\n",
      "Val Loss: 0.1374 Acc: 0.9700\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0199 Acc: 0.9944\n",
      "Val Loss: 0.1831 Acc: 0.9651\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0242 Acc: 0.9930\n",
      "Val Loss: 0.1517 Acc: 0.9697\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7959)\n",
      "Train Loss: 0.0155 Acc: 0.9949\n",
      "Val Loss: 0.1552 Acc: 0.9705\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7971)\n",
      "Train Loss: 0.0123 Acc: 0.9964\n",
      "Val Loss: 0.1773 Acc: 0.9683\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0108 Acc: 0.9960\n",
      "Val Loss: 0.1459 Acc: 0.9725\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0265 Acc: 0.9914\n",
      "Val Loss: 0.1862 Acc: 0.9689\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0184 Acc: 0.9954\n",
      "Val Loss: 0.1554 Acc: 0.9732\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7978)\n",
      "Train Loss: 0.0079 Acc: 0.9972\n",
      "Val Loss: 0.1485 Acc: 0.9759\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7995)\n",
      "Train Loss: 0.0012 Acc: 0.9994\n",
      "Val Loss: 0.1358 Acc: 0.9773\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1346 Acc: 0.9778\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1339 Acc: 0.9783\n",
      "\n",
      "Training complete in 6m 2s\n",
      "Best val Acc: 0.978271\n"
     ]
    }
   ],
   "source": [
    "best_net104, best_acc104, last_net104 = train_model(net104, train_zz_dl, test_dl, criterion, optimizer104, exp_lr_scheduler_104,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "id": "-pvaIs4_OIsn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(5976)\n",
      "Train Loss: 1.6381 Acc: 0.7470\n",
      "Val Loss: 0.2755 Acc: 0.9230\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7562)\n",
      "Train Loss: 0.1781 Acc: 0.9453\n",
      "Val Loss: 0.1589 Acc: 0.9499\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7729)\n",
      "Train Loss: 0.1014 Acc: 0.9661\n",
      "Val Loss: 0.1151 Acc: 0.9676\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7843)\n",
      "Train Loss: 0.0608 Acc: 0.9804\n",
      "Val Loss: 0.1380 Acc: 0.9611\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7868)\n",
      "Train Loss: 0.0493 Acc: 0.9835\n",
      "Val Loss: 0.1157 Acc: 0.9671\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0358 Acc: 0.9876\n",
      "Val Loss: 0.1496 Acc: 0.9622\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0331 Acc: 0.9879\n",
      "Val Loss: 0.1500 Acc: 0.9643\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7968)\n",
      "Train Loss: 0.0166 Acc: 0.9960\n",
      "Val Loss: 0.1469 Acc: 0.9680\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0202 Acc: 0.9944\n",
      "Val Loss: 0.1411 Acc: 0.9690\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0264 Acc: 0.9912\n",
      "Val Loss: 0.2568 Acc: 0.9533\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7902)\n",
      "Train Loss: 0.0366 Acc: 0.9878\n",
      "Val Loss: 0.1880 Acc: 0.9589\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0220 Acc: 0.9935\n",
      "Val Loss: 0.1795 Acc: 0.9664\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7931)\n",
      "Train Loss: 0.0242 Acc: 0.9914\n",
      "Val Loss: 0.1574 Acc: 0.9675\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0184 Acc: 0.9940\n",
      "Val Loss: 0.2035 Acc: 0.9587\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0292 Acc: 0.9909\n",
      "Val Loss: 0.1545 Acc: 0.9705\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0109 Acc: 0.9965\n",
      "Val Loss: 0.1713 Acc: 0.9671\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0077 Acc: 0.9978\n",
      "Val Loss: 0.1752 Acc: 0.9714\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0081 Acc: 0.9965\n",
      "Val Loss: 0.1908 Acc: 0.9722\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7961)\n",
      "Train Loss: 0.0217 Acc: 0.9951\n",
      "Val Loss: 0.2076 Acc: 0.9640\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7935)\n",
      "Train Loss: 0.0278 Acc: 0.9919\n",
      "Val Loss: 0.2245 Acc: 0.9586\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7978)\n",
      "Train Loss: 0.0076 Acc: 0.9972\n",
      "Val Loss: 0.1538 Acc: 0.9734\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0011 Acc: 0.9999\n",
      "Val Loss: 0.1491 Acc: 0.9739\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1481 Acc: 0.9741\n",
      "\n",
      "Training complete in 6m 2s\n",
      "Best val Acc: 0.974089\n"
     ]
    }
   ],
   "source": [
    "best_net105, best_acc105, last_net105 = train_model(net105, train_zz_dl, test_dl, criterion, optimizer105, exp_lr_scheduler_105,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "id": "n7uvDJ9NOInh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6758)\n",
      "Train Loss: 1.0678 Acc: 0.8448\n",
      "Val Loss: 0.1651 Acc: 0.9492\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7714)\n",
      "Train Loss: 0.1146 Acc: 0.9643\n",
      "Val Loss: 0.1872 Acc: 0.9448\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7806)\n",
      "Train Loss: 0.0731 Acc: 0.9758\n",
      "Val Loss: 0.1172 Acc: 0.9662\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7880)\n",
      "Train Loss: 0.0414 Acc: 0.9850\n",
      "Val Loss: 0.1512 Acc: 0.9619\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7898)\n",
      "Train Loss: 0.0366 Acc: 0.9872\n",
      "Val Loss: 0.1186 Acc: 0.9692\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0325 Acc: 0.9898\n",
      "Val Loss: 0.1884 Acc: 0.9575\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7867)\n",
      "Train Loss: 0.0511 Acc: 0.9834\n",
      "Val Loss: 0.1685 Acc: 0.9620\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0154 Acc: 0.9944\n",
      "Val Loss: 0.1826 Acc: 0.9625\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7984)\n",
      "Train Loss: 0.0049 Acc: 0.9980\n",
      "Val Loss: 0.1586 Acc: 0.9715\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7900)\n",
      "Train Loss: 0.0441 Acc: 0.9875\n",
      "Val Loss: 0.1392 Acc: 0.9684\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0221 Acc: 0.9925\n",
      "Val Loss: 0.1301 Acc: 0.9709\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7969)\n",
      "Train Loss: 0.0120 Acc: 0.9961\n",
      "Val Loss: 0.1368 Acc: 0.9715\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0076 Acc: 0.9969\n",
      "Val Loss: 0.1454 Acc: 0.9725\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7993)\n",
      "Train Loss: 0.0023 Acc: 0.9991\n",
      "Val Loss: 0.1462 Acc: 0.9716\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7981)\n",
      "Train Loss: 0.0063 Acc: 0.9976\n",
      "Val Loss: 0.1762 Acc: 0.9688\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7939)\n",
      "Train Loss: 0.0258 Acc: 0.9924\n",
      "Val Loss: 0.2663 Acc: 0.9559\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7896)\n",
      "Train Loss: 0.0460 Acc: 0.9870\n",
      "Val Loss: 0.1833 Acc: 0.9638\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0327 Acc: 0.9908\n",
      "Val Loss: 0.1503 Acc: 0.9720\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7960)\n",
      "Train Loss: 0.0176 Acc: 0.9950\n",
      "Val Loss: 0.1556 Acc: 0.9734\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0181 Acc: 0.9944\n",
      "Val Loss: 0.1299 Acc: 0.9759\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7988)\n",
      "Train Loss: 0.0039 Acc: 0.9985\n",
      "Val Loss: 0.1261 Acc: 0.9769\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Loss: 0.1258 Acc: 0.9770\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Loss: 0.1258 Acc: 0.9766\n",
      "\n",
      "Training complete in 5m 60s\n",
      "Best val Acc: 0.976998\n"
     ]
    }
   ],
   "source": [
    "best_net106, best_acc106, last_net106 = train_model(net106, train_zz_dl, test_dl, criterion, optimizer106, exp_lr_scheduler_106,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "id": "Yx2_ZCt2OIiq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6690)\n",
      "Train Loss: 1.2081 Acc: 0.8363\n",
      "Val Loss: 0.1521 Acc: 0.9525\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7668)\n",
      "Train Loss: 0.1323 Acc: 0.9585\n",
      "Val Loss: 0.1232 Acc: 0.9632\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7814)\n",
      "Train Loss: 0.0705 Acc: 0.9768\n",
      "Val Loss: 0.1251 Acc: 0.9640\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7886)\n",
      "Train Loss: 0.0410 Acc: 0.9858\n",
      "Val Loss: 0.1563 Acc: 0.9605\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7903)\n",
      "Train Loss: 0.0393 Acc: 0.9879\n",
      "Val Loss: 0.1257 Acc: 0.9673\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7937)\n",
      "Train Loss: 0.0224 Acc: 0.9921\n",
      "Val Loss: 0.1323 Acc: 0.9664\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0243 Acc: 0.9908\n",
      "Val Loss: 0.1274 Acc: 0.9686\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7956)\n",
      "Train Loss: 0.0165 Acc: 0.9945\n",
      "Val Loss: 0.2267 Acc: 0.9528\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7923)\n",
      "Train Loss: 0.0291 Acc: 0.9904\n",
      "Val Loss: 0.1378 Acc: 0.9693\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7940)\n",
      "Train Loss: 0.0227 Acc: 0.9925\n",
      "Val Loss: 0.1345 Acc: 0.9725\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7976)\n",
      "Train Loss: 0.0103 Acc: 0.9970\n",
      "Val Loss: 0.1535 Acc: 0.9735\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7925)\n",
      "Train Loss: 0.0284 Acc: 0.9906\n",
      "Val Loss: 0.1849 Acc: 0.9659\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0237 Acc: 0.9929\n",
      "Val Loss: 0.1849 Acc: 0.9644\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7936)\n",
      "Train Loss: 0.0264 Acc: 0.9920\n",
      "Val Loss: 0.1776 Acc: 0.9691\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0205 Acc: 0.9934\n",
      "Val Loss: 0.2199 Acc: 0.9618\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0195 Acc: 0.9940\n",
      "Val Loss: 0.1839 Acc: 0.9703\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0169 Acc: 0.9944\n",
      "Val Loss: 0.2097 Acc: 0.9699\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0151 Acc: 0.9956\n",
      "Val Loss: 0.1895 Acc: 0.9727\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7965)\n",
      "Train Loss: 0.0118 Acc: 0.9956\n",
      "Val Loss: 0.1782 Acc: 0.9719\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0224 Acc: 0.9955\n",
      "Val Loss: 0.2513 Acc: 0.9614\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7982)\n",
      "Train Loss: 0.0073 Acc: 0.9978\n",
      "Val Loss: 0.1515 Acc: 0.9743\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1492 Acc: 0.9746\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1480 Acc: 0.9751\n",
      "\n",
      "Training complete in 5m 56s\n",
      "Best val Acc: 0.975089\n"
     ]
    }
   ],
   "source": [
    "best_net107, best_acc107, last_net107 = train_model(net107, train_zz_dl, test_dl, criterion, optimizer107, exp_lr_scheduler_107,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "id": "SIOIN8whOId4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6266)\n",
      "Train Loss: 1.9477 Acc: 0.7833\n",
      "Val Loss: 0.2462 Acc: 0.9262\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7550)\n",
      "Train Loss: 0.1769 Acc: 0.9437\n",
      "Val Loss: 0.1470 Acc: 0.9544\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7710)\n",
      "Train Loss: 0.1079 Acc: 0.9637\n",
      "Val Loss: 0.1562 Acc: 0.9522\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7791)\n",
      "Train Loss: 0.0777 Acc: 0.9739\n",
      "Val Loss: 0.1545 Acc: 0.9559\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7842)\n",
      "Train Loss: 0.0580 Acc: 0.9802\n",
      "Val Loss: 0.1600 Acc: 0.9571\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7831)\n",
      "Train Loss: 0.0571 Acc: 0.9789\n",
      "Val Loss: 0.1459 Acc: 0.9627\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7888)\n",
      "Train Loss: 0.0437 Acc: 0.9860\n",
      "Val Loss: 0.1575 Acc: 0.9600\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7938)\n",
      "Train Loss: 0.0254 Acc: 0.9922\n",
      "Val Loss: 0.1510 Acc: 0.9633\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0250 Acc: 0.9915\n",
      "Val Loss: 0.1588 Acc: 0.9633\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7953)\n",
      "Train Loss: 0.0201 Acc: 0.9941\n",
      "Val Loss: 0.1508 Acc: 0.9671\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7893)\n",
      "Train Loss: 0.0461 Acc: 0.9866\n",
      "Val Loss: 0.2353 Acc: 0.9515\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7882)\n",
      "Train Loss: 0.0480 Acc: 0.9852\n",
      "Val Loss: 0.1455 Acc: 0.9660\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7944)\n",
      "Train Loss: 0.0226 Acc: 0.9930\n",
      "Val Loss: 0.1605 Acc: 0.9668\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0162 Acc: 0.9946\n",
      "Val Loss: 0.1519 Acc: 0.9683\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0094 Acc: 0.9971\n",
      "Val Loss: 0.1454 Acc: 0.9713\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7970)\n",
      "Train Loss: 0.0126 Acc: 0.9962\n",
      "Val Loss: 0.1568 Acc: 0.9680\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7980)\n",
      "Train Loss: 0.0091 Acc: 0.9975\n",
      "Val Loss: 0.1518 Acc: 0.9715\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7977)\n",
      "Train Loss: 0.0082 Acc: 0.9971\n",
      "Val Loss: 0.1758 Acc: 0.9666\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0210 Acc: 0.9940\n",
      "Val Loss: 0.2202 Acc: 0.9605\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7901)\n",
      "Train Loss: 0.0444 Acc: 0.9876\n",
      "Val Loss: 0.2041 Acc: 0.9645\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7973)\n",
      "Train Loss: 0.0111 Acc: 0.9966\n",
      "Val Loss: 0.1567 Acc: 0.9716\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0015 Acc: 0.9999\n",
      "Val Loss: 0.1554 Acc: 0.9713\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0009 Acc: 1.0000\n",
      "Val Loss: 0.1552 Acc: 0.9715\n",
      "\n",
      "Training complete in 5m 59s\n",
      "Best val Acc: 0.971634\n"
     ]
    }
   ],
   "source": [
    "best_net108, best_acc108, last_net108 = train_model(net108, train_zz_dl, test_dl, criterion, optimizer108, exp_lr_scheduler_108,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "id": "VKDyBvtcOIXM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6722)\n",
      "Train Loss: 1.0999 Acc: 0.8403\n",
      "Val Loss: 0.1536 Acc: 0.9519\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7701)\n",
      "Train Loss: 0.1194 Acc: 0.9626\n",
      "Val Loss: 0.1593 Acc: 0.9529\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7811)\n",
      "Train Loss: 0.0737 Acc: 0.9764\n",
      "Val Loss: 0.1289 Acc: 0.9625\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7892)\n",
      "Train Loss: 0.0417 Acc: 0.9865\n",
      "Val Loss: 0.1361 Acc: 0.9636\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7904)\n",
      "Train Loss: 0.0341 Acc: 0.9880\n",
      "Val Loss: 0.1319 Acc: 0.9687\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7893)\n",
      "Train Loss: 0.0387 Acc: 0.9866\n",
      "Val Loss: 0.1835 Acc: 0.9572\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7932)\n",
      "Train Loss: 0.0254 Acc: 0.9915\n",
      "Val Loss: 0.1535 Acc: 0.9654\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7946)\n",
      "Train Loss: 0.0243 Acc: 0.9932\n",
      "Val Loss: 0.1505 Acc: 0.9684\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7957)\n",
      "Train Loss: 0.0161 Acc: 0.9946\n",
      "Val Loss: 0.1427 Acc: 0.9706\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7952)\n",
      "Train Loss: 0.0199 Acc: 0.9940\n",
      "Val Loss: 0.1932 Acc: 0.9624\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0203 Acc: 0.9944\n",
      "Val Loss: 0.1670 Acc: 0.9703\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0307 Acc: 0.9909\n",
      "Val Loss: 0.1703 Acc: 0.9699\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7918)\n",
      "Train Loss: 0.0370 Acc: 0.9898\n",
      "Val Loss: 0.1576 Acc: 0.9695\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0213 Acc: 0.9938\n",
      "Val Loss: 0.1943 Acc: 0.9693\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7947)\n",
      "Train Loss: 0.0214 Acc: 0.9934\n",
      "Val Loss: 0.1541 Acc: 0.9742\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0097 Acc: 0.9969\n",
      "Val Loss: 0.1496 Acc: 0.9757\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0060 Acc: 0.9981\n",
      "Val Loss: 0.1667 Acc: 0.9758\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7985)\n",
      "Train Loss: 0.0074 Acc: 0.9981\n",
      "Val Loss: 0.1922 Acc: 0.9682\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7979)\n",
      "Train Loss: 0.0066 Acc: 0.9974\n",
      "Val Loss: 0.1560 Acc: 0.9763\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7964)\n",
      "Train Loss: 0.0187 Acc: 0.9955\n",
      "Val Loss: 0.1845 Acc: 0.9705\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7987)\n",
      "Train Loss: 0.0059 Acc: 0.9984\n",
      "Val Loss: 0.1501 Acc: 0.9769\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7998)\n",
      "Train Loss: 0.0009 Acc: 0.9998\n",
      "Val Loss: 0.1484 Acc: 0.9773\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Loss: 0.1477 Acc: 0.9777\n",
      "\n",
      "Training complete in 6m 1s\n",
      "Best val Acc: 0.977725\n"
     ]
    }
   ],
   "source": [
    "best_net109, best_acc109, last_net109 = train_model(net109, train_zz_dl, test_dl, criterion, optimizer109, exp_lr_scheduler_109,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "id": "640H2yhiOISK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/22\n",
      "----------\n",
      "tensor(6720)\n",
      "Train Loss: 1.0907 Acc: 0.8400\n",
      "Val Loss: 0.1995 Acc: 0.9394\n",
      "\n",
      "Epoch 1/22\n",
      "----------\n",
      "tensor(7689)\n",
      "Train Loss: 0.1245 Acc: 0.9611\n",
      "Val Loss: 0.1529 Acc: 0.9532\n",
      "\n",
      "Epoch 2/22\n",
      "----------\n",
      "tensor(7831)\n",
      "Train Loss: 0.0700 Acc: 0.9789\n",
      "Val Loss: 0.1206 Acc: 0.9672\n",
      "\n",
      "Epoch 3/22\n",
      "----------\n",
      "tensor(7890)\n",
      "Train Loss: 0.0446 Acc: 0.9862\n",
      "Val Loss: 0.1444 Acc: 0.9624\n",
      "\n",
      "Epoch 4/22\n",
      "----------\n",
      "tensor(7852)\n",
      "Train Loss: 0.0545 Acc: 0.9815\n",
      "Val Loss: 0.1573 Acc: 0.9608\n",
      "\n",
      "Epoch 5/22\n",
      "----------\n",
      "tensor(7930)\n",
      "Train Loss: 0.0269 Acc: 0.9912\n",
      "Val Loss: 0.1850 Acc: 0.9569\n",
      "\n",
      "Epoch 6/22\n",
      "----------\n",
      "tensor(7926)\n",
      "Train Loss: 0.0290 Acc: 0.9908\n",
      "Val Loss: 0.1473 Acc: 0.9683\n",
      "\n",
      "Epoch 7/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0298 Acc: 0.9909\n",
      "Val Loss: 0.1190 Acc: 0.9734\n",
      "\n",
      "Epoch 8/22\n",
      "----------\n",
      "tensor(7912)\n",
      "Train Loss: 0.0326 Acc: 0.9890\n",
      "Val Loss: 0.1614 Acc: 0.9665\n",
      "\n",
      "Epoch 9/22\n",
      "----------\n",
      "tensor(7950)\n",
      "Train Loss: 0.0210 Acc: 0.9938\n",
      "Val Loss: 0.1294 Acc: 0.9725\n",
      "\n",
      "Epoch 10/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0165 Acc: 0.9942\n",
      "Val Loss: 0.1924 Acc: 0.9591\n",
      "\n",
      "Epoch 11/22\n",
      "----------\n",
      "tensor(7943)\n",
      "Train Loss: 0.0242 Acc: 0.9929\n",
      "Val Loss: 0.2032 Acc: 0.9624\n",
      "\n",
      "Epoch 12/22\n",
      "----------\n",
      "tensor(7955)\n",
      "Train Loss: 0.0158 Acc: 0.9944\n",
      "Val Loss: 0.1864 Acc: 0.9662\n",
      "\n",
      "Epoch 13/22\n",
      "----------\n",
      "tensor(7972)\n",
      "Train Loss: 0.0147 Acc: 0.9965\n",
      "Val Loss: 0.1964 Acc: 0.9645\n",
      "\n",
      "Epoch 14/22\n",
      "----------\n",
      "tensor(7933)\n",
      "Train Loss: 0.0260 Acc: 0.9916\n",
      "Val Loss: 0.2592 Acc: 0.9560\n",
      "\n",
      "Epoch 15/22\n",
      "----------\n",
      "tensor(7945)\n",
      "Train Loss: 0.0256 Acc: 0.9931\n",
      "Val Loss: 0.1653 Acc: 0.9713\n",
      "\n",
      "Epoch 16/22\n",
      "----------\n",
      "tensor(7954)\n",
      "Train Loss: 0.0177 Acc: 0.9942\n",
      "Val Loss: 0.1768 Acc: 0.9713\n",
      "\n",
      "Epoch 17/22\n",
      "----------\n",
      "tensor(7948)\n",
      "Train Loss: 0.0288 Acc: 0.9935\n",
      "Val Loss: 0.1548 Acc: 0.9735\n",
      "\n",
      "Epoch 18/22\n",
      "----------\n",
      "tensor(7927)\n",
      "Train Loss: 0.0347 Acc: 0.9909\n",
      "Val Loss: 0.1968 Acc: 0.9695\n",
      "\n",
      "Epoch 19/22\n",
      "----------\n",
      "tensor(7963)\n",
      "Train Loss: 0.0127 Acc: 0.9954\n",
      "Val Loss: 0.2142 Acc: 0.9655\n",
      "\n",
      "Epoch 20/22\n",
      "----------\n",
      "tensor(7975)\n",
      "Train Loss: 0.0094 Acc: 0.9969\n",
      "Val Loss: 0.1592 Acc: 0.9741\n",
      "\n",
      "Epoch 21/22\n",
      "----------\n",
      "tensor(7999)\n",
      "Train Loss: 0.0008 Acc: 0.9999\n",
      "Val Loss: 0.1545 Acc: 0.9745\n",
      "\n",
      "Epoch 22/22\n",
      "----------\n",
      "tensor(8000)\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Loss: 0.1542 Acc: 0.9744\n",
      "\n",
      "Training complete in 5m 60s\n",
      "Best val Acc: 0.974543\n"
     ]
    }
   ],
   "source": [
    "best_net110, best_acc110, last_net110 = train_model(net110, train_zz_dl, test_dl, criterion, optimizer110, exp_lr_scheduler_110,\n",
    "                        num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "id": "-wdOueSbyprw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-340-35c23184f3f4>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_1 = sm1(outputs_prob_1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.2311e-17, 1.6791e-10, 1.0000e+00, 1.9529e-12, 9.5740e-19, 5.0655e-22,\n",
      "         1.0462e-19, 1.6868e-16, 5.0111e-13, 3.5292e-17]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.1\n"
     ]
    }
   ],
   "source": [
    "correct_prob_1 = 0\n",
    "total_prob_1 = 0\n",
    "post_prob_1 = []\n",
    "pred_prob_1 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_1 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net1.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_1, labels_prob_1 = data\n",
    "            outputs_prob_1 = best_net1(images_prob_1)\n",
    "\n",
    "            sm1 = torch.nn.Softmax()\n",
    "            probabilities_prob_1 = sm1(outputs_prob_1)\n",
    "            post_prob_1.append(probabilities_prob_1)\n",
    "            _, predicted_prob_1 = torch.max(outputs_prob_1.data, 1)\n",
    "            pred_prob_1.append(predicted_prob_1.item())\n",
    "            \n",
    "\n",
    "            total_prob_1 += labels_prob_1.size(0)\n",
    "            correct_prob_1 += (predicted_prob_1== labels_prob_1).sum().item()\n",
    "    accuracy = 100 * (correct_prob_1 / total_prob_1)\n",
    "    post_probs_1.append(post_prob_1)\n",
    "\n",
    "print('Probabilities', probabilities_prob_1)\n",
    "print('length of Probabilities', len(post_prob_1))\n",
    "print('Total Images: ', total_prob_1)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "id": "my0BjWtU0nid"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_probs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "id": "CTDuPVZhx3il"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-342-5c22f64ff48a>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_2 = sm2(outputs_prob_2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.6798e-15, 8.9793e-16, 1.0000e+00, 9.1708e-13, 1.4585e-17, 5.5337e-23,\n",
      "         7.2669e-24, 1.0743e-13, 4.5956e-11, 3.1938e-11]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.89999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_2 = 0\n",
    "total_prob_2 = 0\n",
    "post_prob_2 = []\n",
    "pred_prob_2 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_2 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net2.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_2, labels_prob_2 = data\n",
    "            outputs_prob_2 = best_net2(images_prob_2)\n",
    "\n",
    "            sm2 = torch.nn.Softmax()\n",
    "            probabilities_prob_2 = sm2(outputs_prob_2)\n",
    "            post_prob_2.append(probabilities_prob_2)\n",
    "            _, predicted_prob_2 = torch.max(outputs_prob_2.data, 1)\n",
    "            pred_prob_2.append(predicted_prob_2.item())\n",
    "            \n",
    "\n",
    "            total_prob_2 += labels_prob_2.size(0)\n",
    "            correct_prob_2 += (predicted_prob_2== labels_prob_2).sum().item()\n",
    "    accuracy2 = 100 * (correct_prob_2 / total_prob_2)\n",
    "    post_probs_2.append(post_prob_2)\n",
    "\n",
    "print('Probabilities', probabilities_prob_2)\n",
    "print('length of Probabilities', len(post_prob_2))\n",
    "print('Total Images: ', total_prob_2)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBtVK7DEyZcU"
   },
   "outputs": [],
   "source": [
    "len(post_probs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "id": "t6Z3Ndpq2hh7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-343-0bcfcd79ccdb>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_3 = sm3(outputs_prob_3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[6.6597e-20, 2.6677e-16, 1.0000e+00, 1.2393e-15, 6.3340e-20, 7.9565e-20,\n",
      "         9.3748e-22, 5.5977e-19, 5.5554e-15, 1.1599e-19]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.89999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_3 = 0\n",
    "total_prob_3 = 0\n",
    "post_prob_3 = []\n",
    "pred_prob_3 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_3 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net3.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_3, labels_prob_3 = data\n",
    "            outputs_prob_3 = best_net3(images_prob_3)\n",
    "\n",
    "            sm3 = torch.nn.Softmax()\n",
    "            probabilities_prob_3 = sm3(outputs_prob_3)\n",
    "            post_prob_3.append(probabilities_prob_3)\n",
    "            _, predicted_prob_3 = torch.max(outputs_prob_3.data, 1)\n",
    "            pred_prob_3.append(predicted_prob_3.item())\n",
    "            \n",
    "\n",
    "            total_prob_3 += labels_prob_3.size(0)\n",
    "            correct_prob_3 += (predicted_prob_3 == labels_prob_3).sum().item()\n",
    "    accuracy3 = 100 * (correct_prob_3 / total_prob_3)\n",
    "    post_probs_3.append(post_prob_3)\n",
    "\n",
    "print('Probabilities', probabilities_prob_3)\n",
    "print('length of Probabilities', len(post_prob_3))\n",
    "print('Total Images: ', total_prob_3)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lN2K3I362_XH"
   },
   "outputs": [],
   "source": [
    "len(post_probs_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "id": "ZXjJmsdC3X0S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-344-927539e56e9d>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_4 = sm4(outputs_prob_4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[7.2628e-12, 1.8392e-09, 9.9999e-01, 2.8787e-06, 2.4013e-09, 5.9221e-09,\n",
      "         7.5587e-12, 4.9364e-12, 1.1297e-05, 1.0139e-07]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.18\n"
     ]
    }
   ],
   "source": [
    "correct_prob_4 = 0\n",
    "total_prob_4 = 0\n",
    "post_prob_4 = []\n",
    "pred_prob_4 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_4 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net4.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_4, labels_prob_4 = data\n",
    "            outputs_prob_4 = best_net4(images_prob_4)\n",
    "\n",
    "            sm4 = torch.nn.Softmax()\n",
    "            probabilities_prob_4 = sm4(outputs_prob_4)\n",
    "            post_prob_4.append(probabilities_prob_4)\n",
    "            _, predicted_prob_4 = torch.max(outputs_prob_4.data, 1)\n",
    "            pred_prob_4.append(predicted_prob_4.item())\n",
    "            \n",
    "\n",
    "            total_prob_4 += labels_prob_4.size(0)\n",
    "            correct_prob_4 += (predicted_prob_4 == labels_prob_4).sum().item()\n",
    "    accuracy4 = 100 * (correct_prob_4 / total_prob_4)\n",
    "    post_probs_4.append(post_prob_4)\n",
    "\n",
    "print('Probabilities', probabilities_prob_4)\n",
    "print('length of Probabilities', len(post_prob_4))\n",
    "print('Total Images: ', total_prob_4)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MEEyTBK39aa"
   },
   "outputs": [],
   "source": [
    "len(post_probs_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "id": "qeIWv22R4Rf6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-345-1ceff2c4410e>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_5 = sm5(outputs_prob_5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.5860e-14, 1.6309e-13, 1.0000e+00, 4.1419e-10, 3.0816e-16, 3.9804e-20,\n",
      "         7.6569e-18, 2.9629e-14, 5.1891e-09, 9.9961e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.54\n"
     ]
    }
   ],
   "source": [
    "correct_prob_5 = 0\n",
    "total_prob_5 = 0\n",
    "post_prob_5 = []\n",
    "pred_prob_5 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_5 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net5.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_5, labels_prob_5 = data\n",
    "            outputs_prob_5 = best_net5(images_prob_5)\n",
    "\n",
    "            sm5 = torch.nn.Softmax()\n",
    "            probabilities_prob_5 = sm5(outputs_prob_5)\n",
    "            post_prob_5.append(probabilities_prob_5)\n",
    "            _, predicted_prob_5 = torch.max(outputs_prob_5.data, 1)\n",
    "            pred_prob_5.append(predicted_prob_5.item())\n",
    "            \n",
    "\n",
    "            total_prob_5 += labels_prob_5.size(0)\n",
    "            correct_prob_5 += (predicted_prob_5 == labels_prob_5).sum().item()\n",
    "        accuracy5 = 100 * (correct_prob_5 / total_prob_5)\n",
    "        post_probs_5.append(post_prob_5)\n",
    "\n",
    "print('Probabilities', probabilities_prob_5)\n",
    "print('length of Probabilities', len(post_prob_5))\n",
    "print('Total Images: ', total_prob_5)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "id": "nyqVelEwdyEi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-346-6aa255551f0f>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_6 = sm6(outputs_prob_6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.5860e-14, 1.6309e-13, 1.0000e+00, 4.1419e-10, 3.0816e-16, 3.9804e-20,\n",
      "         7.6569e-18, 2.9629e-14, 5.1891e-09, 9.9961e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.54\n"
     ]
    }
   ],
   "source": [
    "correct_prob_6 = 0\n",
    "total_prob_6 = 0\n",
    "post_prob_6 = []\n",
    "pred_prob_6 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_6 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net6.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_6, labels_prob_6 = data\n",
    "            outputs_prob_6 = best_net5(images_prob_6)\n",
    "\n",
    "            sm6 = torch.nn.Softmax()\n",
    "            probabilities_prob_6 = sm6(outputs_prob_6)\n",
    "            post_prob_6.append(probabilities_prob_6)\n",
    "            _, predicted_prob_6 = torch.max(outputs_prob_6.data, 1)\n",
    "            pred_prob_6.append(predicted_prob_6.item())\n",
    "            \n",
    "\n",
    "            total_prob_6 += labels_prob_6.size(0)\n",
    "            correct_prob_6 += (predicted_prob_6 == labels_prob_6).sum().item()\n",
    "        accuracy6 = 100 * (correct_prob_6 / total_prob_6)\n",
    "        post_probs_6.append(post_prob_6)\n",
    "\n",
    "print('Probabilities', probabilities_prob_6)\n",
    "print('length of Probabilities', len(post_prob_6))\n",
    "print('Total Images: ', total_prob_6)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "id": "orzXKY73ePYJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-347-14ff12d996ff>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_7 = sm7(outputs_prob_7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[6.0153e-18, 2.4741e-10, 1.0000e+00, 2.0639e-11, 4.6793e-14, 2.0483e-16,\n",
      "         9.7691e-18, 2.4969e-15, 4.3546e-10, 2.4175e-16]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.68\n"
     ]
    }
   ],
   "source": [
    "correct_prob_7 = 0\n",
    "total_prob_7 = 0\n",
    "post_prob_7 = []\n",
    "pred_prob_7 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_7 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net7.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_7, labels_prob_7 = data\n",
    "            outputs_prob_7 = best_net7(images_prob_7)\n",
    "\n",
    "            sm7 = torch.nn.Softmax()\n",
    "            probabilities_prob_7 = sm7(outputs_prob_7)\n",
    "            post_prob_7.append(probabilities_prob_7)\n",
    "            _, predicted_prob_7 = torch.max(outputs_prob_7.data, 1)\n",
    "            pred_prob_7.append(predicted_prob_7.item())\n",
    "            \n",
    "\n",
    "            total_prob_7 += labels_prob_7.size(0)\n",
    "            correct_prob_7 += (predicted_prob_7 == labels_prob_7).sum().item()\n",
    "        accuracy7 = 100 * (correct_prob_7 / total_prob_7)\n",
    "        post_probs_7.append(post_prob_7)\n",
    "\n",
    "print('Probabilities', probabilities_prob_7)\n",
    "print('length of Probabilities', len(post_prob_7))\n",
    "print('Total Images: ', total_prob_7)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "id": "JxT1RGQJenpi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-348-1c7c4411ace4>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_8 = sm8(outputs_prob_8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.2515e-13, 3.9438e-15, 1.0000e+00, 1.1867e-11, 9.0211e-17, 3.7062e-17,\n",
      "         6.7109e-18, 5.1793e-16, 5.2356e-07, 4.9580e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.89999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_8 = 0\n",
    "total_prob_8 = 0\n",
    "post_prob_8 = []\n",
    "pred_prob_8 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_8 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net8.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_8, labels_prob_8 = data\n",
    "            outputs_prob_8 = best_net8(images_prob_8)\n",
    "\n",
    "            sm8 = torch.nn.Softmax()\n",
    "            probabilities_prob_8 = sm8(outputs_prob_8)\n",
    "            post_prob_8.append(probabilities_prob_8)\n",
    "            _, predicted_prob_8 = torch.max(outputs_prob_8.data, 1)\n",
    "            pred_prob_8.append(predicted_prob_8.item())\n",
    "            \n",
    "\n",
    "            total_prob_8 += labels_prob_8.size(0)\n",
    "            correct_prob_8 += (predicted_prob_8 == labels_prob_8).sum().item()\n",
    "        accuracy8 = 100 * (correct_prob_8 / total_prob_8)\n",
    "        post_probs_8.append(post_prob_8)\n",
    "\n",
    "print('Probabilities', probabilities_prob_8)\n",
    "print('length of Probabilities', len(post_prob_8))\n",
    "print('Total Images: ', total_prob_8)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "id": "hIj4fMwAfCyl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-349-d962df51e73f>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_9 = sm9(outputs_prob_9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.0625e-15, 1.5395e-12, 1.0000e+00, 2.3070e-08, 4.4282e-14, 1.8190e-14,\n",
      "         5.3331e-15, 3.3496e-12, 2.6163e-11, 5.3016e-17]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.11999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_9 = 0\n",
    "total_prob_9 = 0\n",
    "post_prob_9 = []\n",
    "pred_prob_9 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_9 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net9.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_9, labels_prob_9 = data\n",
    "            outputs_prob_9 = best_net9(images_prob_9)\n",
    "\n",
    "            sm9 = torch.nn.Softmax()\n",
    "            probabilities_prob_9 = sm9(outputs_prob_9)\n",
    "            post_prob_9.append(probabilities_prob_9)\n",
    "            _, predicted_prob_9 = torch.max(outputs_prob_9.data, 1)\n",
    "            pred_prob_9.append(predicted_prob_9.item())\n",
    "            \n",
    "\n",
    "            total_prob_9 += labels_prob_9.size(0)\n",
    "            correct_prob_9 += (predicted_prob_9 == labels_prob_9).sum().item()\n",
    "        accuracy9 = 100 * (correct_prob_9 / total_prob_9)\n",
    "        post_probs_9.append(post_prob_9)\n",
    "\n",
    "print('Probabilities', probabilities_prob_9)\n",
    "print('length of Probabilities', len(post_prob_9))\n",
    "print('Total Images: ', total_prob_9)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "id": "V8PAGvD7flA3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-350-9de1375da429>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_10 = sm10(outputs_prob_10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[7.7668e-17, 2.2894e-16, 1.0000e+00, 3.1669e-18, 1.0323e-27, 4.1521e-20,\n",
      "         1.1189e-20, 8.8350e-21, 9.2972e-14, 1.7312e-21]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.68\n"
     ]
    }
   ],
   "source": [
    "correct_prob_10 = 0\n",
    "total_prob_10 = 0\n",
    "post_prob_10 = []\n",
    "pred_prob_10 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_10 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net10.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_10, labels_prob_10 = data\n",
    "            outputs_prob_10 = best_net10(images_prob_10)\n",
    "\n",
    "            sm10 = torch.nn.Softmax()\n",
    "            probabilities_prob_10 = sm10(outputs_prob_10)\n",
    "            post_prob_10.append(probabilities_prob_10)\n",
    "            _, predicted_prob_10 = torch.max(outputs_prob_10.data, 1)\n",
    "            pred_prob_10.append(predicted_prob_10.item())\n",
    "            \n",
    "\n",
    "            total_prob_10 += labels_prob_10.size(0)\n",
    "            correct_prob_10 += (predicted_prob_10 == labels_prob_10).sum().item()\n",
    "        accuracy10 = 100 * (correct_prob_10 / total_prob_10)\n",
    "        post_probs_10.append(post_prob_10)\n",
    "\n",
    "print('Probabilities', probabilities_prob_10)\n",
    "print('length of Probabilities', len(post_prob_10))\n",
    "print('Total Images: ', total_prob_10)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "id": "rDguKWHpgFh-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-351-05ab7bb5d337>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_11 = sm11(outputs_prob_11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.1344e-10, 3.8606e-12, 1.0000e+00, 2.9192e-07, 1.0269e-13, 1.1708e-11,\n",
      "         1.7953e-09, 7.5653e-11, 4.2632e-07, 1.1147e-09]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.68\n"
     ]
    }
   ],
   "source": [
    "correct_prob_11 = 0\n",
    "total_prob_11 = 0\n",
    "post_prob_11 = []\n",
    "pred_prob_11 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_11 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net11.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_11, labels_prob_11 = data\n",
    "            outputs_prob_11 = best_net11(images_prob_11)\n",
    "\n",
    "            sm11 = torch.nn.Softmax()\n",
    "            probabilities_prob_11 = sm11(outputs_prob_11)\n",
    "            post_prob_11.append(probabilities_prob_11)\n",
    "            _, predicted_prob_11 = torch.max(outputs_prob_11.data, 1)\n",
    "            pred_prob_11.append(predicted_prob_11.item())\n",
    "            \n",
    "\n",
    "            total_prob_11 += labels_prob_11.size(0)\n",
    "            correct_prob_11 += (predicted_prob_11 == labels_prob_11).sum().item()\n",
    "        accuracy11 = 100 * (correct_prob_11 / total_prob_11)\n",
    "        post_probs_11.append(post_prob_11)\n",
    "\n",
    "print('Probabilities', probabilities_prob_11)\n",
    "print('length of Probabilities', len(post_prob_11))\n",
    "print('Total Images: ', total_prob_11)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "id": "_GOvleXWTbVS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-352-95f418c093f5>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_12 = sm12(outputs_prob_12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[7.7495e-17, 3.7623e-14, 1.0000e+00, 7.7563e-12, 2.7005e-14, 2.1933e-17,\n",
      "         2.3213e-17, 5.4363e-19, 8.1074e-12, 8.5627e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.0\n"
     ]
    }
   ],
   "source": [
    "correct_prob_12 = 0\n",
    "total_prob_12 = 0\n",
    "post_prob_12 = []\n",
    "pred_prob_12 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_12 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net12.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_12, labels_prob_12 = data\n",
    "            outputs_prob_12 = best_net12(images_prob_12)\n",
    "\n",
    "            sm12 = torch.nn.Softmax()\n",
    "            probabilities_prob_12 = sm12(outputs_prob_12)\n",
    "            post_prob_12.append(probabilities_prob_12)\n",
    "            _, predicted_prob_12 = torch.max(outputs_prob_12.data, 1)\n",
    "            pred_prob_12.append(predicted_prob_12.item())\n",
    "            \n",
    "\n",
    "            total_prob_12 += labels_prob_12.size(0)\n",
    "            correct_prob_12 += (predicted_prob_12 == labels_prob_12).sum().item()\n",
    "        accuracy12 = 100 * (correct_prob_12 / total_prob_12)\n",
    "        post_probs_12.append(post_prob_12)\n",
    "\n",
    "print('Probabilities', probabilities_prob_12)\n",
    "print('length of Probabilities', len(post_prob_12))\n",
    "print('Total Images: ', total_prob_12)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "id": "xVRPpW2_T-tD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-353-76784ec1b32c>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_13 = sm13(outputs_prob_13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.8968e-19, 2.9403e-19, 1.0000e+00, 9.9071e-15, 1.4924e-15, 1.0421e-15,\n",
      "         4.6904e-16, 3.9612e-16, 1.8172e-12, 4.1714e-17]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.82\n"
     ]
    }
   ],
   "source": [
    "correct_prob_13 = 0\n",
    "total_prob_13 = 0\n",
    "post_prob_13 = []\n",
    "pred_prob_13 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_13 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net13.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_13, labels_prob_13 = data\n",
    "            outputs_prob_13 = best_net13(images_prob_13)\n",
    "\n",
    "            sm13 = torch.nn.Softmax()\n",
    "            probabilities_prob_13 = sm13(outputs_prob_13)\n",
    "            post_prob_13.append(probabilities_prob_13)\n",
    "            _, predicted_prob_13 = torch.max(outputs_prob_13.data, 1)\n",
    "            pred_prob_13.append(predicted_prob_13.item())\n",
    "            \n",
    "\n",
    "            total_prob_13 += labels_prob_13.size(0)\n",
    "            correct_prob_13 += (predicted_prob_13 == labels_prob_13).sum().item()\n",
    "        accuracy13 = 100 * (correct_prob_13 / total_prob_13)\n",
    "        post_probs_13.append(post_prob_13)\n",
    "\n",
    "print('Probabilities', probabilities_prob_13)\n",
    "print('length of Probabilities', len(post_prob_13))\n",
    "print('Total Images: ', total_prob_13)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "id": "lBOD5dpmUhqz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-354-8d304423106a>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_14 = sm14(outputs_prob_14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.7738e-15, 1.7899e-14, 1.0000e+00, 2.4038e-13, 2.6439e-14, 5.2917e-18,\n",
      "         6.9278e-20, 1.5459e-14, 3.5925e-11, 6.3423e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.8\n"
     ]
    }
   ],
   "source": [
    "correct_prob_14 = 0\n",
    "total_prob_14 = 0\n",
    "post_prob_14 = []\n",
    "pred_prob_14 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_14 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net14.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_14, labels_prob_14 = data\n",
    "            outputs_prob_14 = best_net14(images_prob_14)\n",
    "\n",
    "            sm14 = torch.nn.Softmax()\n",
    "            probabilities_prob_14 = sm14(outputs_prob_14)\n",
    "            post_prob_14.append(probabilities_prob_14)\n",
    "            _, predicted_prob_14 = torch.max(outputs_prob_14.data, 1)\n",
    "            pred_prob_14.append(predicted_prob_14.item())\n",
    "            \n",
    "\n",
    "            total_prob_14 += labels_prob_14.size(0)\n",
    "            correct_prob_14 += (predicted_prob_14 == labels_prob_14).sum().item()\n",
    "        accuracy14 = 100 * (correct_prob_14 / total_prob_14)\n",
    "        post_probs_14.append(post_prob_14)\n",
    "\n",
    "print('Probabilities', probabilities_prob_14)\n",
    "print('length of Probabilities', len(post_prob_14))\n",
    "print('Total Images: ', total_prob_14)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "id": "AZOZ5nXjXBvo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-355-9fc056aec161>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_15 = sm15(outputs_prob_15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.1326e-13, 4.2345e-10, 1.0000e+00, 1.2579e-09, 2.8781e-10, 1.2894e-14,\n",
      "         9.0437e-13, 1.4388e-07, 1.0316e-10, 1.0788e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.5\n"
     ]
    }
   ],
   "source": [
    "correct_prob_15 = 0\n",
    "total_prob_15 = 0\n",
    "post_prob_15 = []\n",
    "pred_prob_15 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_15 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net15.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_15, labels_prob_15 = data\n",
    "            outputs_prob_15 = best_net15(images_prob_15)\n",
    "\n",
    "            sm15 = torch.nn.Softmax()\n",
    "            probabilities_prob_15 = sm15(outputs_prob_15)\n",
    "            post_prob_15.append(probabilities_prob_15)\n",
    "            _, predicted_prob_15 = torch.max(outputs_prob_15.data, 1)\n",
    "            pred_prob_15.append(predicted_prob_15.item())\n",
    "            \n",
    "\n",
    "            total_prob_15 += labels_prob_15.size(0)\n",
    "            correct_prob_15 += (predicted_prob_15 == labels_prob_15).sum().item()\n",
    "        accuracy15 = 100 * (correct_prob_15 / total_prob_15)\n",
    "        post_probs_15.append(post_prob_15)\n",
    "\n",
    "print('Probabilities', probabilities_prob_15)\n",
    "print('length of Probabilities', len(post_prob_15))\n",
    "print('Total Images: ', total_prob_15)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "id": "drw2BBcNXmPx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-356-351289562304>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_16 = sm16(outputs_prob_16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.0767e-13, 1.5699e-15, 1.0000e+00, 5.5868e-13, 2.9880e-15, 6.4775e-19,\n",
      "         5.2434e-20, 1.9728e-17, 4.6256e-13, 2.4465e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.61999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_16 = 0\n",
    "total_prob_16 = 0\n",
    "post_prob_16 = []\n",
    "pred_prob_16 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_16 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net16.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_16, labels_prob_16 = data\n",
    "            outputs_prob_16 = best_net16(images_prob_16)\n",
    "\n",
    "            sm16 = torch.nn.Softmax()\n",
    "            probabilities_prob_16 = sm16(outputs_prob_16)\n",
    "            post_prob_16.append(probabilities_prob_16)\n",
    "            _, predicted_prob_16 = torch.max(outputs_prob_16.data, 1)\n",
    "            pred_prob_16.append(predicted_prob_16.item())\n",
    "            \n",
    "\n",
    "            total_prob_16 += labels_prob_16.size(0)\n",
    "            correct_prob_16 += (predicted_prob_16 == labels_prob_16).sum().item()\n",
    "        accuracy16 = 100 * (correct_prob_16 / total_prob_16)\n",
    "        post_probs_16.append(post_prob_16)\n",
    "\n",
    "print('Probabilities', probabilities_prob_16)\n",
    "print('length of Probabilities', len(post_prob_16))\n",
    "print('Total Images: ', total_prob_16)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "id": "bu_JVejKYKb_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-357-ac5979f3c712>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_17 = sm17(outputs_prob_17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.9667e-17, 2.3077e-12, 1.0000e+00, 3.5965e-17, 3.8452e-18, 5.8200e-19,\n",
      "         2.4485e-17, 1.9848e-18, 9.8661e-14, 1.0779e-17]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.04\n"
     ]
    }
   ],
   "source": [
    "correct_prob_17 = 0\n",
    "total_prob_17 = 0\n",
    "post_prob_17 = []\n",
    "pred_prob_17 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_17 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net17.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_17, labels_prob_17 = data\n",
    "            outputs_prob_17 = best_net17(images_prob_17)\n",
    "\n",
    "            sm17 = torch.nn.Softmax()\n",
    "            probabilities_prob_17 = sm17(outputs_prob_17)\n",
    "            post_prob_17.append(probabilities_prob_17)\n",
    "            _, predicted_prob_17 = torch.max(outputs_prob_17.data, 1)\n",
    "            pred_prob_17.append(predicted_prob_17.item())\n",
    "            \n",
    "\n",
    "            total_prob_17 += labels_prob_17.size(0)\n",
    "            correct_prob_17 += (predicted_prob_17 == labels_prob_17).sum().item()\n",
    "        accuracy17 = 100 * (correct_prob_17 / total_prob_17)\n",
    "        post_probs_17.append(post_prob_17)\n",
    "\n",
    "print('Probabilities', probabilities_prob_17)\n",
    "print('length of Probabilities', len(post_prob_17))\n",
    "print('Total Images: ', total_prob_17)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "id": "6q1WbG4xZCjH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-358-79bb0499cc3b>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_18 = sm18(outputs_prob_18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[9.0322e-17, 1.1793e-09, 1.0000e+00, 1.9580e-09, 1.6724e-13, 3.5575e-17,\n",
      "         1.3098e-15, 1.6819e-13, 3.4736e-12, 1.5985e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.14\n"
     ]
    }
   ],
   "source": [
    "correct_prob_18 = 0\n",
    "total_prob_18 = 0\n",
    "post_prob_18 = []\n",
    "pred_prob_18 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_18 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net18.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_18, labels_prob_18 = data\n",
    "            outputs_prob_18 = best_net18(images_prob_18)\n",
    "\n",
    "            sm18 = torch.nn.Softmax()\n",
    "            probabilities_prob_18 = sm18(outputs_prob_18)\n",
    "            post_prob_18.append(probabilities_prob_18)\n",
    "            _, predicted_prob_18 = torch.max(outputs_prob_18.data, 1)\n",
    "            pred_prob_18.append(predicted_prob_18.item())\n",
    "            \n",
    "\n",
    "            total_prob_18 += labels_prob_18.size(0)\n",
    "            correct_prob_18 += (predicted_prob_18 == labels_prob_18).sum().item()\n",
    "        accuracy18 = 100 * (correct_prob_18 / total_prob_18)\n",
    "        post_probs_18.append(post_prob_18)\n",
    "\n",
    "print('Probabilities', probabilities_prob_18)\n",
    "print('length of Probabilities', len(post_prob_18))\n",
    "print('Total Images: ', total_prob_18)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "id": "UaG-EHcZZwrO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-359-937bf67f47c2>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_19 = sm19(outputs_prob_19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[6.6171e-21, 1.2290e-15, 1.0000e+00, 1.0685e-13, 1.7203e-21, 4.8746e-26,\n",
      "         7.8601e-25, 4.4933e-16, 2.1867e-14, 4.2006e-16]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.74000000000001\n"
     ]
    }
   ],
   "source": [
    "correct_prob_19 = 0\n",
    "total_prob_19 = 0\n",
    "post_prob_19 = []\n",
    "pred_prob_19 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_19 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net19.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_19, labels_prob_19 = data\n",
    "            outputs_prob_19 = best_net19(images_prob_19)\n",
    "\n",
    "            sm19 = torch.nn.Softmax()\n",
    "            probabilities_prob_19 = sm19(outputs_prob_19)\n",
    "            post_prob_19.append(probabilities_prob_19)\n",
    "            _, predicted_prob_19 = torch.max(outputs_prob_19.data, 1)\n",
    "            pred_prob_19.append(predicted_prob_19.item())\n",
    "            \n",
    "\n",
    "            total_prob_19 += labels_prob_19.size(0)\n",
    "            correct_prob_19 += (predicted_prob_19 == labels_prob_19).sum().item()\n",
    "        accuracy19 = 100 * (correct_prob_19 / total_prob_19)\n",
    "        post_probs_19.append(post_prob_19)\n",
    "\n",
    "print('Probabilities', probabilities_prob_19)\n",
    "print('length of Probabilities', len(post_prob_19))\n",
    "print('Total Images: ', total_prob_19)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "id": "_NZDaej9aS3B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-360-7db995b18920>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_20 = sm20(outputs_prob_20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.0956e-17, 2.0730e-12, 1.0000e+00, 9.9948e-10, 1.4946e-16, 1.1194e-17,\n",
      "         5.5839e-18, 3.8253e-15, 2.7411e-10, 2.9480e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.8\n"
     ]
    }
   ],
   "source": [
    "correct_prob_20 = 0\n",
    "total_prob_20 = 0\n",
    "post_prob_20 = []\n",
    "pred_prob_20 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_20 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net20.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_20, labels_prob_20 = data\n",
    "            outputs_prob_20 = best_net20(images_prob_20)\n",
    "\n",
    "            sm20 = torch.nn.Softmax()\n",
    "            probabilities_prob_20 = sm20(outputs_prob_20)\n",
    "            post_prob_20.append(probabilities_prob_20)\n",
    "            _, predicted_prob_20 = torch.max(outputs_prob_20.data, 1)\n",
    "            pred_prob_20.append(predicted_prob_20.item())\n",
    "            \n",
    "\n",
    "            total_prob_20 += labels_prob_20.size(0)\n",
    "            correct_prob_20 += (predicted_prob_20 == labels_prob_20).sum().item()\n",
    "        accuracy20 = 100 * (correct_prob_20 / total_prob_20)\n",
    "        post_probs_20.append(post_prob_20)\n",
    "\n",
    "print('Probabilities', probabilities_prob_20)\n",
    "print('length of Probabilities', len(post_prob_20))\n",
    "print('Total Images: ', total_prob_20)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "id": "L0ulOHygawsu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-361-2eba662de1a7>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_21 = sm21(outputs_prob_21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[4.3131e-12, 5.4317e-08, 1.0000e+00, 9.2693e-14, 8.0937e-18, 9.9152e-18,\n",
      "         6.5207e-16, 1.8090e-11, 3.4570e-13, 2.1425e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.46000000000001\n"
     ]
    }
   ],
   "source": [
    "correct_prob_21 = 0\n",
    "total_prob_21 = 0\n",
    "post_prob_21 = []\n",
    "pred_prob_21 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_21 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net21.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_21, labels_prob_21 = data\n",
    "            outputs_prob_21 = best_net21(images_prob_21)\n",
    "\n",
    "            sm21 = torch.nn.Softmax()\n",
    "            probabilities_prob_21 = sm21(outputs_prob_21)\n",
    "            post_prob_21.append(probabilities_prob_21)\n",
    "            _, predicted_prob_21 = torch.max(outputs_prob_21.data, 1)\n",
    "            pred_prob_21.append(predicted_prob_21.item())\n",
    "            \n",
    "\n",
    "            total_prob_21 += labels_prob_21.size(0)\n",
    "            correct_prob_21 += (predicted_prob_21 == labels_prob_21).sum().item()\n",
    "        accuracy21 = 100 * (correct_prob_21 / total_prob_21)\n",
    "        post_probs_21.append(post_prob_21)\n",
    "\n",
    "print('Probabilities', probabilities_prob_21)\n",
    "print('length of Probabilities', len(post_prob_21))\n",
    "print('Total Images: ', total_prob_21)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "id": "EuvQWTU2bdff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-362-d03f60b63915>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_22 = sm22(outputs_prob_22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.5993e-18, 7.7397e-17, 1.0000e+00, 8.8816e-14, 8.5495e-16, 3.0659e-23,\n",
      "         1.8706e-18, 1.4856e-15, 1.6163e-14, 3.1809e-16]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.74000000000001\n"
     ]
    }
   ],
   "source": [
    "correct_prob_22 = 0\n",
    "total_prob_22 = 0\n",
    "post_prob_22 = []\n",
    "pred_prob_22 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_22 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net22.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_22, labels_prob_22 = data\n",
    "            outputs_prob_22 = best_net22(images_prob_22)\n",
    "\n",
    "            sm22 = torch.nn.Softmax()\n",
    "            probabilities_prob_22 = sm22(outputs_prob_22)\n",
    "            post_prob_22.append(probabilities_prob_22)\n",
    "            _, predicted_prob_22 = torch.max(outputs_prob_22.data, 1)\n",
    "            pred_prob_22.append(predicted_prob_22.item())\n",
    "            \n",
    "\n",
    "            total_prob_22 += labels_prob_22.size(0)\n",
    "            correct_prob_22 += (predicted_prob_22 == labels_prob_22).sum().item()\n",
    "        accuracy22 = 100 * (correct_prob_22 / total_prob_22)\n",
    "        post_probs_22.append(post_prob_22)\n",
    "\n",
    "print('Probabilities', probabilities_prob_22)\n",
    "print('length of Probabilities', len(post_prob_22))\n",
    "print('Total Images: ', total_prob_22)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "id": "EwO8SuDSb8yB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-363-ed50086adaa7>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_23 = sm23(outputs_prob_23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.8599e-22, 2.8711e-12, 1.0000e+00, 8.7010e-16, 7.2383e-19, 2.5581e-26,\n",
      "         4.2076e-21, 8.7335e-16, 6.4004e-17, 9.6554e-20]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.16\n"
     ]
    }
   ],
   "source": [
    "correct_prob_23 = 0\n",
    "total_prob_23 = 0\n",
    "post_prob_23 = []\n",
    "pred_prob_23 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_23 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net23.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_23, labels_prob_23 = data\n",
    "            outputs_prob_23 = best_net23(images_prob_23)\n",
    "\n",
    "            sm23 = torch.nn.Softmax()\n",
    "            probabilities_prob_23 = sm23(outputs_prob_23)\n",
    "            post_prob_23.append(probabilities_prob_23)\n",
    "            _, predicted_prob_23 = torch.max(outputs_prob_23.data, 1)\n",
    "            pred_prob_23.append(predicted_prob_23.item())\n",
    "            \n",
    "\n",
    "            total_prob_23 += labels_prob_23.size(0)\n",
    "            correct_prob_23 += (predicted_prob_23 == labels_prob_23).sum().item()\n",
    "        accuracy23 = 100 * (correct_prob_23 / total_prob_23)\n",
    "        post_probs_23.append(post_prob_23)\n",
    "\n",
    "print('Probabilities', probabilities_prob_23)\n",
    "print('length of Probabilities', len(post_prob_23))\n",
    "print('Total Images: ', total_prob_23)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "id": "dmU5Yfv_cmeE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-364-e599f21bb813>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_24 = sm24(outputs_prob_24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[4.7708e-11, 1.5337e-08, 9.9999e-01, 4.7305e-09, 8.0717e-07, 3.4623e-11,\n",
      "         9.4712e-08, 3.3499e-10, 8.6519e-06, 3.2227e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.76\n"
     ]
    }
   ],
   "source": [
    "correct_prob_24 = 0\n",
    "total_prob_24 = 0\n",
    "post_prob_24 = []\n",
    "pred_prob_24 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_24 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net24.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_24, labels_prob_24 = data\n",
    "            outputs_prob_24 = best_net24(images_prob_24)\n",
    "\n",
    "            sm24 = torch.nn.Softmax()\n",
    "            probabilities_prob_24 = sm24(outputs_prob_24)\n",
    "            post_prob_24.append(probabilities_prob_24)\n",
    "            _, predicted_prob_24 = torch.max(outputs_prob_24.data, 1)\n",
    "            pred_prob_24.append(predicted_prob_24.item())\n",
    "            \n",
    "\n",
    "            total_prob_24 += labels_prob_24.size(0)\n",
    "            correct_prob_24 += (predicted_prob_24 == labels_prob_24).sum().item()\n",
    "        accuracy24 = 100 * (correct_prob_24 / total_prob_24)\n",
    "        post_probs_24.append(post_prob_24)\n",
    "\n",
    "print('Probabilities', probabilities_prob_24)\n",
    "print('length of Probabilities', len(post_prob_24))\n",
    "print('Total Images: ', total_prob_24)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "id": "LswPJVjmdxny"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-365-b51d9e5a04d2>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_25 = sm25(outputs_prob_25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.6005e-14, 3.1538e-11, 1.0000e+00, 3.1036e-09, 9.1189e-07, 1.6470e-11,\n",
      "         2.2354e-14, 9.9897e-11, 1.0161e-07, 6.1207e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.74000000000001\n"
     ]
    }
   ],
   "source": [
    "correct_prob_25 = 0\n",
    "total_prob_25 = 0\n",
    "post_prob_25 = []\n",
    "pred_prob_25 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_25 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net25.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_25, labels_prob_25 = data\n",
    "            outputs_prob_25 = best_net25(images_prob_25)\n",
    "\n",
    "            sm25 = torch.nn.Softmax()\n",
    "            probabilities_prob_25 = sm25(outputs_prob_25)\n",
    "            post_prob_25.append(probabilities_prob_25)\n",
    "            _, predicted_prob_25 = torch.max(outputs_prob_25.data, 1)\n",
    "            pred_prob_25.append(predicted_prob_25.item())\n",
    "            \n",
    "\n",
    "            total_prob_25 += labels_prob_25.size(0)\n",
    "            correct_prob_25 += (predicted_prob_25 == labels_prob_25).sum().item()\n",
    "        accuracy25 = 100 * (correct_prob_25 / total_prob_25)\n",
    "        post_probs_25.append(post_prob_25)\n",
    "\n",
    "print('Probabilities', probabilities_prob_25)\n",
    "print('length of Probabilities', len(post_prob_25))\n",
    "print('Total Images: ', total_prob_25)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "id": "HhTW2x6oeVuh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-366-200237ca2744>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_26 = sm26(outputs_prob_26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.8478e-21, 1.9414e-17, 1.0000e+00, 2.8512e-15, 3.4481e-18, 3.8171e-24,\n",
      "         3.3993e-25, 1.4348e-16, 5.7867e-16, 1.2491e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.06\n"
     ]
    }
   ],
   "source": [
    "correct_prob_26 = 0\n",
    "total_prob_26 = 0\n",
    "post_prob_26 = []\n",
    "pred_prob_26 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_26 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net26.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_26, labels_prob_26 = data\n",
    "            outputs_prob_26 = best_net26(images_prob_26)\n",
    "\n",
    "            sm26 = torch.nn.Softmax()\n",
    "            probabilities_prob_26 = sm26(outputs_prob_26)\n",
    "            post_prob_26.append(probabilities_prob_26)\n",
    "            _, predicted_prob_26 = torch.max(outputs_prob_26.data, 1)\n",
    "            pred_prob_26.append(predicted_prob_26.item())\n",
    "            \n",
    "\n",
    "            total_prob_26 += labels_prob_26.size(0)\n",
    "            correct_prob_26 += (predicted_prob_26 == labels_prob_26).sum().item()\n",
    "        accuracy26 = 100 * (correct_prob_26 / total_prob_26)\n",
    "        post_probs_26.append(post_prob_26)\n",
    "\n",
    "print('Probabilities', probabilities_prob_26)\n",
    "print('length of Probabilities', len(post_prob_26))\n",
    "print('Total Images: ', total_prob_26)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "id": "AYKOVdume-xd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-367-025818133cad>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_27 = sm27(outputs_prob_27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.6659e-16, 3.0247e-11, 1.0000e+00, 4.3776e-09, 1.0847e-14, 7.0275e-18,\n",
      "         9.1036e-21, 3.0265e-12, 4.2374e-12, 3.3110e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.06\n"
     ]
    }
   ],
   "source": [
    "correct_prob_27 = 0\n",
    "total_prob_27 = 0\n",
    "post_prob_27 = []\n",
    "pred_prob_27 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_27 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net27.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_27, labels_prob_27 = data\n",
    "            outputs_prob_27 = best_net27(images_prob_27)\n",
    "\n",
    "            sm27 = torch.nn.Softmax()\n",
    "            probabilities_prob_27 = sm27(outputs_prob_27)\n",
    "            post_prob_27.append(probabilities_prob_27)\n",
    "            _, predicted_prob_27 = torch.max(outputs_prob_27.data, 1)\n",
    "            pred_prob_27.append(predicted_prob_27.item())\n",
    "            \n",
    "\n",
    "            total_prob_27 += labels_prob_27.size(0)\n",
    "            correct_prob_27 += (predicted_prob_27 == labels_prob_27).sum().item()\n",
    "        accuracy27 = 100 * (correct_prob_27 / total_prob_27)\n",
    "        post_probs_27.append(post_prob_27)\n",
    "\n",
    "print('Probabilities', probabilities_prob_27)\n",
    "print('length of Probabilities', len(post_prob_27))\n",
    "print('Total Images: ', total_prob_27)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "id": "-h62DO4YfkkH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-368-0682f19b7d81>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_28 = sm28(outputs_prob_28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[7.5865e-13, 1.6079e-14, 1.0000e+00, 2.4567e-09, 1.5311e-19, 5.0512e-17,\n",
      "         1.7340e-19, 4.6304e-16, 1.8524e-06, 2.7457e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.89999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_28 = 0\n",
    "total_prob_28 = 0\n",
    "post_prob_28 = []\n",
    "pred_prob_28 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_28 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net28.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_28, labels_prob_28 = data\n",
    "            outputs_prob_28 = best_net28(images_prob_28)\n",
    "\n",
    "            sm28 = torch.nn.Softmax()\n",
    "            probabilities_prob_28 = sm28(outputs_prob_28)\n",
    "            post_prob_28.append(probabilities_prob_28)\n",
    "            _, predicted_prob_28 = torch.max(outputs_prob_28.data, 1)\n",
    "            pred_prob_28.append(predicted_prob_28.item())\n",
    "            \n",
    "\n",
    "            total_prob_28 += labels_prob_28.size(0)\n",
    "            correct_prob_28 += (predicted_prob_28 == labels_prob_28).sum().item()\n",
    "        accuracy28 = 100 * (correct_prob_28 / total_prob_28)\n",
    "        post_probs_28.append(post_prob_28)\n",
    "\n",
    "print('Probabilities', probabilities_prob_28)\n",
    "print('length of Probabilities', len(post_prob_28))\n",
    "print('Total Images: ', total_prob_28)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "id": "XzZerU4lgHQX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-369-4b49bd9543a9>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_29 = sm29(outputs_prob_29)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.3853e-17, 7.6512e-13, 1.0000e+00, 7.6642e-12, 6.7955e-19, 1.1138e-17,\n",
      "         7.9859e-18, 1.2773e-14, 2.5460e-11, 1.0843e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.78\n"
     ]
    }
   ],
   "source": [
    "correct_prob_29 = 0\n",
    "total_prob_29 = 0\n",
    "post_prob_29 = []\n",
    "pred_prob_29 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_29 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net29.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_29, labels_prob_29 = data\n",
    "            outputs_prob_29 = best_net29(images_prob_29)\n",
    "\n",
    "            sm29 = torch.nn.Softmax()\n",
    "            probabilities_prob_29 = sm29(outputs_prob_29)\n",
    "            post_prob_29.append(probabilities_prob_29)\n",
    "            _, predicted_prob_29 = torch.max(outputs_prob_29.data, 1)\n",
    "            pred_prob_29.append(predicted_prob_29.item())\n",
    "            \n",
    "\n",
    "            total_prob_29 += labels_prob_29.size(0)\n",
    "            correct_prob_29 += (predicted_prob_29 == labels_prob_29).sum().item()\n",
    "        accuracy29 = 100 * (correct_prob_29 / total_prob_29)\n",
    "        post_probs_29.append(post_prob_29)\n",
    "\n",
    "print('Probabilities', probabilities_prob_29)\n",
    "print('length of Probabilities', len(post_prob_29))\n",
    "print('Total Images: ', total_prob_29)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "id": "l7-1MNrkgpAY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-370-886dc61a5f5e>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_30 = sm30(outputs_prob_30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.1655e-12, 2.6433e-07, 9.9996e-01, 4.8744e-07, 2.7743e-10, 4.0330e-11,\n",
      "         8.6546e-13, 2.7770e-08, 4.3400e-05, 4.4452e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.61999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_30 = 0\n",
    "total_prob_30 = 0\n",
    "post_prob_30 = []\n",
    "pred_prob_30 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_30 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net30.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_30, labels_prob_30 = data\n",
    "            outputs_prob_30 = best_net30(images_prob_30)\n",
    "\n",
    "            sm30 = torch.nn.Softmax()\n",
    "            probabilities_prob_30 = sm30(outputs_prob_30)\n",
    "            post_prob_30.append(probabilities_prob_30)\n",
    "            _, predicted_prob_30 = torch.max(outputs_prob_30.data, 1)\n",
    "            pred_prob_30.append(predicted_prob_30.item())\n",
    "            \n",
    "\n",
    "            total_prob_30 += labels_prob_30.size(0)\n",
    "            correct_prob_30 += (predicted_prob_30 == labels_prob_30).sum().item()\n",
    "        accuracy30 = 100 * (correct_prob_30 / total_prob_30)\n",
    "        post_probs_30.append(post_prob_30)\n",
    "\n",
    "print('Probabilities', probabilities_prob_30)\n",
    "print('length of Probabilities', len(post_prob_30))\n",
    "print('Total Images: ', total_prob_30)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "id": "WqbkbSf3hX7S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-371-a14cdcf01ec1>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_31 = sm31(outputs_prob_31)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.0713e-14, 4.6506e-13, 9.9999e-01, 1.7298e-06, 1.3029e-16, 4.2960e-16,\n",
      "         1.3658e-18, 1.9615e-14, 7.0840e-06, 6.6661e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.98\n"
     ]
    }
   ],
   "source": [
    "correct_prob_31 = 0\n",
    "total_prob_31 = 0\n",
    "post_prob_31 = []\n",
    "pred_prob_31 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_31 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net31.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_31, labels_prob_31 = data\n",
    "            outputs_prob_31 = best_net31(images_prob_31)\n",
    "\n",
    "            sm31 = torch.nn.Softmax()\n",
    "            probabilities_prob_31 = sm31(outputs_prob_31)\n",
    "            post_prob_31.append(probabilities_prob_31)\n",
    "            _, predicted_prob_31 = torch.max(outputs_prob_31.data, 1)\n",
    "            pred_prob_31.append(predicted_prob_31.item())\n",
    "            \n",
    "\n",
    "            total_prob_31 += labels_prob_31.size(0)\n",
    "            correct_prob_31 += (predicted_prob_31 == labels_prob_31).sum().item()\n",
    "        accuracy31 = 100 * (correct_prob_31 / total_prob_31)\n",
    "        post_probs_31.append(post_prob_31)\n",
    "\n",
    "print('Probabilities', probabilities_prob_31)\n",
    "print('length of Probabilities', len(post_prob_31))\n",
    "print('Total Images: ', total_prob_31)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "id": "wHAWdlZdiKBw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-372-43d35372a00f>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_32 = sm32(outputs_prob_32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.4307e-14, 2.6617e-13, 1.0000e+00, 3.1608e-14, 6.3387e-13, 3.2357e-17,\n",
      "         3.8094e-22, 3.1472e-13, 1.0617e-08, 2.7524e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.7\n"
     ]
    }
   ],
   "source": [
    "correct_prob_32 = 0\n",
    "total_prob_32 = 0\n",
    "post_prob_32 = []\n",
    "pred_prob_32 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_32 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net32.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_32, labels_prob_32 = data\n",
    "            outputs_prob_32 = best_net32(images_prob_32)\n",
    "\n",
    "            sm32 = torch.nn.Softmax()\n",
    "            probabilities_prob_32 = sm32(outputs_prob_32)\n",
    "            post_prob_32.append(probabilities_prob_32)\n",
    "            _, predicted_prob_32 = torch.max(outputs_prob_32.data, 1)\n",
    "            pred_prob_32.append(predicted_prob_32.item())\n",
    "            \n",
    "\n",
    "            total_prob_32 += labels_prob_32.size(0)\n",
    "            correct_prob_32 += (predicted_prob_32 == labels_prob_32).sum().item()\n",
    "        accuracy32 = 100 * (correct_prob_32 / total_prob_32)\n",
    "        post_probs_32.append(post_prob_32)\n",
    "\n",
    "print('Probabilities', probabilities_prob_32)\n",
    "print('length of Probabilities', len(post_prob_32))\n",
    "print('Total Images: ', total_prob_32)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "id": "CAhi_PmxipWt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-373-bde18e70f03f>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_33 = sm33(outputs_prob_33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.5956e-14, 4.9581e-14, 1.0000e+00, 2.4224e-09, 7.6942e-17, 1.1595e-15,\n",
      "         8.8350e-17, 6.4556e-14, 2.9592e-09, 1.2775e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.61999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_33 = 0\n",
    "total_prob_33 = 0\n",
    "post_prob_33 = []\n",
    "pred_prob_33 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_33 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net33.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_33, labels_prob_33 = data\n",
    "            outputs_prob_33 = best_net33(images_prob_33)\n",
    "\n",
    "            sm33 = torch.nn.Softmax()\n",
    "            probabilities_prob_33 = sm33(outputs_prob_33)\n",
    "            post_prob_33.append(probabilities_prob_33)\n",
    "            _, predicted_prob_33 = torch.max(outputs_prob_33.data, 1)\n",
    "            pred_prob_33.append(predicted_prob_33.item())\n",
    "            \n",
    "\n",
    "            total_prob_33 += labels_prob_33.size(0)\n",
    "            correct_prob_33 += (predicted_prob_33 == labels_prob_33).sum().item()\n",
    "        accuracy33 = 100 * (correct_prob_33 / total_prob_33)\n",
    "        post_probs_33.append(post_prob_33)\n",
    "\n",
    "print('Probabilities', probabilities_prob_33)\n",
    "print('length of Probabilities', len(post_prob_33))\n",
    "print('Total Images: ', total_prob_33)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "id": "WO9nTY4GjG5K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-374-459915e8a9e9>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_34 = sm34(outputs_prob_34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.4871e-16, 2.0140e-11, 1.0000e+00, 1.5339e-10, 9.7223e-19, 5.6408e-18,\n",
      "         6.5484e-20, 1.4598e-13, 3.5169e-11, 3.9757e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.72\n"
     ]
    }
   ],
   "source": [
    "correct_prob_34 = 0\n",
    "total_prob_34 = 0\n",
    "post_prob_34 = []\n",
    "pred_prob_34 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_34 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net34.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_34, labels_prob_34 = data\n",
    "            outputs_prob_34 = best_net34(images_prob_34)\n",
    "\n",
    "            sm34 = torch.nn.Softmax()\n",
    "            probabilities_prob_34 = sm34(outputs_prob_34)\n",
    "            post_prob_34.append(probabilities_prob_34)\n",
    "            _, predicted_prob_34 = torch.max(outputs_prob_34.data, 1)\n",
    "            pred_prob_34.append(predicted_prob_34.item())\n",
    "            \n",
    "\n",
    "            total_prob_34 += labels_prob_34.size(0)\n",
    "            correct_prob_34 += (predicted_prob_34 == labels_prob_34).sum().item()\n",
    "        accuracy34 = 100 * (correct_prob_34 / total_prob_34)\n",
    "        post_probs_34.append(post_prob_34)\n",
    "\n",
    "print('Probabilities', probabilities_prob_34)\n",
    "print('length of Probabilities', len(post_prob_34))\n",
    "print('Total Images: ', total_prob_34)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "id": "LoJGpSidkPDr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-375-69155f501d82>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_35 = sm35(outputs_prob_35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.5942e-16, 2.0041e-11, 1.0000e+00, 5.0699e-10, 1.0833e-15, 1.0792e-14,\n",
      "         1.6089e-17, 3.6556e-11, 2.5074e-10, 4.9229e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.42\n"
     ]
    }
   ],
   "source": [
    "correct_prob_35 = 0\n",
    "total_prob_35 = 0\n",
    "post_prob_35 = []\n",
    "pred_prob_35 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_35 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net35.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_35, labels_prob_35 = data\n",
    "            outputs_prob_35 = best_net35(images_prob_35)\n",
    "\n",
    "            sm35 = torch.nn.Softmax()\n",
    "            probabilities_prob_35 = sm35(outputs_prob_35)\n",
    "            post_prob_35.append(probabilities_prob_35)\n",
    "            _, predicted_prob_35 = torch.max(outputs_prob_35.data, 1)\n",
    "            pred_prob_35.append(predicted_prob_35.item())\n",
    "            \n",
    "\n",
    "            total_prob_35 += labels_prob_35.size(0)\n",
    "            correct_prob_35 += (predicted_prob_35 == labels_prob_35).sum().item()\n",
    "        accuracy35 = 100 * (correct_prob_35 / total_prob_35)\n",
    "        post_probs_35.append(post_prob_35)\n",
    "\n",
    "print('Probabilities', probabilities_prob_35)\n",
    "print('length of Probabilities', len(post_prob_35))\n",
    "print('Total Images: ', total_prob_35)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "id": "40mK9FJ9kw84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-376-c551ca48b0bb>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_36 = sm36(outputs_prob_36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[4.9638e-18, 1.3328e-13, 1.0000e+00, 7.4602e-12, 8.3873e-21, 1.8422e-21,\n",
      "         3.2600e-19, 3.9241e-12, 1.2621e-13, 7.9732e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.8\n"
     ]
    }
   ],
   "source": [
    "correct_prob_36 = 0\n",
    "total_prob_36 = 0\n",
    "post_prob_36 = []\n",
    "pred_prob_36 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_36 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net36.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_36, labels_prob_36 = data\n",
    "            outputs_prob_36 = best_net36(images_prob_36)\n",
    "\n",
    "            sm36 = torch.nn.Softmax()\n",
    "            probabilities_prob_36 = sm36(outputs_prob_36)\n",
    "            post_prob_36.append(probabilities_prob_36)\n",
    "            _, predicted_prob_36 = torch.max(outputs_prob_36.data, 1)\n",
    "            pred_prob_36.append(predicted_prob_36.item())\n",
    "            \n",
    "\n",
    "            total_prob_36 += labels_prob_36.size(0)\n",
    "            correct_prob_36 += (predicted_prob_36 == labels_prob_36).sum().item()\n",
    "        accuracy36 = 100 * (correct_prob_36 / total_prob_36)\n",
    "        post_probs_36.append(post_prob_36)\n",
    "\n",
    "print('Probabilities', probabilities_prob_36)\n",
    "print('length of Probabilities', len(post_prob_36))\n",
    "print('Total Images: ', total_prob_36)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "id": "VcQ3f4sKlRhb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-377-299d50e666d5>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_37 = sm37(outputs_prob_37)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[9.4843e-12, 2.1005e-08, 9.9966e-01, 3.3664e-04, 6.4850e-16, 5.9663e-12,\n",
      "         1.2204e-11, 2.3490e-08, 3.1059e-07, 6.4094e-11]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.78\n"
     ]
    }
   ],
   "source": [
    "correct_prob_37 = 0\n",
    "total_prob_37 = 0\n",
    "post_prob_37 = []\n",
    "pred_prob_37 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_37 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net37.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_37, labels_prob_37 = data\n",
    "            outputs_prob_37 = best_net37(images_prob_37)\n",
    "\n",
    "            sm37 = torch.nn.Softmax()\n",
    "            probabilities_prob_37 = sm37(outputs_prob_37)\n",
    "            post_prob_37.append(probabilities_prob_37)\n",
    "            _, predicted_prob_37 = torch.max(outputs_prob_37.data, 1)\n",
    "            pred_prob_37.append(predicted_prob_37.item())\n",
    "            \n",
    "\n",
    "            total_prob_37 += labels_prob_37.size(0)\n",
    "            correct_prob_37 += (predicted_prob_37 == labels_prob_37).sum().item()\n",
    "        accuracy37 = 100 * (correct_prob_37 / total_prob_37)\n",
    "        post_probs_37.append(post_prob_37)\n",
    "\n",
    "print('Probabilities', probabilities_prob_37)\n",
    "print('length of Probabilities', len(post_prob_37))\n",
    "print('Total Images: ', total_prob_37)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "id": "RfSXkbmzlv7x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-378-c035819d6cd2>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_38 = sm38(outputs_prob_38)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.1796e-15, 3.2764e-11, 9.9999e-01, 1.7076e-06, 6.1283e-10, 3.1883e-14,\n",
      "         5.2356e-13, 9.3557e-06, 2.5758e-09, 3.7690e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.84\n"
     ]
    }
   ],
   "source": [
    "correct_prob_38 = 0\n",
    "total_prob_38 = 0\n",
    "post_prob_38 = []\n",
    "pred_prob_38 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_38 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net38.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_38, labels_prob_38 = data\n",
    "            outputs_prob_38 = best_net38(images_prob_38)\n",
    "\n",
    "            sm38 = torch.nn.Softmax()\n",
    "            probabilities_prob_38 = sm38(outputs_prob_38)\n",
    "            post_prob_38.append(probabilities_prob_38)\n",
    "            _, predicted_prob_38 = torch.max(outputs_prob_38.data, 1)\n",
    "            pred_prob_38.append(predicted_prob_38.item())\n",
    "            \n",
    "\n",
    "            total_prob_38 += labels_prob_38.size(0)\n",
    "            correct_prob_38 += (predicted_prob_38 == labels_prob_38).sum().item()\n",
    "        accuracy38 = 100 * (correct_prob_38 / total_prob_38)\n",
    "        post_probs_38.append(post_prob_38)\n",
    "\n",
    "print('Probabilities', probabilities_prob_38)\n",
    "print('length of Probabilities', len(post_prob_38))\n",
    "print('Total Images: ', total_prob_38)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "id": "moEknf5bmPSc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-379-6ff5ca9a19fc>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_39 = sm39(outputs_prob_39)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.2048e-12, 7.0435e-14, 1.0000e+00, 4.0575e-09, 3.8332e-14, 1.6536e-15,\n",
      "         5.2693e-18, 1.2695e-12, 9.7043e-13, 8.1609e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.42\n"
     ]
    }
   ],
   "source": [
    "correct_prob_39 = 0\n",
    "total_prob_39 = 0\n",
    "post_prob_39 = []\n",
    "pred_prob_39 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_39 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net39.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_39, labels_prob_39 = data\n",
    "            outputs_prob_39 = best_net39(images_prob_39)\n",
    "\n",
    "            sm39 = torch.nn.Softmax()\n",
    "            probabilities_prob_39 = sm39(outputs_prob_39)\n",
    "            post_prob_39.append(probabilities_prob_39)\n",
    "            _, predicted_prob_39 = torch.max(outputs_prob_39.data, 1)\n",
    "            pred_prob_39.append(predicted_prob_39.item())\n",
    "            \n",
    "\n",
    "            total_prob_39 += labels_prob_39.size(0)\n",
    "            correct_prob_39 += (predicted_prob_39 == labels_prob_39).sum().item()\n",
    "        accuracy39 = 100 * (correct_prob_39 / total_prob_39)\n",
    "        post_probs_39.append(post_prob_39)\n",
    "\n",
    "print('Probabilities', probabilities_prob_39)\n",
    "print('length of Probabilities', len(post_prob_39))\n",
    "print('Total Images: ', total_prob_39)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "id": "EIkk6OPBm1qV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-380-aa51d5b6bc1a>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_40 = sm40(outputs_prob_40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[0.0221, 0.0330, 0.7932, 0.0158, 0.0295, 0.0261, 0.0107, 0.0152, 0.0444,\n",
      "         0.0101]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 92.94\n"
     ]
    }
   ],
   "source": [
    "correct_prob_40 = 0\n",
    "total_prob_40 = 0\n",
    "post_prob_40 = []\n",
    "pred_prob_40 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_40 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net40.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_40, labels_prob_40 = data\n",
    "            outputs_prob_40 = best_net40(images_prob_40)\n",
    "\n",
    "            sm40 = torch.nn.Softmax()\n",
    "            probabilities_prob_40 = sm40(outputs_prob_40)\n",
    "            post_prob_40.append(probabilities_prob_40)\n",
    "            _, predicted_prob_40 = torch.max(outputs_prob_40.data, 1)\n",
    "            pred_prob_40.append(predicted_prob_40.item())\n",
    "            \n",
    "\n",
    "            total_prob_40 += labels_prob_40.size(0)\n",
    "            correct_prob_40 += (predicted_prob_40 == labels_prob_40).sum().item()\n",
    "        accuracy40 = 100 * (correct_prob_40 / total_prob_40)\n",
    "        post_probs_40.append(post_prob_40)\n",
    "\n",
    "print('Probabilities', probabilities_prob_40)\n",
    "print('length of Probabilities', len(post_prob_40))\n",
    "print('Total Images: ', total_prob_40)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "id": "ldqfkN15nVCw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-381-889231c19b9e>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_41 = sm41(outputs_prob_41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.0232e-16, 2.6210e-16, 1.0000e+00, 2.7682e-14, 1.0031e-16, 2.4900e-20,\n",
      "         1.0402e-14, 9.6884e-17, 2.2669e-16, 1.9342e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.0\n"
     ]
    }
   ],
   "source": [
    "correct_prob_41 = 0\n",
    "total_prob_41 = 0\n",
    "post_prob_41 = []\n",
    "pred_prob_41 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_41 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net41.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_41, labels_prob_41 = data\n",
    "            outputs_prob_41 = best_net41(images_prob_41)\n",
    "\n",
    "            sm41 = torch.nn.Softmax()\n",
    "            probabilities_prob_41 = sm41(outputs_prob_41)\n",
    "            post_prob_41.append(probabilities_prob_41)\n",
    "            _, predicted_prob_41 = torch.max(outputs_prob_41.data, 1)\n",
    "            pred_prob_41.append(predicted_prob_41.item())\n",
    "            \n",
    "\n",
    "            total_prob_41 += labels_prob_41.size(0)\n",
    "            correct_prob_41 += (predicted_prob_41 == labels_prob_41).sum().item()\n",
    "        accuracy41 = 100 * (correct_prob_41 / total_prob_41)\n",
    "        post_probs_41.append(post_prob_41)\n",
    "\n",
    "print('Probabilities', probabilities_prob_41)\n",
    "print('length of Probabilities', len(post_prob_41))\n",
    "print('Total Images: ', total_prob_41)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "id": "eqhSL_Lxn18Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-382-9e5209d6ff9e>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_42 = sm42(outputs_prob_42)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.8142e-15, 5.7553e-11, 1.0000e+00, 2.6382e-15, 5.7147e-11, 1.2518e-17,\n",
      "         1.0034e-16, 4.9228e-09, 6.9565e-08, 5.3313e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.32\n"
     ]
    }
   ],
   "source": [
    "correct_prob_42 = 0\n",
    "total_prob_42 = 0\n",
    "post_prob_42 = []\n",
    "pred_prob_42 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_42 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net42.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_42, labels_prob_42 = data\n",
    "            outputs_prob_42 = best_net42(images_prob_42)\n",
    "\n",
    "            sm42 = torch.nn.Softmax()\n",
    "            probabilities_prob_42 = sm42(outputs_prob_42)\n",
    "            post_prob_42.append(probabilities_prob_42)\n",
    "            _, predicted_prob_42 = torch.max(outputs_prob_42.data, 1)\n",
    "            pred_prob_42.append(predicted_prob_42.item())\n",
    "            \n",
    "\n",
    "            total_prob_42 += labels_prob_42.size(0)\n",
    "            correct_prob_42 += (predicted_prob_42 == labels_prob_42).sum().item()\n",
    "        accuracy42 = 100 * (correct_prob_42 / total_prob_42)\n",
    "        post_probs_42.append(post_prob_42)\n",
    "\n",
    "print('Probabilities', probabilities_prob_42)\n",
    "print('length of Probabilities', len(post_prob_42))\n",
    "print('Total Images: ', total_prob_42)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "id": "VkBhlxoBoTqR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-383-be8cee719354>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_43 = sm43(outputs_prob_43)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.1262e-18, 7.9798e-12, 1.0000e+00, 4.3574e-10, 8.6938e-12, 3.1149e-15,\n",
      "         1.6039e-16, 1.0723e-17, 2.9077e-12, 7.3584e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.74000000000001\n"
     ]
    }
   ],
   "source": [
    "correct_prob_43 = 0\n",
    "total_prob_43 = 0\n",
    "post_prob_43 = []\n",
    "pred_prob_43 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_43 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net43.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_43, labels_prob_43 = data\n",
    "            outputs_prob_43 = best_net43(images_prob_43)\n",
    "\n",
    "            sm43 = torch.nn.Softmax()\n",
    "            probabilities_prob_43 = sm43(outputs_prob_43)\n",
    "            post_prob_43.append(probabilities_prob_43)\n",
    "            _, predicted_prob_43 = torch.max(outputs_prob_43.data, 1)\n",
    "            pred_prob_43.append(predicted_prob_43.item())\n",
    "            \n",
    "\n",
    "            total_prob_43 += labels_prob_43.size(0)\n",
    "            correct_prob_43 += (predicted_prob_43 == labels_prob_43).sum().item()\n",
    "        accuracy43 = 100 * (correct_prob_43 / total_prob_43)\n",
    "        post_probs_43.append(post_prob_43)\n",
    "\n",
    "print('Probabilities', probabilities_prob_43)\n",
    "print('length of Probabilities', len(post_prob_43))\n",
    "print('Total Images: ', total_prob_43)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "id": "4ln0pxWhoy42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-384-bb217957b54f>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_44 = sm44(outputs_prob_44)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[9.7412e-15, 9.7159e-11, 1.0000e+00, 1.2901e-16, 1.9976e-13, 6.7578e-18,\n",
      "         8.4529e-16, 8.1422e-12, 9.5179e-14, 4.5911e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.6\n"
     ]
    }
   ],
   "source": [
    "correct_prob_44 = 0\n",
    "total_prob_44 = 0\n",
    "post_prob_44 = []\n",
    "pred_prob_44 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_44 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net44.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_44, labels_prob_44 = data\n",
    "            outputs_prob_44 = best_net44(images_prob_44)\n",
    "\n",
    "            sm44 = torch.nn.Softmax()\n",
    "            probabilities_prob_44 = sm44(outputs_prob_44)\n",
    "            post_prob_44.append(probabilities_prob_44)\n",
    "            _, predicted_prob_44 = torch.max(outputs_prob_44.data, 1)\n",
    "            pred_prob_44.append(predicted_prob_44.item())\n",
    "            \n",
    "\n",
    "            total_prob_44 += labels_prob_44.size(0)\n",
    "            correct_prob_44 += (predicted_prob_44 == labels_prob_44).sum().item()\n",
    "        accuracy44 = 100 * (correct_prob_44 / total_prob_44)\n",
    "        post_probs_44.append(post_prob_44)\n",
    "\n",
    "print('Probabilities', probabilities_prob_44)\n",
    "print('length of Probabilities', len(post_prob_44))\n",
    "print('Total Images: ', total_prob_44)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "id": "Fu0ihi64pQ7U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-385-5cbc85cfed49>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_45 = sm45(outputs_prob_45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.5319e-13, 9.7226e-13, 1.0000e+00, 2.6667e-10, 2.4289e-15, 1.1511e-12,\n",
      "         3.7905e-13, 5.7143e-16, 1.1650e-10, 5.6598e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.8\n"
     ]
    }
   ],
   "source": [
    "correct_prob_45 = 0\n",
    "total_prob_45 = 0\n",
    "post_prob_45 = []\n",
    "pred_prob_45 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_45 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net45.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_45, labels_prob_45 = data\n",
    "            outputs_prob_45 = best_net45(images_prob_45)\n",
    "\n",
    "            sm45 = torch.nn.Softmax()\n",
    "            probabilities_prob_45 = sm45(outputs_prob_45)\n",
    "            post_prob_45.append(probabilities_prob_45)\n",
    "            _, predicted_prob_45 = torch.max(outputs_prob_45.data, 1)\n",
    "            pred_prob_45.append(predicted_prob_45.item())\n",
    "            \n",
    "\n",
    "            total_prob_45 += labels_prob_45.size(0)\n",
    "            correct_prob_45 += (predicted_prob_45 == labels_prob_45).sum().item()\n",
    "        accuracy45 = 100 * (correct_prob_45 / total_prob_45)\n",
    "        post_probs_45.append(post_prob_45)\n",
    "\n",
    "print('Probabilities', probabilities_prob_45)\n",
    "print('length of Probabilities', len(post_prob_45))\n",
    "print('Total Images: ', total_prob_45)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "id": "5Nf1b5iCpv81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-386-82a930e1477e>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_46 = sm46(outputs_prob_46)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.8585e-10, 2.3561e-08, 9.9999e-01, 1.0410e-05, 7.0023e-12, 3.5110e-14,\n",
      "         5.1805e-12, 2.3943e-09, 8.5740e-07, 3.1254e-09]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.39999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_46 = 0\n",
    "total_prob_46 = 0\n",
    "post_prob_46 = []\n",
    "pred_prob_46 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_46 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net46.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_46, labels_prob_46 = data\n",
    "            outputs_prob_46 = best_net46(images_prob_46)\n",
    "\n",
    "            sm46 = torch.nn.Softmax()\n",
    "            probabilities_prob_46 = sm46(outputs_prob_46)\n",
    "            post_prob_46.append(probabilities_prob_46)\n",
    "            _, predicted_prob_46 = torch.max(outputs_prob_46.data, 1)\n",
    "            pred_prob_46.append(predicted_prob_46.item())\n",
    "            \n",
    "\n",
    "            total_prob_46 += labels_prob_46.size(0)\n",
    "            correct_prob_46 += (predicted_prob_46 == labels_prob_46).sum().item()\n",
    "        accuracy46 = 100 * (correct_prob_46 / total_prob_46)\n",
    "        post_probs_46.append(post_prob_46)\n",
    "\n",
    "print('Probabilities', probabilities_prob_46)\n",
    "print('length of Probabilities', len(post_prob_46))\n",
    "print('Total Images: ', total_prob_46)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "id": "H9Pp11wXqM8Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-387-1c017c985502>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_47 = sm47(outputs_prob_47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.6593e-10, 1.1922e-08, 1.0000e+00, 2.8511e-07, 1.1651e-08, 4.8489e-11,\n",
      "         5.1959e-12, 3.2894e-13, 1.2633e-09, 1.0382e-06]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.56\n"
     ]
    }
   ],
   "source": [
    "correct_prob_47 = 0\n",
    "total_prob_47 = 0\n",
    "post_prob_47 = []\n",
    "pred_prob_47 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_47 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net47.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_47, labels_prob_47 = data\n",
    "            outputs_prob_47 = best_net47(images_prob_47)\n",
    "\n",
    "            sm47 = torch.nn.Softmax()\n",
    "            probabilities_prob_47 = sm47(outputs_prob_47)\n",
    "            post_prob_47.append(probabilities_prob_47)\n",
    "            _, predicted_prob_47 = torch.max(outputs_prob_47.data, 1)\n",
    "            pred_prob_47.append(predicted_prob_47.item())\n",
    "            \n",
    "\n",
    "            total_prob_47 += labels_prob_47.size(0)\n",
    "            correct_prob_47 += (predicted_prob_47 == labels_prob_47).sum().item()\n",
    "        accuracy47 = 100 * (correct_prob_47 / total_prob_47)\n",
    "        post_probs_47.append(post_prob_47)\n",
    "\n",
    "print('Probabilities', probabilities_prob_47)\n",
    "print('length of Probabilities', len(post_prob_47))\n",
    "print('Total Images: ', total_prob_47)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "id": "bqlIIlFUqvzz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-388-6846e3294f7c>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_48 = sm48(outputs_prob_48)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.8525e-10, 2.1363e-07, 1.0000e+00, 1.4206e-09, 2.1319e-11, 3.6727e-10,\n",
      "         9.8514e-13, 4.5621e-10, 1.6313e-07, 5.0941e-07]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 96.98\n"
     ]
    }
   ],
   "source": [
    "correct_prob_48 = 0\n",
    "total_prob_48 = 0\n",
    "post_prob_48 = []\n",
    "pred_prob_48 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_48 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net48.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_48, labels_prob_48 = data\n",
    "            outputs_prob_48 = best_net48(images_prob_48)\n",
    "\n",
    "            sm48 = torch.nn.Softmax()\n",
    "            probabilities_prob_48 = sm48(outputs_prob_48)\n",
    "            post_prob_48.append(probabilities_prob_48)\n",
    "            _, predicted_prob_48 = torch.max(outputs_prob_48.data, 1)\n",
    "            pred_prob_48.append(predicted_prob_48.item())\n",
    "            \n",
    "\n",
    "            total_prob_48 += labels_prob_48.size(0)\n",
    "            correct_prob_48 += (predicted_prob_48 == labels_prob_48).sum().item()\n",
    "        accuracy48 = 100 * (correct_prob_48 / total_prob_48)\n",
    "        post_probs_48.append(post_prob_48)\n",
    "\n",
    "print('Probabilities', probabilities_prob_48)\n",
    "print('length of Probabilities', len(post_prob_48))\n",
    "print('Total Images: ', total_prob_48)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "id": "X71P_jcrrWYv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-389-0f2e839426bf>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_49 = sm49(outputs_prob_49)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.5215e-07, 9.9948e-13, 1.0000e+00, 1.7271e-07, 3.3852e-11, 2.8218e-10,\n",
      "         3.2039e-09, 7.1260e-09, 3.8280e-06, 2.4956e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.48\n"
     ]
    }
   ],
   "source": [
    "correct_prob_49 = 0\n",
    "total_prob_49 = 0\n",
    "post_prob_49 = []\n",
    "pred_prob_49 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_49 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net49.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_49, labels_prob_49 = data\n",
    "            outputs_prob_49 = best_net49(images_prob_49)\n",
    "\n",
    "            sm49 = torch.nn.Softmax()\n",
    "            probabilities_prob_49 = sm49(outputs_prob_49)\n",
    "            post_prob_49.append(probabilities_prob_49)\n",
    "            _, predicted_prob_49 = torch.max(outputs_prob_49.data, 1)\n",
    "            pred_prob_49.append(predicted_prob_49.item())\n",
    "            \n",
    "\n",
    "            total_prob_49 += labels_prob_49.size(0)\n",
    "            correct_prob_49 += (predicted_prob_49 == labels_prob_49).sum().item()\n",
    "        accuracy49 = 100 * (correct_prob_49 / total_prob_49)\n",
    "        post_probs_49.append(post_prob_49)\n",
    "\n",
    "print('Probabilities', probabilities_prob_49)\n",
    "print('length of Probabilities', len(post_prob_49))\n",
    "print('Total Images: ', total_prob_49)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "id": "F25N8S4-r5qN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-390-14f8dd772b00>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_50 = sm50(outputs_prob_50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.4572e-19, 5.2582e-15, 1.0000e+00, 1.7989e-15, 1.6103e-18, 1.5224e-23,\n",
      "         4.0155e-19, 3.5262e-17, 1.2490e-11, 1.2483e-17]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.52\n"
     ]
    }
   ],
   "source": [
    "correct_prob_50 = 0\n",
    "total_prob_50 = 0\n",
    "post_prob_50 = []\n",
    "pred_prob_50 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_50 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net50.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_50, labels_prob_50 = data\n",
    "            outputs_prob_50 = best_net50(images_prob_50)\n",
    "\n",
    "            sm50 = torch.nn.Softmax()\n",
    "            probabilities_prob_50 = sm50(outputs_prob_50)\n",
    "            post_prob_50.append(probabilities_prob_50)\n",
    "            _, predicted_prob_50 = torch.max(outputs_prob_50.data, 1)\n",
    "            pred_prob_50.append(predicted_prob_50.item())\n",
    "            \n",
    "\n",
    "            total_prob_50 += labels_prob_50.size(0)\n",
    "            correct_prob_50 += (predicted_prob_50 == labels_prob_50).sum().item()\n",
    "        accuracy50 = 100 * (correct_prob_50 / total_prob_50)\n",
    "        post_probs_50.append(post_prob_50)\n",
    "\n",
    "print('Probabilities', probabilities_prob_50)\n",
    "print('length of Probabilities', len(post_prob_50))\n",
    "print('Total Images: ', total_prob_50)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "id": "fIoMXVvsO3Lh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-391-736e2d78f368>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_51 = sm51(outputs_prob_51)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[7.2115e-12, 4.8785e-08, 1.0000e+00, 4.6923e-11, 5.5743e-14, 1.4980e-17,\n",
      "         3.8835e-16, 4.1483e-11, 3.7246e-08, 1.1718e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.76\n"
     ]
    }
   ],
   "source": [
    "correct_prob_51 = 0\n",
    "total_prob_51 = 0\n",
    "post_prob_51 = []\n",
    "pred_prob_51 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_51 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net51.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_51, labels_prob_51 = data\n",
    "            outputs_prob_51 = best_net51(images_prob_51)\n",
    "\n",
    "            sm51 = torch.nn.Softmax()\n",
    "            probabilities_prob_51 = sm51(outputs_prob_51)\n",
    "            post_prob_51.append(probabilities_prob_51)\n",
    "            _, predicted_prob_51 = torch.max(outputs_prob_51.data, 1)\n",
    "            pred_prob_51.append(predicted_prob_51.item())\n",
    "            \n",
    "\n",
    "            total_prob_51 += labels_prob_51.size(0)\n",
    "            correct_prob_51 += (predicted_prob_51 == labels_prob_51).sum().item()\n",
    "        accuracy51 = 100 * (correct_prob_51 / total_prob_51)\n",
    "        post_probs_51.append(post_prob_51)\n",
    "\n",
    "print('Probabilities', probabilities_prob_51)\n",
    "print('length of Probabilities', len(post_prob_51))\n",
    "print('Total Images: ', total_prob_51)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "id": "Sh7L9Gr3O3BH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-392-78decf6d161c>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_52 = sm52(outputs_prob_52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.5800e-19, 1.4993e-13, 1.0000e+00, 6.1538e-14, 1.7170e-19, 1.7198e-23,\n",
      "         1.7204e-18, 2.3040e-18, 1.2626e-11, 2.2865e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.94\n"
     ]
    }
   ],
   "source": [
    "correct_prob_52 = 0\n",
    "total_prob_52 = 0\n",
    "post_prob_52 = []\n",
    "pred_prob_52 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_52 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net52.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_52, labels_prob_52 = data\n",
    "            outputs_prob_52 = best_net52(images_prob_52)\n",
    "\n",
    "            sm52 = torch.nn.Softmax()\n",
    "            probabilities_prob_52 = sm52(outputs_prob_52)\n",
    "            post_prob_52.append(probabilities_prob_52)\n",
    "            _, predicted_prob_52 = torch.max(outputs_prob_52.data, 1)\n",
    "            pred_prob_52.append(predicted_prob_52.item())\n",
    "            \n",
    "\n",
    "            total_prob_52 += labels_prob_52.size(0)\n",
    "            correct_prob_52 += (predicted_prob_52 == labels_prob_52).sum().item()\n",
    "        accuracy52 = 100 * (correct_prob_52 / total_prob_52)\n",
    "        post_probs_52.append(post_prob_52)\n",
    "\n",
    "print('Probabilities', probabilities_prob_52)\n",
    "print('length of Probabilities', len(post_prob_52))\n",
    "print('Total Images: ', total_prob_52)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "id": "xJkauNuwO22L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-393-d764d78dfb0b>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_53 = sm53(outputs_prob_53)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.3748e-16, 5.7178e-12, 1.0000e+00, 4.4737e-10, 3.3959e-16, 1.5380e-17,\n",
      "         5.3475e-20, 6.2683e-16, 8.8946e-12, 6.9707e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.14\n"
     ]
    }
   ],
   "source": [
    "correct_prob_53 = 0\n",
    "total_prob_53 = 0\n",
    "post_prob_53 = []\n",
    "pred_prob_53 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_53 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net53.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_53, labels_prob_53 = data\n",
    "            outputs_prob_53 = best_net53(images_prob_53)\n",
    "\n",
    "            sm53 = torch.nn.Softmax()\n",
    "            probabilities_prob_53 = sm53(outputs_prob_53)\n",
    "            post_prob_53.append(probabilities_prob_53)\n",
    "            _, predicted_prob_53 = torch.max(outputs_prob_53.data, 1)\n",
    "            pred_prob_53.append(predicted_prob_53.item())\n",
    "            \n",
    "\n",
    "            total_prob_53 += labels_prob_53.size(0)\n",
    "            correct_prob_53 += (predicted_prob_53 == labels_prob_53).sum().item()\n",
    "        accuracy53 = 100 * (correct_prob_53 / total_prob_53)\n",
    "        post_probs_53.append(post_prob_53)\n",
    "\n",
    "print('Probabilities', probabilities_prob_53)\n",
    "print('length of Probabilities', len(post_prob_53))\n",
    "print('Total Images: ', total_prob_53)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "id": "9pJ5sxG2O2uQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-394-cf96ab8df16a>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_54 = sm54(outputs_prob_54)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.6339e-16, 3.9920e-11, 1.0000e+00, 1.9729e-13, 2.3188e-12, 4.8506e-16,\n",
      "         6.9681e-15, 2.7591e-13, 2.3146e-11, 6.3471e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.68\n"
     ]
    }
   ],
   "source": [
    "correct_prob_54 = 0\n",
    "total_prob_54 = 0\n",
    "post_prob_54 = []\n",
    "pred_prob_54 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_54 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net54.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_54, labels_prob_54 = data\n",
    "            outputs_prob_54 = best_net54(images_prob_54)\n",
    "\n",
    "            sm54 = torch.nn.Softmax()\n",
    "            probabilities_prob_54 = sm54(outputs_prob_54)\n",
    "            post_prob_54.append(probabilities_prob_54)\n",
    "            _, predicted_prob_54 = torch.max(outputs_prob_54.data, 1)\n",
    "            pred_prob_54.append(predicted_prob_54.item())\n",
    "            \n",
    "\n",
    "            total_prob_54 += labels_prob_54.size(0)\n",
    "            correct_prob_54 += (predicted_prob_54 == labels_prob_54).sum().item()\n",
    "        accuracy54 = 100 * (correct_prob_54 / total_prob_54)\n",
    "        post_probs_54.append(post_prob_54)\n",
    "\n",
    "print('Probabilities', probabilities_prob_54)\n",
    "print('length of Probabilities', len(post_prob_54))\n",
    "print('Total Images: ', total_prob_54)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "id": "06D5XrcXO2k0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-395-6118fabb6f5d>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_55 = sm55(outputs_prob_55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[9.2036e-14, 9.6937e-11, 1.0000e+00, 6.9167e-12, 7.3929e-11, 1.1345e-14,\n",
      "         3.0238e-15, 4.4364e-12, 3.3731e-11, 4.5179e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.58\n"
     ]
    }
   ],
   "source": [
    "correct_prob_55 = 0\n",
    "total_prob_55 = 0\n",
    "post_prob_55 = []\n",
    "pred_prob_55 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_55 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net55.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_55, labels_prob_55 = data\n",
    "            outputs_prob_55 = best_net55(images_prob_55)\n",
    "\n",
    "            sm55 = torch.nn.Softmax()\n",
    "            probabilities_prob_55 = sm55(outputs_prob_55)\n",
    "            post_prob_55.append(probabilities_prob_55)\n",
    "            _, predicted_prob_55 = torch.max(outputs_prob_55.data, 1)\n",
    "            pred_prob_55.append(predicted_prob_55.item())\n",
    "            \n",
    "\n",
    "            total_prob_55 += labels_prob_55.size(0)\n",
    "            correct_prob_55 += (predicted_prob_55 == labels_prob_55).sum().item()\n",
    "        accuracy55 = 100 * (correct_prob_55 / total_prob_55)\n",
    "        post_probs_55.append(post_prob_55)\n",
    "\n",
    "print('Probabilities', probabilities_prob_55)\n",
    "print('length of Probabilities', len(post_prob_55))\n",
    "print('Total Images: ', total_prob_55)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "id": "9pY5NL8eO2aY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-396-c1cf508a3e89>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_56 = sm56(outputs_prob_56)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.5193e-20, 8.5193e-14, 1.0000e+00, 7.8887e-16, 1.5852e-15, 2.7202e-17,\n",
      "         2.1968e-18, 1.6439e-14, 1.4322e-13, 9.7961e-18]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.7\n"
     ]
    }
   ],
   "source": [
    "correct_prob_56 = 0\n",
    "total_prob_56 = 0\n",
    "post_prob_56 = []\n",
    "pred_prob_56 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_56 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net56.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_56, labels_prob_56 = data\n",
    "            outputs_prob_56 = best_net56(images_prob_56)\n",
    "\n",
    "            sm56 = torch.nn.Softmax()\n",
    "            probabilities_prob_56 = sm56(outputs_prob_56)\n",
    "            post_prob_56.append(probabilities_prob_56)\n",
    "            _, predicted_prob_56 = torch.max(outputs_prob_56.data, 1)\n",
    "            pred_prob_56.append(predicted_prob_56.item())\n",
    "            \n",
    "\n",
    "            total_prob_56 += labels_prob_56.size(0)\n",
    "            correct_prob_56 += (predicted_prob_56 == labels_prob_56).sum().item()\n",
    "        accuracy56 = 100 * (correct_prob_56 / total_prob_56)\n",
    "        post_probs_56.append(post_prob_56)\n",
    "\n",
    "print('Probabilities', probabilities_prob_56)\n",
    "print('length of Probabilities', len(post_prob_56))\n",
    "print('Total Images: ', total_prob_56)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "id": "NBR02CfWO2Qt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-397-dd5e98d0e505>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_57 = sm57(outputs_prob_57)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.5533e-18, 6.9882e-13, 1.0000e+00, 5.3159e-12, 6.7172e-16, 1.1019e-15,\n",
      "         1.5169e-19, 7.6645e-15, 1.5599e-10, 1.2203e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.88\n"
     ]
    }
   ],
   "source": [
    "correct_prob_57 = 0\n",
    "total_prob_57 = 0\n",
    "post_prob_57 = []\n",
    "pred_prob_57 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_57 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net57.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_57, labels_prob_57 = data\n",
    "            outputs_prob_57 = best_net57(images_prob_57)\n",
    "\n",
    "            sm57 = torch.nn.Softmax()\n",
    "            probabilities_prob_57 = sm57(outputs_prob_57)\n",
    "            post_prob_57.append(probabilities_prob_57)\n",
    "            _, predicted_prob_57 = torch.max(outputs_prob_57.data, 1)\n",
    "            pred_prob_57.append(predicted_prob_57.item())\n",
    "            \n",
    "\n",
    "            total_prob_57 += labels_prob_57.size(0)\n",
    "            correct_prob_57 += (predicted_prob_57 == labels_prob_57).sum().item()\n",
    "        accuracy57 = 100 * (correct_prob_57 / total_prob_57)\n",
    "        post_probs_57.append(post_prob_57)\n",
    "\n",
    "print('Probabilities', probabilities_prob_57)\n",
    "print('length of Probabilities', len(post_prob_57))\n",
    "print('Total Images: ', total_prob_57)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "MlnMbs02O2EE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-398-dbdec3ba4b57>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_58 = sm58(outputs_prob_58)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[6.8420e-17, 3.8065e-14, 1.0000e+00, 4.0255e-11, 3.6180e-18, 8.3364e-18,\n",
      "         5.7057e-19, 2.0222e-16, 4.6043e-15, 1.2149e-18]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.76\n"
     ]
    }
   ],
   "source": [
    "correct_prob_58 = 0\n",
    "total_prob_58 = 0\n",
    "post_prob_58 = []\n",
    "pred_prob_58 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_58 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net58.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_58, labels_prob_58 = data\n",
    "            outputs_prob_58 = best_net58(images_prob_58)\n",
    "\n",
    "            sm58 = torch.nn.Softmax()\n",
    "            probabilities_prob_58 = sm58(outputs_prob_58)\n",
    "            post_prob_58.append(probabilities_prob_58)\n",
    "            _, predicted_prob_58 = torch.max(outputs_prob_58.data, 1)\n",
    "            pred_prob_58.append(predicted_prob_58.item())\n",
    "            \n",
    "\n",
    "            total_prob_58 += labels_prob_58.size(0)\n",
    "            correct_prob_58 += (predicted_prob_58 == labels_prob_58).sum().item()\n",
    "        accuracy58 = 100 * (correct_prob_58 / total_prob_58)\n",
    "        post_probs_58.append(post_prob_58)\n",
    "\n",
    "print('Probabilities', probabilities_prob_58)\n",
    "print('length of Probabilities', len(post_prob_58))\n",
    "print('Total Images: ', total_prob_58)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "id": "JQjGmGq8O159"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-399-4981c2e390eb>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_59 = sm59(outputs_prob_59)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.5250e-16, 5.0736e-14, 1.0000e+00, 8.8913e-15, 3.6888e-18, 4.6915e-19,\n",
      "         6.6628e-19, 2.2343e-18, 1.9719e-13, 4.8586e-18]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.7\n"
     ]
    }
   ],
   "source": [
    "correct_prob_59 = 0\n",
    "total_prob_59 = 0\n",
    "post_prob_59 = []\n",
    "pred_prob_59 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_59 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net59.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_59, labels_prob_59 = data\n",
    "            outputs_prob_59 = best_net59(images_prob_59)\n",
    "\n",
    "            sm59 = torch.nn.Softmax()\n",
    "            probabilities_prob_59 = sm59(outputs_prob_59)\n",
    "            post_prob_59.append(probabilities_prob_59)\n",
    "            _, predicted_prob_59 = torch.max(outputs_prob_59.data, 1)\n",
    "            pred_prob_59.append(predicted_prob_59.item())\n",
    "            \n",
    "\n",
    "            total_prob_59 += labels_prob_59.size(0)\n",
    "            correct_prob_59 += (predicted_prob_59 == labels_prob_59).sum().item()\n",
    "        accuracy59 = 100 * (correct_prob_59 / total_prob_59)\n",
    "        post_probs_59.append(post_prob_59)\n",
    "\n",
    "print('Probabilities', probabilities_prob_59)\n",
    "print('length of Probabilities', len(post_prob_59))\n",
    "print('Total Images: ', total_prob_59)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "id": "YmLzj2khO1tg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-400-0c2f94268559>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_60 = sm60(outputs_prob_60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.8820e-13, 2.2540e-07, 1.0000e+00, 2.1675e-09, 1.3539e-13, 4.8526e-12,\n",
      "         1.2702e-14, 1.3676e-08, 1.1739e-12, 3.9930e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.84\n"
     ]
    }
   ],
   "source": [
    "correct_prob_60 = 0\n",
    "total_prob_60 = 0\n",
    "post_prob_60 = []\n",
    "pred_prob_60 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_60 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net60.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_60, labels_prob_60 = data\n",
    "            outputs_prob_60 = best_net60(images_prob_60)\n",
    "\n",
    "            sm60 = torch.nn.Softmax()\n",
    "            probabilities_prob_60 = sm60(outputs_prob_60)\n",
    "            post_prob_60.append(probabilities_prob_60)\n",
    "            _, predicted_prob_60 = torch.max(outputs_prob_60.data, 1)\n",
    "            pred_prob_60.append(predicted_prob_60.item())\n",
    "            \n",
    "\n",
    "            total_prob_60 += labels_prob_60.size(0)\n",
    "            correct_prob_60 += (predicted_prob_60 == labels_prob_60).sum().item()\n",
    "        accuracy60 = 100 * (correct_prob_60 / total_prob_60)\n",
    "        post_probs_60.append(post_prob_60)\n",
    "\n",
    "print('Probabilities', probabilities_prob_60)\n",
    "print('length of Probabilities', len(post_prob_60))\n",
    "print('Total Images: ', total_prob_60)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "id": "so8KgGCDO1g0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-401-2c24d4b9a008>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_61 = sm61(outputs_prob_61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.1479e-14, 1.3587e-10, 1.0000e+00, 6.2676e-11, 5.6252e-16, 1.2710e-14,\n",
      "         9.2777e-16, 2.4372e-15, 8.6539e-11, 9.3888e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.82\n"
     ]
    }
   ],
   "source": [
    "correct_prob_61 = 0\n",
    "total_prob_61 = 0\n",
    "post_prob_61 = []\n",
    "pred_prob_61 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_61 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net61.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_61, labels_prob_61 = data\n",
    "            outputs_prob_61 = best_net61(images_prob_61)\n",
    "\n",
    "            sm61 = torch.nn.Softmax()\n",
    "            probabilities_prob_61 = sm61(outputs_prob_61)\n",
    "            post_prob_61.append(probabilities_prob_61)\n",
    "            _, predicted_prob_61 = torch.max(outputs_prob_61.data, 1)\n",
    "            pred_prob_61.append(predicted_prob_61.item())\n",
    "            \n",
    "\n",
    "            total_prob_61 += labels_prob_61.size(0)\n",
    "            correct_prob_61 += (predicted_prob_61 == labels_prob_61).sum().item()\n",
    "        accuracy61 = 100 * (correct_prob_61 / total_prob_61)\n",
    "        post_probs_61.append(post_prob_61)\n",
    "\n",
    "print('Probabilities', probabilities_prob_61)\n",
    "print('length of Probabilities', len(post_prob_61))\n",
    "print('Total Images: ', total_prob_61)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "id": "1jZAV5eRO1UE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-402-26426ec9684b>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_62 = sm62(outputs_prob_62)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.5108e-18, 2.7901e-13, 1.0000e+00, 2.4280e-14, 7.9546e-14, 3.6655e-17,\n",
      "         5.2878e-14, 4.5891e-17, 2.5425e-10, 5.2007e-17]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.8\n"
     ]
    }
   ],
   "source": [
    "correct_prob_62 = 0\n",
    "total_prob_62 = 0\n",
    "post_prob_62 = []\n",
    "pred_prob_62 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_62 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net62.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_62, labels_prob_62 = data\n",
    "            outputs_prob_62 = best_net62(images_prob_62)\n",
    "\n",
    "            sm62 = torch.nn.Softmax()\n",
    "            probabilities_prob_62 = sm62(outputs_prob_62)\n",
    "            post_prob_62.append(probabilities_prob_62)\n",
    "            _, predicted_prob_62 = torch.max(outputs_prob_62.data, 1)\n",
    "            pred_prob_62.append(predicted_prob_62.item())\n",
    "            \n",
    "\n",
    "            total_prob_62 += labels_prob_62.size(0)\n",
    "            correct_prob_62 += (predicted_prob_62 == labels_prob_62).sum().item()\n",
    "        accuracy62 = 100 * (correct_prob_62 / total_prob_62)\n",
    "        post_probs_62.append(post_prob_62)\n",
    "\n",
    "print('Probabilities', probabilities_prob_62)\n",
    "print('length of Probabilities', len(post_prob_62))\n",
    "print('Total Images: ', total_prob_62)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "id": "8L41XFs4O1Hy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-403-b2d3753b0ed8>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_63 = sm63(outputs_prob_63)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[6.0288e-15, 4.0746e-11, 9.9999e-01, 2.4003e-07, 2.0695e-10, 4.5704e-18,\n",
      "         1.2296e-17, 1.7725e-13, 4.9646e-06, 2.8885e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.84\n"
     ]
    }
   ],
   "source": [
    "correct_prob_63 = 0\n",
    "total_prob_63 = 0\n",
    "post_prob_63 = []\n",
    "pred_prob_63 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_63 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net63.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_63, labels_prob_63 = data\n",
    "            outputs_prob_63 = best_net63(images_prob_63)\n",
    "\n",
    "            sm63 = torch.nn.Softmax()\n",
    "            probabilities_prob_63 = sm63(outputs_prob_63)\n",
    "            post_prob_63.append(probabilities_prob_63)\n",
    "            _, predicted_prob_63 = torch.max(outputs_prob_63.data, 1)\n",
    "            pred_prob_63.append(predicted_prob_63.item())\n",
    "            \n",
    "\n",
    "            total_prob_63 += labels_prob_63.size(0)\n",
    "            correct_prob_63 += (predicted_prob_63 == labels_prob_63).sum().item()\n",
    "        accuracy63 = 100 * (correct_prob_63 / total_prob_63)\n",
    "        post_probs_63.append(post_prob_63)\n",
    "\n",
    "print('Probabilities', probabilities_prob_63)\n",
    "print('length of Probabilities', len(post_prob_63))\n",
    "print('Total Images: ', total_prob_63)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "id": "Uit7KdopO07v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-404-2eb8e94ae5f9>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_64 = sm64(outputs_prob_64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.3634e-13, 1.4155e-07, 1.0000e+00, 1.1090e-09, 2.1826e-10, 4.4515e-15,\n",
      "         9.6329e-14, 2.8683e-09, 1.5186e-09, 7.9685e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.26\n"
     ]
    }
   ],
   "source": [
    "correct_prob_64 = 0\n",
    "total_prob_64 = 0\n",
    "post_prob_64 = []\n",
    "pred_prob_64 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_64 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net64.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_64, labels_prob_64 = data\n",
    "            outputs_prob_64 = best_net64(images_prob_64)\n",
    "\n",
    "            sm64 = torch.nn.Softmax()\n",
    "            probabilities_prob_64 = sm64(outputs_prob_64)\n",
    "            post_prob_64.append(probabilities_prob_64)\n",
    "            _, predicted_prob_64 = torch.max(outputs_prob_64.data, 1)\n",
    "            pred_prob_64.append(predicted_prob_64.item())\n",
    "            \n",
    "\n",
    "            total_prob_64 += labels_prob_64.size(0)\n",
    "            correct_prob_64 += (predicted_prob_64 == labels_prob_64).sum().item()\n",
    "        accuracy64 = 100 * (correct_prob_64 / total_prob_64)\n",
    "        post_probs_64.append(post_prob_64)\n",
    "\n",
    "print('Probabilities', probabilities_prob_64)\n",
    "print('length of Probabilities', len(post_prob_64))\n",
    "print('Total Images: ', total_prob_64)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "id": "8Tfzn5O3O0vc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-405-f8e9c6fb023d>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_65 = sm65(outputs_prob_65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[4.9970e-13, 1.0505e-07, 9.9999e-01, 5.0062e-06, 5.3449e-12, 5.1858e-13,\n",
      "         9.8869e-16, 6.0246e-11, 1.7623e-09, 6.5889e-07]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.66\n"
     ]
    }
   ],
   "source": [
    "correct_prob_65 = 0\n",
    "total_prob_65 = 0\n",
    "post_prob_65 = []\n",
    "pred_prob_65 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_65 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net65.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_65, labels_prob_65 = data\n",
    "            outputs_prob_65 = best_net65(images_prob_65)\n",
    "\n",
    "            sm65 = torch.nn.Softmax()\n",
    "            probabilities_prob_65 = sm65(outputs_prob_65)\n",
    "            post_prob_65.append(probabilities_prob_65)\n",
    "            _, predicted_prob_65 = torch.max(outputs_prob_65.data, 1)\n",
    "            pred_prob_65.append(predicted_prob_65.item())\n",
    "            \n",
    "\n",
    "            total_prob_65 += labels_prob_65.size(0)\n",
    "            correct_prob_65 += (predicted_prob_65 == labels_prob_65).sum().item()\n",
    "        accuracy65 = 100 * (correct_prob_65 / total_prob_65)\n",
    "        post_probs_65.append(post_prob_65)\n",
    "\n",
    "print('Probabilities', probabilities_prob_65)\n",
    "print('length of Probabilities', len(post_prob_65))\n",
    "print('Total Images: ', total_prob_65)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "id": "0WJIaBhxO0iQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-406-2628664cf319>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_66 = sm66(outputs_prob_66)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[6.4516e-20, 7.9812e-15, 1.0000e+00, 5.3740e-12, 1.3008e-15, 2.1987e-18,\n",
      "         1.5491e-19, 1.0657e-12, 4.4690e-11, 4.8769e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.82\n"
     ]
    }
   ],
   "source": [
    "correct_prob_66 = 0\n",
    "total_prob_66 = 0\n",
    "post_prob_66 = []\n",
    "pred_prob_66 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_66 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net66.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_66, labels_prob_66 = data\n",
    "            outputs_prob_66 = best_net66(images_prob_66)\n",
    "\n",
    "            sm66 = torch.nn.Softmax()\n",
    "            probabilities_prob_66 = sm66(outputs_prob_66)\n",
    "            post_prob_66.append(probabilities_prob_66)\n",
    "            _, predicted_prob_66 = torch.max(outputs_prob_66.data, 1)\n",
    "            pred_prob_66.append(predicted_prob_66.item())\n",
    "            \n",
    "\n",
    "            total_prob_66 += labels_prob_66.size(0)\n",
    "            correct_prob_66 += (predicted_prob_66 == labels_prob_66).sum().item()\n",
    "        accuracy66 = 100 * (correct_prob_66 / total_prob_66)\n",
    "        post_probs_66.append(post_prob_66)\n",
    "\n",
    "print('Probabilities', probabilities_prob_66)\n",
    "print('length of Probabilities', len(post_prob_66))\n",
    "print('Total Images: ', total_prob_66)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "id": "6tvOInwbO0S7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-407-be30d5a816ed>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_67 = sm67(outputs_prob_67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.0826e-11, 4.1795e-11, 1.0000e+00, 1.5599e-10, 1.0801e-13, 1.0520e-13,\n",
      "         7.0720e-16, 2.4845e-16, 4.6938e-08, 1.2332e-11]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.02\n"
     ]
    }
   ],
   "source": [
    "correct_prob_67 = 0\n",
    "total_prob_67 = 0\n",
    "post_prob_67 = []\n",
    "pred_prob_67 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_67 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net60.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_67, labels_prob_67 = data\n",
    "            outputs_prob_67 = best_net67(images_prob_67)\n",
    "\n",
    "            sm67 = torch.nn.Softmax()\n",
    "            probabilities_prob_67 = sm67(outputs_prob_67)\n",
    "            post_prob_67.append(probabilities_prob_67)\n",
    "            _, predicted_prob_67 = torch.max(outputs_prob_67.data, 1)\n",
    "            pred_prob_67.append(predicted_prob_67.item())\n",
    "            \n",
    "\n",
    "            total_prob_67 += labels_prob_67.size(0)\n",
    "            correct_prob_67 += (predicted_prob_67 == labels_prob_67).sum().item()\n",
    "        accuracy67 = 100 * (correct_prob_67 / total_prob_67)\n",
    "        post_probs_67.append(post_prob_67)\n",
    "\n",
    "print('Probabilities', probabilities_prob_67)\n",
    "print('length of Probabilities', len(post_prob_67))\n",
    "print('Total Images: ', total_prob_67)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "id": "jlSEXxM7O0FL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-408-2a83af607863>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_68 = sm68(outputs_prob_68)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[4.7076e-13, 3.7085e-12, 1.0000e+00, 4.8533e-06, 1.0362e-10, 1.3924e-12,\n",
      "         1.5663e-14, 7.5003e-13, 5.8728e-09, 7.5303e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.1\n"
     ]
    }
   ],
   "source": [
    "correct_prob_68 = 0\n",
    "total_prob_68 = 0\n",
    "post_prob_68 = []\n",
    "pred_prob_68 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_68 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net68.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_68, labels_prob_68 = data\n",
    "            outputs_prob_68 = best_net68(images_prob_68)\n",
    "\n",
    "            sm68 = torch.nn.Softmax()\n",
    "            probabilities_prob_68 = sm68(outputs_prob_68)\n",
    "            post_prob_68.append(probabilities_prob_68)\n",
    "            _, predicted_prob_68 = torch.max(outputs_prob_68.data, 1)\n",
    "            pred_prob_68.append(predicted_prob_68.item())\n",
    "            \n",
    "\n",
    "            total_prob_68 += labels_prob_68.size(0)\n",
    "            correct_prob_68 += (predicted_prob_68 == labels_prob_68).sum().item()\n",
    "        accuracy68 = 100 * (correct_prob_68 / total_prob_68)\n",
    "        post_probs_68.append(post_prob_68)\n",
    "\n",
    "print('Probabilities', probabilities_prob_68)\n",
    "print('length of Probabilities', len(post_prob_68))\n",
    "print('Total Images: ', total_prob_68)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "id": "TnDdYU1XOz4O"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-409-472f4e6571fb>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_69 = sm69(outputs_prob_69)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[4.3484e-15, 1.1128e-11, 1.0000e+00, 1.4961e-11, 1.8880e-16, 9.1075e-15,\n",
      "         6.9450e-21, 3.0999e-14, 1.8731e-12, 5.6831e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.84\n"
     ]
    }
   ],
   "source": [
    "correct_prob_69 = 0\n",
    "total_prob_69 = 0\n",
    "post_prob_69 = []\n",
    "pred_prob_69 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_69 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net69.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_69, labels_prob_69 = data\n",
    "            outputs_prob_69 = best_net69(images_prob_69)\n",
    "\n",
    "            sm69 = torch.nn.Softmax()\n",
    "            probabilities_prob_69 = sm69(outputs_prob_69)\n",
    "            post_prob_69.append(probabilities_prob_69)\n",
    "            _, predicted_prob_69 = torch.max(outputs_prob_69.data, 1)\n",
    "            pred_prob_69.append(predicted_prob_69.item())\n",
    "            \n",
    "\n",
    "            total_prob_69 += labels_prob_69.size(0)\n",
    "            correct_prob_69 += (predicted_prob_69 == labels_prob_69).sum().item()\n",
    "        accuracy69 = 100 * (correct_prob_69 / total_prob_69)\n",
    "        post_probs_69.append(post_prob_69)\n",
    "\n",
    "print('Probabilities', probabilities_prob_69)\n",
    "print('length of Probabilities', len(post_prob_69))\n",
    "print('Total Images: ', total_prob_69)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "id": "3rHWypaqOzqN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-410-b2b6d18a51e6>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_70 = sm70(outputs_prob_70)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.3803e-14, 1.7084e-09, 1.0000e+00, 5.0972e-11, 2.2041e-13, 2.0343e-12,\n",
      "         5.4956e-15, 8.5102e-12, 1.0767e-09, 9.4449e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.98\n"
     ]
    }
   ],
   "source": [
    "correct_prob_70 = 0\n",
    "total_prob_70 = 0\n",
    "post_prob_70 = []\n",
    "pred_prob_70 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_70 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net70.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_70, labels_prob_70 = data\n",
    "            outputs_prob_70 = best_net70(images_prob_70)\n",
    "\n",
    "            sm70 = torch.nn.Softmax()\n",
    "            probabilities_prob_70 = sm70(outputs_prob_70)\n",
    "            post_prob_70.append(probabilities_prob_70)\n",
    "            _, predicted_prob_70 = torch.max(outputs_prob_70.data, 1)\n",
    "            pred_prob_70.append(predicted_prob_70.item())\n",
    "            \n",
    "\n",
    "            total_prob_70 += labels_prob_70.size(0)\n",
    "            correct_prob_70 += (predicted_prob_70 == labels_prob_70).sum().item()\n",
    "        accuracy70 = 100 * (correct_prob_70 / total_prob_70)\n",
    "        post_probs_70.append(post_prob_70)\n",
    "\n",
    "print('Probabilities', probabilities_prob_70)\n",
    "print('length of Probabilities', len(post_prob_70))\n",
    "print('Total Images: ', total_prob_70)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "id": "-cwVCpWRjRZv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-411-49bbbe2e41b2>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_71 = sm71(outputs_prob_71)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.8668e-11, 8.3539e-12, 1.0000e+00, 6.8877e-12, 3.0412e-09, 1.1967e-17,\n",
      "         5.1334e-15, 4.8127e-13, 1.1637e-08, 6.8086e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.68\n"
     ]
    }
   ],
   "source": [
    "correct_prob_71 = 0\n",
    "total_prob_71 = 0\n",
    "post_prob_71 = []\n",
    "pred_prob_71 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_71 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net71.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_71, labels_prob_71 = data\n",
    "            outputs_prob_71 = best_net71(images_prob_71)\n",
    "\n",
    "            sm71 = torch.nn.Softmax()\n",
    "            probabilities_prob_71 = sm71(outputs_prob_71)\n",
    "            post_prob_71.append(probabilities_prob_71)\n",
    "            _, predicted_prob_71 = torch.max(outputs_prob_71.data, 1)\n",
    "            pred_prob_71.append(predicted_prob_71.item())\n",
    "            \n",
    "\n",
    "            total_prob_71 += labels_prob_71.size(0)\n",
    "            correct_prob_71 += (predicted_prob_71 == labels_prob_71).sum().item()\n",
    "        accuracy71 = 100 * (correct_prob_71 / total_prob_71)\n",
    "        post_probs_71.append(post_prob_71)\n",
    "\n",
    "print('Probabilities', probabilities_prob_71)\n",
    "print('length of Probabilities', len(post_prob_71))\n",
    "print('Total Images: ', total_prob_71)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "id": "GlkAr6PVljut"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-412-2354f71dc043>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_72 = sm72(outputs_prob_72)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.4356e-18, 3.2069e-17, 1.0000e+00, 1.3167e-15, 1.0360e-21, 2.2728e-19,\n",
      "         1.3829e-18, 7.4670e-20, 4.1486e-16, 4.6267e-17]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.68\n"
     ]
    }
   ],
   "source": [
    "correct_prob_72 = 0\n",
    "total_prob_72 = 0\n",
    "post_prob_72 = []\n",
    "pred_prob_72 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_72 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net72.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_72, labels_prob_72 = data\n",
    "            outputs_prob_72 = best_net72(images_prob_72)\n",
    "\n",
    "            sm72 = torch.nn.Softmax()\n",
    "            probabilities_prob_72 = sm72(outputs_prob_72)\n",
    "            post_prob_72.append(probabilities_prob_72)\n",
    "            _, predicted_prob_72 = torch.max(outputs_prob_72.data, 1)\n",
    "            pred_prob_72.append(predicted_prob_72.item())\n",
    "            \n",
    "\n",
    "            total_prob_72 += labels_prob_72.size(0)\n",
    "            correct_prob_72 += (predicted_prob_72 == labels_prob_72).sum().item()\n",
    "        accuracy72 = 100 * (correct_prob_72 / total_prob_72)\n",
    "        post_probs_72.append(post_prob_72)\n",
    "\n",
    "print('Probabilities', probabilities_prob_72)\n",
    "print('length of Probabilities', len(post_prob_72))\n",
    "print('Total Images: ', total_prob_72)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "id": "CVhhrmLvljkm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-413-2ac08c87d22c>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_73 = sm73(outputs_prob_73)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.6445e-14, 1.7023e-12, 9.9983e-01, 2.6141e-12, 3.3122e-13, 9.1919e-17,\n",
      "         2.5997e-18, 1.3108e-14, 1.6609e-04, 2.3897e-09]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.68\n"
     ]
    }
   ],
   "source": [
    "correct_prob_73 = 0\n",
    "total_prob_73 = 0\n",
    "post_prob_73 = []\n",
    "pred_prob_73 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_73 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net73.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_73, labels_prob_73 = data\n",
    "            outputs_prob_73 = best_net73(images_prob_73)\n",
    "\n",
    "            sm73 = torch.nn.Softmax()\n",
    "            probabilities_prob_73 = sm73(outputs_prob_73)\n",
    "            post_prob_73.append(probabilities_prob_73)\n",
    "            _, predicted_prob_73 = torch.max(outputs_prob_73.data, 1)\n",
    "            pred_prob_73.append(predicted_prob_73.item())\n",
    "            \n",
    "\n",
    "            total_prob_73 += labels_prob_73.size(0)\n",
    "            correct_prob_73 += (predicted_prob_73 == labels_prob_73).sum().item()\n",
    "        accuracy73 = 100 * (correct_prob_73 / total_prob_73)\n",
    "        post_probs_73.append(post_prob_73)\n",
    "\n",
    "print('Probabilities', probabilities_prob_73)\n",
    "print('length of Probabilities', len(post_prob_73))\n",
    "print('Total Images: ', total_prob_73)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "id": "CQ1mgfIsljfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-414-1e47577b982b>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_74 = sm74(outputs_prob_74)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.8587e-11, 1.8583e-11, 9.9996e-01, 4.1321e-05, 3.3745e-15, 5.7046e-13,\n",
      "         3.2421e-13, 5.4409e-12, 5.0351e-09, 1.5768e-11]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.84\n"
     ]
    }
   ],
   "source": [
    "correct_prob_74 = 0\n",
    "total_prob_74 = 0\n",
    "post_prob_74 = []\n",
    "pred_prob_74 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_74 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net74.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_74, labels_prob_74 = data\n",
    "            outputs_prob_74 = best_net74(images_prob_74)\n",
    "\n",
    "            sm74 = torch.nn.Softmax()\n",
    "            probabilities_prob_74 = sm74(outputs_prob_74)\n",
    "            post_prob_74.append(probabilities_prob_74)\n",
    "            _, predicted_prob_74 = torch.max(outputs_prob_74.data, 1)\n",
    "            pred_prob_74.append(predicted_prob_74.item())\n",
    "            \n",
    "\n",
    "            total_prob_74 += labels_prob_74.size(0)\n",
    "            correct_prob_74 += (predicted_prob_74 == labels_prob_74).sum().item()\n",
    "        accuracy74 = 100 * (correct_prob_74 / total_prob_74)\n",
    "        post_probs_74.append(post_prob_74)\n",
    "\n",
    "print('Probabilities', probabilities_prob_74)\n",
    "print('length of Probabilities', len(post_prob_74))\n",
    "print('Total Images: ', total_prob_74)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "id": "IAnZtTcNljaF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-415-7c196ee9e465>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_75 = sm75(outputs_prob_75)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.9538e-15, 3.5514e-13, 1.0000e+00, 7.1113e-07, 2.2438e-08, 7.3653e-11,\n",
      "         4.1555e-13, 3.9526e-08, 2.7895e-08, 6.0374e-09]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.64\n"
     ]
    }
   ],
   "source": [
    "correct_prob_75 = 0\n",
    "total_prob_75 = 0\n",
    "post_prob_75 = []\n",
    "pred_prob_75 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_75 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net75.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_75, labels_prob_75 = data\n",
    "            outputs_prob_75 = best_net75(images_prob_75)\n",
    "\n",
    "            sm75 = torch.nn.Softmax()\n",
    "            probabilities_prob_75 = sm75(outputs_prob_75)\n",
    "            post_prob_75.append(probabilities_prob_75)\n",
    "            _, predicted_prob_75 = torch.max(outputs_prob_75.data, 1)\n",
    "            pred_prob_75.append(predicted_prob_75.item())\n",
    "            \n",
    "\n",
    "            total_prob_75 += labels_prob_75.size(0)\n",
    "            correct_prob_75 += (predicted_prob_75 == labels_prob_75).sum().item()\n",
    "        accuracy75 = 100 * (correct_prob_75 / total_prob_75)\n",
    "        post_probs_75.append(post_prob_75)\n",
    "\n",
    "print('Probabilities', probabilities_prob_75)\n",
    "print('length of Probabilities', len(post_prob_75))\n",
    "print('Total Images: ', total_prob_75)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "id": "5hrU44tiljUr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-416-9932052af436>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_76 = sm76(outputs_prob_76)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.5718e-12, 2.2986e-08, 1.0000e+00, 5.5541e-10, 2.2294e-14, 1.2730e-15,\n",
      "         1.4010e-11, 8.1679e-12, 2.0724e-09, 1.2233e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.7\n"
     ]
    }
   ],
   "source": [
    "correct_prob_76 = 0\n",
    "total_prob_76 = 0\n",
    "post_prob_76 = []\n",
    "pred_prob_76 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_76 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net76.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_76, labels_prob_76 = data\n",
    "            outputs_prob_76 = best_net76(images_prob_76)\n",
    "\n",
    "            sm76 = torch.nn.Softmax()\n",
    "            probabilities_prob_76 = sm76(outputs_prob_76)\n",
    "            post_prob_76.append(probabilities_prob_76)\n",
    "            _, predicted_prob_76 = torch.max(outputs_prob_76.data, 1)\n",
    "            pred_prob_76.append(predicted_prob_76.item())\n",
    "            \n",
    "\n",
    "            total_prob_76 += labels_prob_76.size(0)\n",
    "            correct_prob_76 += (predicted_prob_76 == labels_prob_76).sum().item()\n",
    "        accuracy76 = 100 * (correct_prob_76 / total_prob_76)\n",
    "        post_probs_76.append(post_prob_76)\n",
    "\n",
    "print('Probabilities', probabilities_prob_76)\n",
    "print('length of Probabilities', len(post_prob_76))\n",
    "print('Total Images: ', total_prob_76)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "id": "3fvoSM6oljPP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-417-26ae2be5b31e>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_77 = sm77(outputs_prob_77)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.5877e-21, 9.8450e-18, 1.0000e+00, 5.6447e-10, 4.7417e-19, 1.9350e-24,\n",
      "         5.7064e-18, 1.7612e-11, 1.3095e-16, 1.5440e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.3\n"
     ]
    }
   ],
   "source": [
    "correct_prob_77 = 0\n",
    "total_prob_77 = 0\n",
    "post_prob_77 = []\n",
    "pred_prob_77 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_77 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net77.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_77, labels_prob_77 = data\n",
    "            outputs_prob_77 = best_net77(images_prob_77)\n",
    "\n",
    "            sm77 = torch.nn.Softmax()\n",
    "            probabilities_prob_77 = sm77(outputs_prob_77)\n",
    "            post_prob_77.append(probabilities_prob_77)\n",
    "            _, predicted_prob_77 = torch.max(outputs_prob_77.data, 1)\n",
    "            pred_prob_77.append(predicted_prob_77.item())\n",
    "            \n",
    "\n",
    "            total_prob_77 += labels_prob_77.size(0)\n",
    "            correct_prob_77 += (predicted_prob_77 == labels_prob_77).sum().item()\n",
    "        accuracy77 = 100 * (correct_prob_77 / total_prob_77)\n",
    "        post_probs_77.append(post_prob_77)\n",
    "\n",
    "print('Probabilities', probabilities_prob_77)\n",
    "print('length of Probabilities', len(post_prob_77))\n",
    "print('Total Images: ', total_prob_77)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "id": "2BJ_j4bVljJ5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-419-0926331e9cfd>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_78 = sm78(outputs_prob_78)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.2778e-09, 1.3714e-10, 1.0000e+00, 6.2398e-08, 3.8494e-10, 1.2175e-11,\n",
      "         1.3633e-11, 1.2998e-10, 5.4942e-10, 3.6171e-09]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.84\n"
     ]
    }
   ],
   "source": [
    "correct_prob_78 = 0\n",
    "total_prob_78 = 0\n",
    "post_prob_78 = []\n",
    "pred_prob_78 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_78 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net78.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_78, labels_prob_78 = data\n",
    "            outputs_prob_78 = best_net78(images_prob_78)\n",
    "\n",
    "            sm78 = torch.nn.Softmax()\n",
    "            probabilities_prob_78 = sm78(outputs_prob_78)\n",
    "            post_prob_78.append(probabilities_prob_78)\n",
    "            _, predicted_prob_78 = torch.max(outputs_prob_78.data, 1)\n",
    "            pred_prob_78.append(predicted_prob_78.item())\n",
    "            \n",
    "\n",
    "            total_prob_78 += labels_prob_78.size(0)\n",
    "            correct_prob_78 += (predicted_prob_78 == labels_prob_78).sum().item()\n",
    "        accuracy78 = 100 * (correct_prob_78 / total_prob_78)\n",
    "        post_probs_78.append(post_prob_78)\n",
    "\n",
    "print('Probabilities', probabilities_prob_78)\n",
    "print('length of Probabilities', len(post_prob_78))\n",
    "print('Total Images: ', total_prob_78)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "id": "_vVMHcBPljCQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-420-40931b23bbb7>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_79 = sm79(outputs_prob_79)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.3803e-14, 1.7084e-09, 1.0000e+00, 5.0972e-11, 2.2041e-13, 2.0343e-12,\n",
      "         5.4956e-15, 8.5102e-12, 1.0767e-09, 9.4449e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.98\n"
     ]
    }
   ],
   "source": [
    "correct_prob_79 = 0\n",
    "total_prob_79 = 0\n",
    "post_prob_79 = []\n",
    "pred_prob_79 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_79 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net79.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_79, labels_prob_79 = data\n",
    "            outputs_prob_79 = best_net70(images_prob_79)\n",
    "\n",
    "            sm79 = torch.nn.Softmax()\n",
    "            probabilities_prob_79 = sm79(outputs_prob_79)\n",
    "            post_prob_79.append(probabilities_prob_79)\n",
    "            _, predicted_prob_79 = torch.max(outputs_prob_79.data, 1)\n",
    "            pred_prob_79.append(predicted_prob_79.item())\n",
    "            \n",
    "\n",
    "            total_prob_79 += labels_prob_79.size(0)\n",
    "            correct_prob_79 += (predicted_prob_79 == labels_prob_79).sum().item()\n",
    "        accuracy79 = 100 * (correct_prob_79 / total_prob_79)\n",
    "        post_probs_79.append(post_prob_79)\n",
    "\n",
    "print('Probabilities', probabilities_prob_79)\n",
    "print('length of Probabilities', len(post_prob_79))\n",
    "print('Total Images: ', total_prob_79)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "id": "C-Y5npVEli8x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-421-ccd4c5cf2522>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_80 = sm80(outputs_prob_80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.3936e-19, 1.7332e-11, 1.0000e+00, 6.4206e-12, 2.0729e-17, 1.5748e-17,\n",
      "         2.2920e-23, 1.5382e-17, 6.4594e-17, 1.3457e-11]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.66\n"
     ]
    }
   ],
   "source": [
    "correct_prob_80 = 0\n",
    "total_prob_80 = 0\n",
    "post_prob_80 = []\n",
    "pred_prob_80 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_80 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net80.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_80, labels_prob_80 = data\n",
    "            outputs_prob_80 = best_net80(images_prob_80)\n",
    "\n",
    "            sm80 = torch.nn.Softmax()\n",
    "            probabilities_prob_80 = sm80(outputs_prob_80)\n",
    "            post_prob_80.append(probabilities_prob_80)\n",
    "            _, predicted_prob_80 = torch.max(outputs_prob_80.data, 1)\n",
    "            pred_prob_80.append(predicted_prob_80.item())\n",
    "            \n",
    "\n",
    "            total_prob_80 += labels_prob_80.size(0)\n",
    "            correct_prob_80 += (predicted_prob_80 == labels_prob_80).sum().item()\n",
    "        accuracy80 = 100 * (correct_prob_80 / total_prob_80)\n",
    "        post_probs_80.append(post_prob_80)\n",
    "\n",
    "print('Probabilities', probabilities_prob_80)\n",
    "print('length of Probabilities', len(post_prob_80))\n",
    "print('Total Images: ', total_prob_80)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "id": "wpLBm0-Ili2Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-422-40fafac8a843>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_81 = sm81(outputs_prob_81)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.0328e-20, 5.5457e-10, 1.0000e+00, 4.1880e-14, 1.3097e-17, 1.1557e-21,\n",
      "         6.6901e-19, 2.8055e-17, 6.7084e-11, 6.4737e-21]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.72\n"
     ]
    }
   ],
   "source": [
    "correct_prob_81 = 0\n",
    "total_prob_81 = 0\n",
    "post_prob_81 = []\n",
    "pred_prob_81 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_81 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net81.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_81, labels_prob_81 = data\n",
    "            outputs_prob_81 = best_net81(images_prob_81)\n",
    "\n",
    "            sm81 = torch.nn.Softmax()\n",
    "            probabilities_prob_81 = sm81(outputs_prob_81)\n",
    "            post_prob_81.append(probabilities_prob_81)\n",
    "            _, predicted_prob_81 = torch.max(outputs_prob_81.data, 1)\n",
    "            pred_prob_81.append(predicted_prob_81.item())\n",
    "            \n",
    "\n",
    "            total_prob_81 += labels_prob_81.size(0)\n",
    "            correct_prob_81 += (predicted_prob_81 == labels_prob_81).sum().item()\n",
    "        accuracy81 = 100 * (correct_prob_81 / total_prob_81)\n",
    "        post_probs_81.append(post_prob_81)\n",
    "\n",
    "print('Probabilities', probabilities_prob_81)\n",
    "print('length of Probabilities', len(post_prob_81))\n",
    "print('Total Images: ', total_prob_81)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "id": "fJr8hQtIlivM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-423-ec915cda07d4>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_82 = sm82(outputs_prob_82)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.0126e-15, 1.0984e-09, 1.0000e+00, 4.0704e-17, 7.1270e-13, 3.8099e-16,\n",
      "         1.3966e-18, 6.8996e-10, 1.2835e-07, 2.0516e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.78\n"
     ]
    }
   ],
   "source": [
    "correct_prob_82 = 0\n",
    "total_prob_82 = 0\n",
    "post_prob_82 = []\n",
    "pred_prob_82 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_82 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net82.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_82, labels_prob_82 = data\n",
    "            outputs_prob_82 = best_net82(images_prob_82)\n",
    "\n",
    "            sm82 = torch.nn.Softmax()\n",
    "            probabilities_prob_82 = sm82(outputs_prob_82)\n",
    "            post_prob_82.append(probabilities_prob_82)\n",
    "            _, predicted_prob_82 = torch.max(outputs_prob_82.data, 1)\n",
    "            pred_prob_82.append(predicted_prob_82.item())\n",
    "            \n",
    "\n",
    "            total_prob_82 += labels_prob_82.size(0)\n",
    "            correct_prob_82 += (predicted_prob_82 == labels_prob_82).sum().item()\n",
    "        accuracy82 = 100 * (correct_prob_82 / total_prob_82)\n",
    "        post_probs_82.append(post_prob_82)\n",
    "\n",
    "print('Probabilities', probabilities_prob_82)\n",
    "print('length of Probabilities', len(post_prob_82))\n",
    "print('Total Images: ', total_prob_82)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "id": "iwwVqpMRlin9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-424-e9c429159dab>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_83 = sm83(outputs_prob_83)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.7578e-09, 4.7774e-06, 9.9998e-01, 1.4426e-06, 1.0879e-05, 4.0901e-08,\n",
      "         1.4917e-12, 6.3845e-07, 3.6962e-09, 2.8297e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.82\n"
     ]
    }
   ],
   "source": [
    "correct_prob_83 = 0\n",
    "total_prob_83 = 0\n",
    "post_prob_83 = []\n",
    "pred_prob_83 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_83 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net83.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_83, labels_prob_83 = data\n",
    "            outputs_prob_83 = best_net83(images_prob_83)\n",
    "\n",
    "            sm83 = torch.nn.Softmax()\n",
    "            probabilities_prob_83 = sm83(outputs_prob_83)\n",
    "            post_prob_83.append(probabilities_prob_83)\n",
    "            _, predicted_prob_83 = torch.max(outputs_prob_83.data, 1)\n",
    "            pred_prob_83.append(predicted_prob_83.item())\n",
    "            \n",
    "\n",
    "            total_prob_83 += labels_prob_83.size(0)\n",
    "            correct_prob_83 += (predicted_prob_83 == labels_prob_83).sum().item()\n",
    "        accuracy83 = 100 * (correct_prob_83 / total_prob_83)\n",
    "        post_probs_83.append(post_prob_83)\n",
    "\n",
    "print('Probabilities', probabilities_prob_83)\n",
    "print('length of Probabilities', len(post_prob_83))\n",
    "print('Total Images: ', total_prob_83)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "id": "TPHFt7Hqligg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-425-5088410742c6>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_84 = sm84(outputs_prob_84)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.1836e-13, 3.1445e-08, 1.0000e+00, 3.8105e-11, 8.2802e-13, 2.0756e-15,\n",
      "         1.5277e-16, 8.2006e-13, 1.3342e-08, 5.6336e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.11999999999999\n"
     ]
    }
   ],
   "source": [
    "correct_prob_84 = 0\n",
    "total_prob_84 = 0\n",
    "post_prob_84 = []\n",
    "pred_prob_84 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_84 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net84.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_84, labels_prob_84 = data\n",
    "            outputs_prob_84 = best_net84(images_prob_84)\n",
    "\n",
    "            sm84 = torch.nn.Softmax()\n",
    "            probabilities_prob_84 = sm84(outputs_prob_84)\n",
    "            post_prob_84.append(probabilities_prob_84)\n",
    "            _, predicted_prob_84 = torch.max(outputs_prob_84.data, 1)\n",
    "            pred_prob_84.append(predicted_prob_84.item())\n",
    "            \n",
    "\n",
    "            total_prob_84 += labels_prob_84.size(0)\n",
    "            correct_prob_84 += (predicted_prob_84 == labels_prob_84).sum().item()\n",
    "        accuracy84 = 100 * (correct_prob_84 / total_prob_84)\n",
    "        post_probs_84.append(post_prob_84)\n",
    "\n",
    "print('Probabilities', probabilities_prob_84)\n",
    "print('length of Probabilities', len(post_prob_84))\n",
    "print('Total Images: ', total_prob_84)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "id": "WYeQfS7nliZM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-426-469844e80060>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_85 = sm85(outputs_prob_85)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.0270e-10, 7.8728e-09, 9.9651e-01, 3.4931e-03, 3.7441e-14, 1.9852e-11,\n",
      "         4.8238e-12, 2.0794e-08, 4.3631e-12, 4.9456e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.92\n"
     ]
    }
   ],
   "source": [
    "correct_prob_85 = 0\n",
    "total_prob_85 = 0\n",
    "post_prob_85 = []\n",
    "pred_prob_85 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_85 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net85.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_85, labels_prob_85 = data\n",
    "            outputs_prob_85 = best_net85(images_prob_85)\n",
    "\n",
    "            sm85 = torch.nn.Softmax()\n",
    "            probabilities_prob_85 = sm85(outputs_prob_85)\n",
    "            post_prob_85.append(probabilities_prob_85)\n",
    "            _, predicted_prob_85 = torch.max(outputs_prob_85.data, 1)\n",
    "            pred_prob_85.append(predicted_prob_85.item())\n",
    "            \n",
    "\n",
    "            total_prob_85 += labels_prob_85.size(0)\n",
    "            correct_prob_85 += (predicted_prob_85 == labels_prob_85).sum().item()\n",
    "        accuracy85 = 100 * (correct_prob_85 / total_prob_85)\n",
    "        post_probs_85.append(post_prob_85)\n",
    "\n",
    "print('Probabilities', probabilities_prob_85)\n",
    "print('length of Probabilities', len(post_prob_85))\n",
    "print('Total Images: ', total_prob_85)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "id": "XZrGFzPkliQt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-427-3487efbcadcf>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_86 = sm86(outputs_prob_86)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[8.2043e-17, 2.4275e-09, 1.0000e+00, 5.0780e-12, 9.9464e-11, 3.0152e-14,\n",
      "         5.1907e-15, 1.2183e-13, 2.0919e-14, 3.4056e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.84\n"
     ]
    }
   ],
   "source": [
    "correct_prob_86 = 0\n",
    "total_prob_86 = 0\n",
    "post_prob_86 = []\n",
    "pred_prob_86 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_86 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net86.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_86, labels_prob_86 = data\n",
    "            outputs_prob_86 = best_net86(images_prob_86)\n",
    "\n",
    "            sm86 = torch.nn.Softmax()\n",
    "            probabilities_prob_86 = sm86(outputs_prob_86)\n",
    "            post_prob_86.append(probabilities_prob_86)\n",
    "            _, predicted_prob_86 = torch.max(outputs_prob_86.data, 1)\n",
    "            pred_prob_86.append(predicted_prob_86.item())\n",
    "            \n",
    "\n",
    "            total_prob_86 += labels_prob_86.size(0)\n",
    "            correct_prob_86 += (predicted_prob_86 == labels_prob_86).sum().item()\n",
    "        accuracy86 = 100 * (correct_prob_86 / total_prob_86)\n",
    "        post_probs_86.append(post_prob_86)\n",
    "\n",
    "print('Probabilities', probabilities_prob_86)\n",
    "print('length of Probabilities', len(post_prob_86))\n",
    "print('Total Images: ', total_prob_86)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "id": "9g6lW_dIliGD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-428-597dc82adcf9>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_87 = sm87(outputs_prob_87)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.6319e-13, 6.9985e-10, 1.0000e+00, 2.2497e-11, 4.0136e-15, 5.0153e-18,\n",
      "         2.6038e-15, 3.4646e-13, 3.7626e-08, 1.7220e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.2\n"
     ]
    }
   ],
   "source": [
    "correct_prob_87 = 0\n",
    "total_prob_87 = 0\n",
    "post_prob_87 = []\n",
    "pred_prob_87 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_87 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net87.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_87, labels_prob_87 = data\n",
    "            outputs_prob_87 = best_net87(images_prob_87)\n",
    "\n",
    "            sm87 = torch.nn.Softmax()\n",
    "            probabilities_prob_87 = sm87(outputs_prob_87)\n",
    "            post_prob_87.append(probabilities_prob_87)\n",
    "            _, predicted_prob_87 = torch.max(outputs_prob_87.data, 1)\n",
    "            pred_prob_87.append(predicted_prob_87.item())\n",
    "            \n",
    "\n",
    "            total_prob_87 += labels_prob_87.size(0)\n",
    "            correct_prob_87 += (predicted_prob_87 == labels_prob_87).sum().item()\n",
    "        accuracy87 = 100 * (correct_prob_87 / total_prob_87)\n",
    "        post_probs_87.append(post_prob_87)\n",
    "\n",
    "print('Probabilities', probabilities_prob_87)\n",
    "print('length of Probabilities', len(post_prob_87))\n",
    "print('Total Images: ', total_prob_87)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "id": "BLbeOR86lh8Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-429-ab59f2b5ead5>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_88 = sm88(outputs_prob_88)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.3227e-09, 5.5215e-08, 1.0000e+00, 2.1993e-10, 2.1432e-08, 1.6680e-14,\n",
      "         9.1771e-14, 1.4691e-10, 1.2135e-10, 2.8166e-07]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.3\n"
     ]
    }
   ],
   "source": [
    "correct_prob_88 = 0\n",
    "total_prob_88 = 0\n",
    "post_prob_88 = []\n",
    "pred_prob_88 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_88 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net88.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_88, labels_prob_88 = data\n",
    "            outputs_prob_88 = best_net88(images_prob_88)\n",
    "\n",
    "            sm88 = torch.nn.Softmax()\n",
    "            probabilities_prob_88 = sm88(outputs_prob_88)\n",
    "            post_prob_88.append(probabilities_prob_88)\n",
    "            _, predicted_prob_88 = torch.max(outputs_prob_88.data, 1)\n",
    "            pred_prob_88.append(predicted_prob_88.item())\n",
    "            \n",
    "\n",
    "            total_prob_88 += labels_prob_88.size(0)\n",
    "            correct_prob_88 += (predicted_prob_88 == labels_prob_88).sum().item()\n",
    "        accuracy88 = 100 * (correct_prob_88 / total_prob_88)\n",
    "        post_probs_88.append(post_prob_88)\n",
    "\n",
    "print('Probabilities', probabilities_prob_88)\n",
    "print('length of Probabilities', len(post_prob_88))\n",
    "print('Total Images: ', total_prob_88)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "id": "Ch8-SOI2lhx0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-430-e33785b72dc0>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_89 = sm89(outputs_prob_89)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.3127e-13, 1.9970e-10, 1.0000e+00, 7.8047e-08, 1.3616e-14, 7.6345e-17,\n",
      "         2.3382e-13, 5.2622e-11, 3.4689e-08, 6.1861e-15]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.08\n"
     ]
    }
   ],
   "source": [
    "correct_prob_89 = 0\n",
    "total_prob_89 = 0\n",
    "post_prob_89 = []\n",
    "pred_prob_89 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_89 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net89.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_89, labels_prob_89 = data\n",
    "            outputs_prob_89 = best_net89(images_prob_89)\n",
    "\n",
    "            sm89 = torch.nn.Softmax()\n",
    "            probabilities_prob_89 = sm89(outputs_prob_89)\n",
    "            post_prob_89.append(probabilities_prob_89)\n",
    "            _, predicted_prob_89 = torch.max(outputs_prob_89.data, 1)\n",
    "            pred_prob_89.append(predicted_prob_89.item())\n",
    "            \n",
    "\n",
    "            total_prob_89 += labels_prob_89.size(0)\n",
    "            correct_prob_89 += (predicted_prob_89 == labels_prob_89).sum().item()\n",
    "        accuracy89 = 100 * (correct_prob_89 / total_prob_89)\n",
    "        post_probs_89.append(post_prob_89)\n",
    "\n",
    "print('Probabilities', probabilities_prob_89)\n",
    "print('length of Probabilities', len(post_prob_89))\n",
    "print('Total Images: ', total_prob_89)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "id": "nqoLq7qRlhk4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-431-30ef9619a2a8>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_90 = sm90(outputs_prob_90)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.5480e-16, 7.3627e-14, 1.0000e+00, 1.9928e-13, 3.7176e-13, 2.0523e-18,\n",
      "         7.3327e-22, 7.6244e-17, 9.5499e-11, 1.8420e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.76\n"
     ]
    }
   ],
   "source": [
    "correct_prob_90 = 0\n",
    "total_prob_90 = 0\n",
    "post_prob_90 = []\n",
    "pred_prob_90 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_90 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net90.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_90, labels_prob_90 = data\n",
    "            outputs_prob_90 = best_net90(images_prob_90)\n",
    "\n",
    "            sm90 = torch.nn.Softmax()\n",
    "            probabilities_prob_90 = sm90(outputs_prob_90)\n",
    "            post_prob_90.append(probabilities_prob_90)\n",
    "            _, predicted_prob_90 = torch.max(outputs_prob_90.data, 1)\n",
    "            pred_prob_90.append(predicted_prob_90.item())\n",
    "            \n",
    "\n",
    "            total_prob_90 += labels_prob_90.size(0)\n",
    "            correct_prob_90 += (predicted_prob_90 == labels_prob_90).sum().item()\n",
    "        accuracy90 = 100 * (correct_prob_90 / total_prob_90)\n",
    "        post_probs_90.append(post_prob_90)\n",
    "\n",
    "print('Probabilities', probabilities_prob_90)\n",
    "print('length of Probabilities', len(post_prob_90))\n",
    "print('Total Images: ', total_prob_90)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "id": "rBS9LDmEm0VU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-432-fd277364fe43>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_91 = sm91(outputs_prob_91)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[6.5507e-15, 2.8449e-07, 1.0000e+00, 2.9929e-08, 4.7710e-12, 1.7433e-11,\n",
      "         1.3036e-15, 5.5345e-13, 1.3570e-09, 3.3782e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.54\n"
     ]
    }
   ],
   "source": [
    "correct_prob_91 = 0\n",
    "total_prob_91 = 0\n",
    "post_prob_91 = []\n",
    "pred_prob_91 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_91 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net91.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_91, labels_prob_91 = data\n",
    "            outputs_prob_91 = best_net91(images_prob_91)\n",
    "\n",
    "            sm91 = torch.nn.Softmax()\n",
    "            probabilities_prob_91 = sm91(outputs_prob_91)\n",
    "            post_prob_91.append(probabilities_prob_91)\n",
    "            _, predicted_prob_91 = torch.max(outputs_prob_91.data, 1)\n",
    "            pred_prob_91.append(predicted_prob_91.item())\n",
    "            \n",
    "\n",
    "            total_prob_91 += labels_prob_91.size(0)\n",
    "            correct_prob_91 += (predicted_prob_91 == labels_prob_91).sum().item()\n",
    "        accuracy91 = 100 * (correct_prob_91 / total_prob_91)\n",
    "        post_probs_91.append(post_prob_91)\n",
    "\n",
    "print('Probabilities', probabilities_prob_91)\n",
    "print('length of Probabilities', len(post_prob_91))\n",
    "print('Total Images: ', total_prob_91)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "id": "03BCW5QEm0Pq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-433-e936832e51ec>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_92 = sm92(outputs_prob_92)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.5862e-18, 8.7621e-10, 1.0000e+00, 1.0981e-12, 2.2963e-09, 1.6218e-18,\n",
      "         1.0529e-20, 4.4856e-15, 1.6306e-12, 2.5321e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 98.06\n"
     ]
    }
   ],
   "source": [
    "correct_prob_92 = 0\n",
    "total_prob_92 = 0\n",
    "post_prob_92 = []\n",
    "pred_prob_92 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_92 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net92.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_92, labels_prob_92 = data\n",
    "            outputs_prob_92 = best_net92(images_prob_92)\n",
    "\n",
    "            sm92 = torch.nn.Softmax()\n",
    "            probabilities_prob_92 = sm92(outputs_prob_92)\n",
    "            post_prob_92.append(probabilities_prob_92)\n",
    "            _, predicted_prob_92 = torch.max(outputs_prob_92.data, 1)\n",
    "            pred_prob_92.append(predicted_prob_92.item())\n",
    "            \n",
    "\n",
    "            total_prob_92 += labels_prob_92.size(0)\n",
    "            correct_prob_92 += (predicted_prob_92 == labels_prob_92).sum().item()\n",
    "        accuracy92 = 100 * (correct_prob_92 / total_prob_92)\n",
    "        post_probs_92.append(post_prob_92)\n",
    "\n",
    "print('Probabilities', probabilities_prob_92)\n",
    "print('length of Probabilities', len(post_prob_92))\n",
    "print('Total Images: ', total_prob_92)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "id": "pM1ewenzm0J6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-434-4c3b13abe4d5>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_93 = sm93(outputs_prob_93)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.5010e-16, 6.2402e-11, 1.0000e+00, 6.9152e-13, 9.4225e-17, 3.2300e-18,\n",
      "         4.1898e-18, 3.0395e-17, 2.3540e-12, 1.9785e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.26\n"
     ]
    }
   ],
   "source": [
    "correct_prob_93 = 0\n",
    "total_prob_93 = 0\n",
    "post_prob_93 = []\n",
    "pred_prob_93 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_93 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net93.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_93, labels_prob_93 = data\n",
    "            outputs_prob_93 = best_net93(images_prob_93)\n",
    "\n",
    "            sm93 = torch.nn.Softmax()\n",
    "            probabilities_prob_93 = sm93(outputs_prob_93)\n",
    "            post_prob_93.append(probabilities_prob_93)\n",
    "            _, predicted_prob_93 = torch.max(outputs_prob_93.data, 1)\n",
    "            pred_prob_93.append(predicted_prob_93.item())\n",
    "            \n",
    "\n",
    "            total_prob_93 += labels_prob_93.size(0)\n",
    "            correct_prob_93 += (predicted_prob_93 == labels_prob_93).sum().item()\n",
    "        accuracy93 = 100 * (correct_prob_93 / total_prob_93)\n",
    "        post_probs_93.append(post_prob_93)\n",
    "\n",
    "print('Probabilities', probabilities_prob_93)\n",
    "print('length of Probabilities', len(post_prob_93))\n",
    "print('Total Images: ', total_prob_93)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "id": "_c_QumtJm0EX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-435-5bb9ed2a4342>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_94 = sm94(outputs_prob_94)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.9883e-13, 3.1222e-12, 1.0000e+00, 3.3547e-08, 1.3915e-12, 2.7431e-16,\n",
      "         5.3870e-15, 5.0956e-12, 5.3594e-07, 1.8628e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.7\n"
     ]
    }
   ],
   "source": [
    "correct_prob_94 = 0\n",
    "total_prob_94 = 0\n",
    "post_prob_94 = []\n",
    "pred_prob_94 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_94 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net94.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_94, labels_prob_94 = data\n",
    "            outputs_prob_94 = best_net94(images_prob_94)\n",
    "\n",
    "            sm94 = torch.nn.Softmax()\n",
    "            probabilities_prob_94 = sm94(outputs_prob_94)\n",
    "            post_prob_94.append(probabilities_prob_94)\n",
    "            _, predicted_prob_94 = torch.max(outputs_prob_94.data, 1)\n",
    "            pred_prob_94.append(predicted_prob_94.item())\n",
    "            \n",
    "\n",
    "            total_prob_94 += labels_prob_94.size(0)\n",
    "            correct_prob_94 += (predicted_prob_94 == labels_prob_94).sum().item()\n",
    "        accuracy94 = 100 * (correct_prob_94 / total_prob_94)\n",
    "        post_probs_94.append(post_prob_94)\n",
    "\n",
    "print('Probabilities', probabilities_prob_94)\n",
    "print('length of Probabilities', len(post_prob_94))\n",
    "print('Total Images: ', total_prob_94)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "id": "ZfQyL8p1mz-4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-436-a2573322d3ac>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_95 = sm95(outputs_prob_95)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.1375e-18, 1.2487e-12, 1.0000e+00, 1.9638e-12, 6.5057e-17, 1.7800e-19,\n",
      "         1.0976e-19, 1.9141e-17, 1.3636e-12, 1.0158e-19]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.94\n"
     ]
    }
   ],
   "source": [
    "correct_prob_95 = 0\n",
    "total_prob_95 = 0\n",
    "post_prob_95 = []\n",
    "pred_prob_95 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_95 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net95.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_95, labels_prob_95 = data\n",
    "            outputs_prob_95 = best_net95(images_prob_95)\n",
    "\n",
    "            sm95 = torch.nn.Softmax()\n",
    "            probabilities_prob_95 = sm95(outputs_prob_95)\n",
    "            post_prob_95.append(probabilities_prob_95)\n",
    "            _, predicted_prob_95 = torch.max(outputs_prob_95.data, 1)\n",
    "            pred_prob_95.append(predicted_prob_95.item())\n",
    "            \n",
    "\n",
    "            total_prob_95 += labels_prob_95.size(0)\n",
    "            correct_prob_95 += (predicted_prob_95 == labels_prob_95).sum().item()\n",
    "        accuracy95 = 100 * (correct_prob_95 / total_prob_95)\n",
    "        post_probs_95.append(post_prob_95)\n",
    "\n",
    "print('Probabilities', probabilities_prob_95)\n",
    "print('length of Probabilities', len(post_prob_95))\n",
    "print('Total Images: ', total_prob_95)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "id": "eHX3Sdgamz5I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-437-69384da8d78e>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_96 = sm96(outputs_prob_96)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.7502e-15, 5.9912e-12, 1.0000e+00, 1.8914e-08, 9.6332e-16, 3.5207e-18,\n",
      "         7.1961e-18, 2.0958e-10, 5.4407e-10, 3.7035e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.76\n"
     ]
    }
   ],
   "source": [
    "correct_prob_96 = 0\n",
    "total_prob_96 = 0\n",
    "post_prob_96 = []\n",
    "pred_prob_96 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_96 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net96.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_96, labels_prob_96 = data\n",
    "            outputs_prob_96 = best_net96(images_prob_96)\n",
    "\n",
    "            sm96 = torch.nn.Softmax()\n",
    "            probabilities_prob_96 = sm96(outputs_prob_96)\n",
    "            post_prob_96.append(probabilities_prob_96)\n",
    "            _, predicted_prob_96 = torch.max(outputs_prob_96.data, 1)\n",
    "            pred_prob_96.append(predicted_prob_96.item())\n",
    "            \n",
    "\n",
    "            total_prob_96 += labels_prob_96.size(0)\n",
    "            correct_prob_96 += (predicted_prob_96 == labels_prob_96).sum().item()\n",
    "        accuracy96 = 100 * (correct_prob_96 / total_prob_96)\n",
    "        post_probs_96.append(post_prob_96)\n",
    "\n",
    "print('Probabilities', probabilities_prob_96)\n",
    "print('length of Probabilities', len(post_prob_96))\n",
    "print('Total Images: ', total_prob_96)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "id": "INm_Stcjmzzj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-438-54cc3416224f>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_97 = sm97(outputs_prob_97)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.1901e-14, 1.0166e-07, 9.9999e-01, 9.7362e-06, 2.0598e-10, 4.1152e-10,\n",
      "         4.2109e-13, 1.3322e-10, 3.8642e-08, 2.3824e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.64\n"
     ]
    }
   ],
   "source": [
    "correct_prob_97 = 0\n",
    "total_prob_97 = 0\n",
    "post_prob_97 = []\n",
    "pred_prob_97 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_97 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net97.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_97, labels_prob_97 = data\n",
    "            outputs_prob_97 = best_net97(images_prob_97)\n",
    "\n",
    "            sm97 = torch.nn.Softmax()\n",
    "            probabilities_prob_97 = sm97(outputs_prob_97)\n",
    "            post_prob_97.append(probabilities_prob_97)\n",
    "            _, predicted_prob_97 = torch.max(outputs_prob_97.data, 1)\n",
    "            pred_prob_97.append(predicted_prob_97.item())\n",
    "            \n",
    "\n",
    "            total_prob_97 += labels_prob_97.size(0)\n",
    "            correct_prob_97 += (predicted_prob_97 == labels_prob_97).sum().item()\n",
    "        accuracy97 = 100 * (correct_prob_97 / total_prob_97)\n",
    "        post_probs_97.append(post_prob_97)\n",
    "\n",
    "print('Probabilities', probabilities_prob_97)\n",
    "print('length of Probabilities', len(post_prob_97))\n",
    "print('Total Images: ', total_prob_97)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "id": "hhuMrU8hmztw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-439-27e0a632a8cc>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_98 = sm98(outputs_prob_98)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.6865e-09, 5.4985e-12, 1.0000e+00, 4.8704e-09, 4.8854e-14, 4.2901e-13,\n",
      "         1.9647e-13, 1.8083e-11, 2.7951e-07, 1.9385e-09]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.86\n"
     ]
    }
   ],
   "source": [
    "correct_prob_98 = 0\n",
    "total_prob_98 = 0\n",
    "post_prob_98 = []\n",
    "pred_prob_98 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_98 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net98.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_98, labels_prob_98 = data\n",
    "            outputs_prob_98 = best_net98(images_prob_98)\n",
    "\n",
    "            sm98 = torch.nn.Softmax()\n",
    "            probabilities_prob_98 = sm98(outputs_prob_98)\n",
    "            post_prob_98.append(probabilities_prob_98)\n",
    "            _, predicted_prob_98 = torch.max(outputs_prob_98.data, 1)\n",
    "            pred_prob_98.append(predicted_prob_98.item())\n",
    "            \n",
    "\n",
    "            total_prob_98 += labels_prob_98.size(0)\n",
    "            correct_prob_98 += (predicted_prob_98 == labels_prob_98).sum().item()\n",
    "        accuracy98 = 100 * (correct_prob_98 / total_prob_98)\n",
    "        post_probs_98.append(post_prob_98)\n",
    "\n",
    "print('Probabilities', probabilities_prob_98)\n",
    "print('length of Probabilities', len(post_prob_98))\n",
    "print('Total Images: ', total_prob_98)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "id": "6I7Ae6F3mzoP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-440-18fcc8ed69bf>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_99 = sm99(outputs_prob_99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.5480e-16, 7.3627e-14, 1.0000e+00, 1.9928e-13, 3.7176e-13, 2.0523e-18,\n",
      "         7.3327e-22, 7.6244e-17, 9.5499e-11, 1.8420e-08]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.76\n"
     ]
    }
   ],
   "source": [
    "correct_prob_99 = 0\n",
    "total_prob_99 = 0\n",
    "post_prob_99 = []\n",
    "pred_prob_99 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_99 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net99.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_99, labels_prob_99 = data\n",
    "            outputs_prob_99 = best_net90(images_prob_99)\n",
    "\n",
    "            sm99 = torch.nn.Softmax()\n",
    "            probabilities_prob_99 = sm99(outputs_prob_99)\n",
    "            post_prob_99.append(probabilities_prob_99)\n",
    "            _, predicted_prob_99 = torch.max(outputs_prob_99.data, 1)\n",
    "            pred_prob_99.append(predicted_prob_99.item())\n",
    "            \n",
    "\n",
    "            total_prob_99 += labels_prob_99.size(0)\n",
    "            correct_prob_99 += (predicted_prob_99 == labels_prob_99).sum().item()\n",
    "        accuracy99 = 100 * (correct_prob_99 / total_prob_99)\n",
    "        post_probs_99.append(post_prob_99)\n",
    "\n",
    "print('Probabilities', probabilities_prob_99)\n",
    "print('length of Probabilities', len(post_prob_99))\n",
    "print('Total Images: ', total_prob_99)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "id": "VJT7wV4-mzio"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-441-90b2a9bfb947>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_100 = sm100(outputs_prob_100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.7901e-15, 1.4133e-10, 1.0000e+00, 1.0629e-12, 1.6646e-13, 6.4816e-18,\n",
      "         7.0484e-17, 4.4049e-11, 3.9382e-11, 6.6905e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.98\n"
     ]
    }
   ],
   "source": [
    "correct_prob_100 = 0\n",
    "total_prob_100 = 0\n",
    "post_prob_100 = []\n",
    "pred_prob_100 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_100 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net100.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_100, labels_prob_100 = data\n",
    "            outputs_prob_100 = best_net100(images_prob_100)\n",
    "\n",
    "            sm100 = torch.nn.Softmax()\n",
    "            probabilities_prob_100 = sm100(outputs_prob_100)\n",
    "            post_prob_100.append(probabilities_prob_100)\n",
    "            _, predicted_prob_100 = torch.max(outputs_prob_100.data, 1)\n",
    "            pred_prob_100.append(predicted_prob_100.item())\n",
    "            \n",
    "\n",
    "            total_prob_100 += labels_prob_100.size(0)\n",
    "            correct_prob_100 += (predicted_prob_100 == labels_prob_100).sum().item()\n",
    "        accuracy100 = 100 * (correct_prob_100 / total_prob_100)\n",
    "        post_probs_100.append(post_prob_100)\n",
    "\n",
    "print('Probabilities', probabilities_prob_100)\n",
    "print('length of Probabilities', len(post_prob_100))\n",
    "print('Total Images: ', total_prob_100)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "id": "xJVBxW7umzdF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-442-327e574b2b7e>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_101 = sm101(outputs_prob_101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.0673e-15, 1.4180e-10, 1.0000e+00, 4.9470e-11, 9.9347e-14, 5.8482e-14,\n",
      "         1.7001e-15, 2.2796e-12, 8.5404e-10, 1.8761e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.78\n"
     ]
    }
   ],
   "source": [
    "correct_prob_101 = 0\n",
    "total_prob_101 = 0\n",
    "post_prob_101 = []\n",
    "pred_prob_101 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_101 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net101.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_101, labels_prob_101 = data\n",
    "            outputs_prob_101 = best_net101(images_prob_101)\n",
    "\n",
    "            sm101 = torch.nn.Softmax()\n",
    "            probabilities_prob_101 = sm101(outputs_prob_101)\n",
    "            post_prob_101.append(probabilities_prob_101)\n",
    "            _, predicted_prob_101 = torch.max(outputs_prob_101.data, 1)\n",
    "            pred_prob_101.append(predicted_prob_101.item())\n",
    "            \n",
    "\n",
    "            total_prob_101 += labels_prob_101.size(0)\n",
    "            correct_prob_101 += (predicted_prob_101 == labels_prob_101).sum().item()\n",
    "        accuracy101 = 100 * (correct_prob_101 / total_prob_101)\n",
    "        post_probs_101.append(post_prob_101)\n",
    "\n",
    "print('Probabilities', probabilities_prob_101)\n",
    "print('length of Probabilities', len(post_prob_101))\n",
    "print('Total Images: ', total_prob_101)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "id": "Bmd6z6XCmzXq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-443-b141683fddc2>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_102 = sm102(outputs_prob_102)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[1.6657e-10, 6.1734e-09, 1.0000e+00, 7.0059e-09, 5.2352e-14, 8.7344e-13,\n",
      "         3.7637e-14, 8.5711e-13, 4.3535e-09, 4.8388e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.8\n"
     ]
    }
   ],
   "source": [
    "correct_prob_102 = 0\n",
    "total_prob_102 = 0\n",
    "post_prob_102 = []\n",
    "pred_prob_102 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_102 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net102.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_102, labels_prob_102 = data\n",
    "            outputs_prob_102 = best_net102(images_prob_102)\n",
    "\n",
    "            sm102 = torch.nn.Softmax()\n",
    "            probabilities_prob_102 = sm102(outputs_prob_102)\n",
    "            post_prob_102.append(probabilities_prob_102)\n",
    "            _, predicted_prob_102 = torch.max(outputs_prob_102.data, 1)\n",
    "            pred_prob_102.append(predicted_prob_102.item())\n",
    "            \n",
    "\n",
    "            total_prob_102 += labels_prob_102.size(0)\n",
    "            correct_prob_102 += (predicted_prob_102 == labels_prob_102).sum().item()\n",
    "        accuracy102 = 100 * (correct_prob_102 / total_prob_102)\n",
    "        post_probs_102.append(post_prob_102)\n",
    "\n",
    "print('Probabilities', probabilities_prob_102)\n",
    "print('length of Probabilities', len(post_prob_102))\n",
    "print('Total Images: ', total_prob_102)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "id": "SF64oZzQmzSL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-444-b7785fa7d220>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_103 = sm103(outputs_prob_103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.2731e-18, 1.7653e-10, 1.0000e+00, 1.0051e-11, 1.3803e-15, 8.7126e-19,\n",
      "         1.5278e-21, 1.8081e-12, 2.3403e-11, 2.3478e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.52\n"
     ]
    }
   ],
   "source": [
    "correct_prob_103 = 0\n",
    "total_prob_103 = 0\n",
    "post_prob_103 = []\n",
    "pred_prob_103 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_103 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net103.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_103, labels_prob_103 = data\n",
    "            outputs_prob_103 = best_net103(images_prob_103)\n",
    "\n",
    "            sm103 = torch.nn.Softmax()\n",
    "            probabilities_prob_103 = sm103(outputs_prob_103)\n",
    "            post_prob_103.append(probabilities_prob_103)\n",
    "            _, predicted_prob_103 = torch.max(outputs_prob_103.data, 1)\n",
    "            pred_prob_103.append(predicted_prob_103.item())\n",
    "            \n",
    "\n",
    "            total_prob_103 += labels_prob_103.size(0)\n",
    "            correct_prob_103 += (predicted_prob_103 == labels_prob_103).sum().item()\n",
    "        accuracy103 = 100 * (correct_prob_103 / total_prob_103)\n",
    "        post_probs_103.append(post_prob_103)\n",
    "\n",
    "print('Probabilities', probabilities_prob_103)\n",
    "print('length of Probabilities', len(post_prob_103))\n",
    "print('Total Images: ', total_prob_103)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "id": "pauiDgUgmzMh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-445-af43103b6fac>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_104 = sm104(outputs_prob_104)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.0113e-15, 2.4780e-12, 1.0000e+00, 1.4600e-15, 8.6301e-13, 8.5966e-15,\n",
      "         1.2098e-17, 2.1670e-12, 1.5301e-18, 2.1849e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.94\n"
     ]
    }
   ],
   "source": [
    "correct_prob_104 = 0\n",
    "total_prob_104 = 0\n",
    "post_prob_104 = []\n",
    "pred_prob_104 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_104 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net104.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_104, labels_prob_104 = data\n",
    "            outputs_prob_104 = best_net104(images_prob_104)\n",
    "\n",
    "            sm104 = torch.nn.Softmax()\n",
    "            probabilities_prob_104 = sm104(outputs_prob_104)\n",
    "            post_prob_104.append(probabilities_prob_104)\n",
    "            _, predicted_prob_104 = torch.max(outputs_prob_104.data, 1)\n",
    "            pred_prob_104.append(predicted_prob_104.item())\n",
    "            \n",
    "\n",
    "            total_prob_104 += labels_prob_104.size(0)\n",
    "            correct_prob_104 += (predicted_prob_104 == labels_prob_104).sum().item()\n",
    "        accuracy104 = 100 * (correct_prob_104 / total_prob_104)\n",
    "        post_probs_104.append(post_prob_104)\n",
    "\n",
    "print('Probabilities', probabilities_prob_104)\n",
    "print('length of Probabilities', len(post_prob_104))\n",
    "print('Total Images: ', total_prob_104)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "id": "ItVW1xCrmzCM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-446-1d4e3ac85c20>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_105 = sm105(outputs_prob_105)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.0787e-15, 3.2437e-10, 1.0000e+00, 8.5285e-17, 6.8457e-20, 5.1141e-17,\n",
      "         8.5732e-19, 7.3267e-17, 4.1484e-14, 7.3998e-18]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.22\n"
     ]
    }
   ],
   "source": [
    "correct_prob_105 = 0\n",
    "total_prob_105 = 0\n",
    "post_prob_105 = []\n",
    "pred_prob_105 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_105 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net105.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_105, labels_prob_105 = data\n",
    "            outputs_prob_105 = best_net105(images_prob_105)\n",
    "\n",
    "            sm105 = torch.nn.Softmax()\n",
    "            probabilities_prob_105 = sm105(outputs_prob_105)\n",
    "            post_prob_105.append(probabilities_prob_105)\n",
    "            _, predicted_prob_105 = torch.max(outputs_prob_105.data, 1)\n",
    "            pred_prob_105.append(predicted_prob_105.item())\n",
    "            \n",
    "\n",
    "            total_prob_105 += labels_prob_105.size(0)\n",
    "            correct_prob_105 += (predicted_prob_105 == labels_prob_105).sum().item()\n",
    "        accuracy105 = 100 * (correct_prob_105 / total_prob_105)\n",
    "        post_probs_105.append(post_prob_105)\n",
    "\n",
    "print('Probabilities', probabilities_prob_105)\n",
    "print('length of Probabilities', len(post_prob_105))\n",
    "print('Total Images: ', total_prob_105)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "id": "MB47uGFbmy6Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-447-653602fe27d3>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_106 = sm106(outputs_prob_106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[4.0760e-17, 4.3554e-13, 1.0000e+00, 1.2198e-14, 9.3687e-14, 3.3712e-18,\n",
      "         9.2879e-16, 2.3855e-14, 2.9240e-11, 1.9274e-13]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.94\n"
     ]
    }
   ],
   "source": [
    "correct_prob_106 = 0\n",
    "total_prob_106 = 0\n",
    "post_prob_106 = []\n",
    "pred_prob_106 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_106 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net106.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_106, labels_prob_106 = data\n",
    "            outputs_prob_106 = best_net106(images_prob_106)\n",
    "\n",
    "            sm106 = torch.nn.Softmax()\n",
    "            probabilities_prob_106 = sm106(outputs_prob_106)\n",
    "            post_prob_106.append(probabilities_prob_106)\n",
    "            _, predicted_prob_106 = torch.max(outputs_prob_106.data, 1)\n",
    "            pred_prob_106.append(predicted_prob_106.item())\n",
    "            \n",
    "\n",
    "            total_prob_106 += labels_prob_106.size(0)\n",
    "            correct_prob_106 += (predicted_prob_106 == labels_prob_106).sum().item()\n",
    "        accuracy106 = 100 * (correct_prob_106 / total_prob_106)\n",
    "        post_probs_106.append(post_prob_106)\n",
    "\n",
    "print('Probabilities', probabilities_prob_106)\n",
    "print('length of Probabilities', len(post_prob_106))\n",
    "print('Total Images: ', total_prob_106)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "id": "vbWMSDUpmy05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-448-87293030b61c>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_107 = sm107(outputs_prob_107)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[3.0777e-18, 1.0245e-15, 1.0000e+00, 3.4263e-13, 8.5534e-19, 2.6916e-20,\n",
      "         5.3584e-25, 2.0174e-13, 1.7709e-15, 7.6985e-19]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.84\n"
     ]
    }
   ],
   "source": [
    "correct_prob_107 = 0\n",
    "total_prob_107 = 0\n",
    "post_prob_107 = []\n",
    "pred_prob_107 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_107 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net107.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_107, labels_prob_107 = data\n",
    "            outputs_prob_107 = best_net107(images_prob_107)\n",
    "\n",
    "            sm107 = torch.nn.Softmax()\n",
    "            probabilities_prob_107 = sm107(outputs_prob_107)\n",
    "            post_prob_107.append(probabilities_prob_107)\n",
    "            _, predicted_prob_107 = torch.max(outputs_prob_107.data, 1)\n",
    "            pred_prob_107.append(predicted_prob_107.item())\n",
    "            \n",
    "\n",
    "            total_prob_107 += labels_prob_107.size(0)\n",
    "            correct_prob_107 += (predicted_prob_107 == labels_prob_107).sum().item()\n",
    "        accuracy107 = 100 * (correct_prob_107 / total_prob_107)\n",
    "        post_probs_107.append(post_prob_107)\n",
    "\n",
    "print('Probabilities', probabilities_prob_107)\n",
    "print('length of Probabilities', len(post_prob_107))\n",
    "print('Total Images: ', total_prob_107)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "id": "o2JlkASamyvL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-449-55ab386cf5da>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_108 = sm108(outputs_prob_108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[7.2849e-14, 8.5917e-13, 1.0000e+00, 2.2518e-13, 3.5996e-12, 1.2125e-17,\n",
      "         2.6276e-17, 1.0946e-13, 4.6304e-14, 2.3372e-14]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.42\n"
     ]
    }
   ],
   "source": [
    "correct_prob_108 = 0\n",
    "total_prob_108 = 0\n",
    "post_prob_108 = []\n",
    "pred_prob_108 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_108 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net108.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_108, labels_prob_108 = data\n",
    "            outputs_prob_108 = best_net108(images_prob_108)\n",
    "\n",
    "            sm108 = torch.nn.Softmax()\n",
    "            probabilities_prob_108 = sm108(outputs_prob_108)\n",
    "            post_prob_108.append(probabilities_prob_108)\n",
    "            _, predicted_prob_108 = torch.max(outputs_prob_108.data, 1)\n",
    "            pred_prob_108.append(predicted_prob_108.item())\n",
    "            \n",
    "\n",
    "            total_prob_108 += labels_prob_108.size(0)\n",
    "            correct_prob_108 += (predicted_prob_108 == labels_prob_108).sum().item()\n",
    "        accuracy108 = 100 * (correct_prob_108 / total_prob_108)\n",
    "        post_probs_108.append(post_prob_108)\n",
    "\n",
    "print('Probabilities', probabilities_prob_108)\n",
    "print('length of Probabilities', len(post_prob_108))\n",
    "print('Total Images: ', total_prob_108)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "id": "O5pNETklmypd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-450-1a57a3cea0f3>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_109 = sm109(outputs_prob_109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[5.6669e-07, 7.1693e-06, 9.9999e-01, 1.0738e-09, 1.4351e-13, 1.3440e-13,\n",
      "         1.4577e-13, 9.3122e-09, 1.0609e-08, 7.0392e-10]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.64\n"
     ]
    }
   ],
   "source": [
    "correct_prob_109 = 0\n",
    "total_prob_109 = 0\n",
    "post_prob_109 = []\n",
    "pred_prob_109 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_109 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net109.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_109, labels_prob_109 = data\n",
    "            outputs_prob_109 = best_net109(images_prob_109)\n",
    "\n",
    "            sm109 = torch.nn.Softmax()\n",
    "            probabilities_prob_109 = sm109(outputs_prob_109)\n",
    "            post_prob_109.append(probabilities_prob_109)\n",
    "            _, predicted_prob_109 = torch.max(outputs_prob_109.data, 1)\n",
    "            pred_prob_109.append(predicted_prob_109.item())\n",
    "            \n",
    "\n",
    "            total_prob_109 += labels_prob_109.size(0)\n",
    "            correct_prob_109 += (predicted_prob_109 == labels_prob_109).sum().item()\n",
    "        accuracy109 = 100 * (correct_prob_109 / total_prob_109)\n",
    "        post_probs_109.append(post_prob_109)\n",
    "\n",
    "print('Probabilities', probabilities_prob_109)\n",
    "print('length of Probabilities', len(post_prob_109))\n",
    "print('Total Images: ', total_prob_109)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "id": "WA0NkFwFmyjj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-451-fbe1032aa5e6>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities_prob_110 = sm110(outputs_prob_110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities tensor([[2.8530e-17, 2.8580e-09, 1.0000e+00, 3.1131e-12, 5.1135e-13, 2.2416e-15,\n",
      "         5.3870e-20, 3.5532e-12, 3.2760e-12, 5.9070e-12]])\n",
      "length of Probabilities 5000\n",
      "Total Images:  5000\n",
      "Accuracy of the network on the 11000 test images: 97.72\n"
     ]
    }
   ],
   "source": [
    "correct_prob_110 = 0\n",
    "total_prob_110 = 0\n",
    "post_prob_110 = []\n",
    "pred_prob_110 = []\n",
    "\n",
    "epochs = 1\n",
    "post_probs_110 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with torch.no_grad():\n",
    "        best_net110.eval()\n",
    "        for data in prob_dl:\n",
    "            images_prob_110, labels_prob_110 = data\n",
    "            outputs_prob_110 = best_net110(images_prob_110)\n",
    "\n",
    "            sm110 = torch.nn.Softmax()\n",
    "            probabilities_prob_110 = sm110(outputs_prob_110)\n",
    "            post_prob_110.append(probabilities_prob_110)\n",
    "            _, predicted_prob_110 = torch.max(outputs_prob_110.data, 1)\n",
    "            pred_prob_110.append(predicted_prob_110.item())\n",
    "            \n",
    "\n",
    "            total_prob_110 += labels_prob_110.size(0)\n",
    "            correct_prob_110 += (predicted_prob_110 == labels_prob_110).sum().item()\n",
    "        accuracy110 = 100 * (correct_prob_110 / total_prob_110)\n",
    "        post_probs_110.append(post_prob_110)\n",
    "\n",
    "print('Probabilities', probabilities_prob_110)\n",
    "print('length of Probabilities', len(post_prob_110))\n",
    "print('Total Images: ', total_prob_110)\n",
    "print('Accuracy of the network on the 11000 test images:',  accuracy110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0nqHZ-rmyRZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xTt4gxA5qSR"
   },
   "outputs": [],
   "source": [
    "post_probs_50\n",
    "#post_probs_5[0][2] == post_probs_5[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "id": "zmZa6JCLFxMS"
   },
   "outputs": [],
   "source": [
    "# Calculate MSE for any two set of posterior probabilities that observed from two different models\n",
    "\n",
    "def nn_mse_loss(post_1, post_2):\n",
    "  mse_loss_meth = nn.MSELoss()\n",
    "  mse_loss = mse_loss_meth(torch.stack(post_1), torch.stack(post_2))\n",
    "  return mse_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTkbpmY91Qjc",
    "outputId": "5b376d79-becc-4080-f1a0-88b4f32a140e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003807435277849436]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_11 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_11):\n",
    "    mse_losses_04_11.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_11)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JqzL7R8Va94m",
    "outputId": "949ae55c-5674-4069-a126-410f7e0023d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0034798975102603436]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_12 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_12):\n",
    "    mse_losses_04_12.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_12)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjE8lYY0bGXS",
    "outputId": "65f37ec7-89d9-4d5e-fc79-4e7d3449b8ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003818339202553034]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_13 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_13):\n",
    "    mse_losses_04_13.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_13)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSm58QpebN6q",
    "outputId": "041a071b-23b6-45cf-e115-d7ca36e73f10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004092898685485125]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_14 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_14):\n",
    "    mse_losses_04_14.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_14)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXhxdu8gbVij",
    "outputId": "cd9a619b-78d8-45f1-b8c7-f01c8859ffc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0041137440130114555]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_15 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_15):\n",
    "    mse_losses_04_15.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvOwilnubdpd",
    "outputId": "4f71bb03-6627-420f-84a8-7e961290b5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004172130022197962]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_16 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_16):\n",
    "    mse_losses_04_16.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnG9_OPJbjER",
    "outputId": "f24edd90-6f8d-4f44-9938-b05d09da3370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003446577349677682]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_17 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_17):\n",
    "    mse_losses_04_17.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_17)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-bPytFabtnn",
    "outputId": "54ba00fb-a64c-476e-eec8-57ce1124594c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036757239140570164]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_18 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_18):\n",
    "    mse_losses_04_18.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_18)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSgcSMVtb0rs",
    "outputId": "e5aece7e-8ae7-461b-c208-a910932086ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004428458865731955]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_19 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_19):\n",
    "    mse_losses_04_19.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_19)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZ_nfv3mb8X3",
    "outputId": "5c9371f3-403b-4aeb-e8c3-ce3c300d020b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004333725664764643]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_20 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_20):\n",
    "    mse_losses_04_20.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFf_QbF2caWt",
    "outputId": "eadcceb2-e8ce-43b6-f3b4-bf688bf92d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004484050441533327]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_21 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_21):\n",
    "    mse_losses_04_21.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCG8Ncm0cgVM",
    "outputId": "7d65f7df-5e3e-4a58-fd7b-97254c117b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003943935036659241]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_22 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_22):\n",
    "    mse_losses_04_22.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LmQbiuRctBW",
    "outputId": "7a008ac9-c24e-4647-a331-9cfd58e80756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004933840129524469]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_23 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_23):\n",
    "    mse_losses_04_23.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UO4twcLuczij",
    "outputId": "ea2dff25-dc48-404a-c39c-7fed2f263dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0042870244942605495]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_24 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_24):\n",
    "    mse_losses_04_24.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brGK9Ob3c7Bt",
    "outputId": "2e2891f0-308b-464f-986e-6ffb99b500a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0041358317248523235]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_25 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_25):\n",
    "    mse_losses_04_25.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9we9SYldAfn",
    "outputId": "205f3983-cd7a-403e-b576-4d0d2d1bb518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0047779446467757225]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_26 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_26):\n",
    "    mse_losses_04_26.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4uw94TRdFpf",
    "outputId": "3fb9e0be-ddef-4519-bf50-f98e8ec89601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036313184536993504]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_27 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_27):\n",
    "    mse_losses_04_27.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M0UoD-VvdTNr",
    "outputId": "e3c98b44-182d-492f-a7c5-1cd65085c206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003942377399653196]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_28 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_28):\n",
    "    mse_losses_04_28.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7sGUSfXdaUJ",
    "outputId": "9577ffd2-669e-4d90-db08-50f0fb836a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004191058222204447]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_29 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_29):\n",
    "    mse_losses_04_29.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZzVeo0-5zyB",
    "outputId": "72c17b2b-1266-4bb3-c884-5ba947401357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004231883678585291]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_30 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_30):\n",
    "    mse_losses_04_30.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TsvK9JhdrFW",
    "outputId": "8dbfae45-d91c-4c1a-fdaf-098ea18ba71e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003732099663466215]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_31 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_31):\n",
    "    mse_losses_04_31.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OFHLA3fdzOj",
    "outputId": "a3379afa-f738-45dc-bdb7-5fbd334c3c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004303223919123411]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_32 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_32):\n",
    "    mse_losses_04_32.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDQor8iad5Dh",
    "outputId": "c0eb9f17-d670-498b-f967-100f8bb01e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004259580746293068]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_33 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_33):\n",
    "    mse_losses_04_33.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18IVAddsd_QD",
    "outputId": "5b6257f0-bbfe-40af-a9c3-d80dfbca0179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003937804605811834]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_34 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_34):\n",
    "    mse_losses_04_34.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHKzpko4eFO5",
    "outputId": "4695ddca-30bc-4db8-c7fc-734801a6d013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004156208131462336]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_35 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_35):\n",
    "    mse_losses_04_35.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjK4cJL-eMw4",
    "outputId": "e3dd810d-9bbe-4e60-db44-0824c1cb2268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004451845306903124]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_36 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_36):\n",
    "    mse_losses_04_36.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT6C5SoeeWxy",
    "outputId": "fa20b5d0-e6f0-480b-b70a-fec169a98172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00382120325230062]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_37 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_37):\n",
    "    mse_losses_04_37.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmSrs8yfeis0",
    "outputId": "6bd4fe0c-bc6b-469f-f5b3-42b6af8c918b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0037558465264737606]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_38 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_38):\n",
    "    mse_losses_04_38.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXbC4i0CeqXp",
    "outputId": "fdde709a-e882-4c76-ddc3-88b6e981e131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004219244234263897]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_39 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_39):\n",
    "    mse_losses_04_39.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUkYKS_d56kQ",
    "outputId": "86f0dfdb-9236-4df5-b03b-5041e981928d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02240172028541565]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_40 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_40):\n",
    "    mse_losses_04_40.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "toi16EPafCzm",
    "outputId": "b8fffaf5-52b4-4a69-fe1c-10bb2d8dfd50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003558887867256999]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_41 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_41):\n",
    "    mse_losses_04_41.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgcQahqDfKvR",
    "outputId": "67bc7d9d-0e11-480b-ce2c-818589b52122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004819352645426989]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_42 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_42):\n",
    "    mse_losses_04_42.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2DBx87nfS9w",
    "outputId": "8508ccfa-d565-4f80-aafc-d3fa0f6460d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003964778035879135]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_43 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_43):\n",
    "    mse_losses_04_43.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgbwqYXjfY7k",
    "outputId": "50238a5d-ab98-4c05-960c-3f3c65535866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004187180195003748]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_44 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_44):\n",
    "    mse_losses_04_44.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tg-_Q6Rfffab",
    "outputId": "e016bb87-92a7-4b6e-8a84-3c2a583e1642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0038902999367564917]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_45 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_45):\n",
    "    mse_losses_04_45.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3Hh8juhfpZV",
    "outputId": "6af8cb7d-63c1-4e63-f6f2-61f76e7e6af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004345211200416088]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_46 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_46):\n",
    "    mse_losses_04_46.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YJvIJ4WfzW_",
    "outputId": "6bcc7420-c53f-49fc-af9d-e5cc14104f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003758955281227827]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_47 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_47):\n",
    "    mse_losses_04_47.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRBO7jZBf714",
    "outputId": "010742e9-bffe-44b7-c355-fc78805d85cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004601652268320322]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_48 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_48):\n",
    "    mse_losses_04_48.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQKa1JAXgFQ8",
    "outputId": "8af556a7-fb20-4a7f-a183-ac4781604980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004190296400338411]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_49 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_49):\n",
    "    mse_losses_04_49.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnGXksxI6A_l",
    "outputId": "dc897419-b54c-4bdd-83a7-1eb92983532c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0038931507151573896]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_50 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_50):\n",
    "    mse_losses_04_50.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0039363703690469265]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_51 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_51):\n",
    "    mse_losses_04_51.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0033157269936054945]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_52 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_52):\n",
    "    mse_losses_04_52.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004483771976083517]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_53 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_53):\n",
    "    mse_losses_04_53.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0035369733814150095]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_54 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_54):\n",
    "    mse_losses_04_54.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0038336634170264006]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_55 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_55):\n",
    "    mse_losses_04_55.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003918081056326628]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_56 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_56):\n",
    "    mse_losses_04_56.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036360828671604395]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_57 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_57):\n",
    "    mse_losses_04_57.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004031990189105272]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_58 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_58):\n",
    "    mse_losses_04_58.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003374875755980611]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_59 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_59):\n",
    "    mse_losses_04_59.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0032868082635104656]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_60 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_60):\n",
    "    mse_losses_04_60.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003539794823154807]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_61 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_61):\n",
    "    mse_losses_04_61.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0033762995153665543]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_62 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_62):\n",
    "    mse_losses_04_62.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003370201913639903]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_63 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_63):\n",
    "    mse_losses_04_63.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004122334066778421]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_64 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_64):\n",
    "    mse_losses_04_64.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0038136786315590143]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_65 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_65):\n",
    "    mse_losses_04_65.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003516755299642682]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_66 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_66):\n",
    "    mse_losses_04_66.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0048047746531665325]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_67 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_67):\n",
    "    mse_losses_04_67.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0031640799716115]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_68 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_68):\n",
    "    mse_losses_04_68.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003312299493700266]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_69 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_69):\n",
    "    mse_losses_04_69.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003289976855739951]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_70 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_70):\n",
    "    mse_losses_04_70.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004105085972696543]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_71 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_71):\n",
    "    mse_losses_04_71.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003930988255888224]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_72 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_72):\n",
    "    mse_losses_04_72.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004051485098898411]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_73 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_73):\n",
    "    mse_losses_04_73.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0037222818937152624]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_74 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_74):\n",
    "    mse_losses_04_74.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004012139514088631]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_75 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_75):\n",
    "    mse_losses_04_75.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003982057329267263]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_76 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_76):\n",
    "    mse_losses_04_76.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003134954022243619]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_77 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_77):\n",
    "    mse_losses_04_77.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0038158646784722805]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_78 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_78):\n",
    "    mse_losses_04_78.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003289976855739951]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_79 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_79):\n",
    "    mse_losses_04_79.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004019223153591156]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_80 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_80):\n",
    "    mse_losses_04_80.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003777352860197425]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_81 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_81):\n",
    "    mse_losses_04_81.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00385990715585649]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_82 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_82):\n",
    "    mse_losses_04_82.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003741832682862878]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_83 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_83):\n",
    "    mse_losses_04_83.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0032527053263038397]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_84 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_84):\n",
    "    mse_losses_04_84.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003636888926848769]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_85 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_85):\n",
    "    mse_losses_04_85.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0039591602981090546]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_86 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_86):\n",
    "    mse_losses_04_86.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036149523220956326]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_87 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_87):\n",
    "    mse_losses_04_87.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0034727074671536684]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_88 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_88):\n",
    "    mse_losses_04_88.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004342333879321814]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_89 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_89):\n",
    "    mse_losses_04_89.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036538150161504745]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_90 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_90):\n",
    "    mse_losses_04_90.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0035573546774685383]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_91 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_91):\n",
    "    mse_losses_04_91.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0033217526506632566]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_92 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_92):\n",
    "    mse_losses_04_92.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004716647323220968]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_93 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_93):\n",
    "    mse_losses_04_93.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036395892966538668]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_94 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_94):\n",
    "    mse_losses_04_94.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003072020597755909]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_95 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_95):\n",
    "    mse_losses_04_95.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00370501889847219]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_96 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_96):\n",
    "    mse_losses_04_96.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0039040741976350546]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_97 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_97):\n",
    "    mse_losses_04_97.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004118909128010273]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_98 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_98):\n",
    "    mse_losses_04_98.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036538150161504745]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_99 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_99):\n",
    "    mse_losses_04_99.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003192608244717121]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_100 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_100):\n",
    "    mse_losses_04_100.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0035127161536365747]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_101 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_101):\n",
    "    mse_losses_04_101.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0037690119352191687]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_102 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_102):\n",
    "    mse_losses_04_102.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004238497465848923]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_103 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_103):\n",
    "    mse_losses_04_103.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0029020910151302814]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_104 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_104):\n",
    "    mse_losses_04_104.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004363260697573423]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_105 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_105):\n",
    "    mse_losses_04_105.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003215744625777006]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_106 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_106):\n",
    "    mse_losses_04_106.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003436416620388627]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_107 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_107):\n",
    "    mse_losses_04_107.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0042449915781617165]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_108 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_108):\n",
    "    mse_losses_04_108.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003978448919951916]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_109 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_109):\n",
    "    mse_losses_04_109.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003460792824625969]\n"
     ]
    }
   ],
   "source": [
    "mse_losses_04_110 = []\n",
    "\n",
    "for l1, l2 in zip(post_probs_4, post_probs_110):\n",
    "    mse_losses_04_110.append(nn_mse_loss(l1, l2))\n",
    "print(mse_losses_04_110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "id": "Jv2KI-ECVo9O"
   },
   "outputs": [],
   "source": [
    "#Calculate Model Similarity\n",
    "\n",
    "def model_similarity(mod_1, mod_2):\n",
    "  zip_lists = zip(mod_1, mod_2)\n",
    "  corr = 0\n",
    "  total = 0\n",
    "  for list_t, list_p in zip_lists:\n",
    "    total += 1\n",
    "    if list_t-list_p == 0:\n",
    "      corr += 1\n",
    "\n",
    "  accuracy = (corr / total) * 100\n",
    "\n",
    "  print(\"Model Similarity: \", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgXrtcSoXUc0",
    "outputId": "8214bc1b-f702-4dd0-fffb-c6a7060afb95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Similarity:  97.16 %\n",
      "Model Similarity:  97.66 %\n",
      "Model Similarity:  97.61999999999999 %\n",
      "Model Similarity:  96.86 %\n"
     ]
    }
   ],
   "source": [
    "# Print the model similarity\n",
    "\n",
    "model_similarity(pred_prob_1, pred_prob_11)\n",
    "model_similarity(pred_prob_1, pred_prob_31)\n",
    "model_similarity(pred_prob_1, pred_prob_41)\n",
    "model_similarity(pred_prob_10, pred_prob_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "id": "I1U0G--kCCpA"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUv8CwpG91oQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def arrange_mses(all_mses):\n",
    "#     count_mse = 0\n",
    "#     mse_data = []\n",
    "#     mse_target = []\n",
    "\n",
    "#     for mse_l in all_mses:\n",
    "#         for mse in mse_l:\n",
    "#             count_mse += 1\n",
    "#             if count_mse <= 10:\n",
    "#                 mse_data.append(mse)\n",
    "#                 mse_target.append(1)\n",
    "#             else:\n",
    "#                 mse_data.append(mse)\n",
    "#                 mse_target.append(0)\n",
    "    \n",
    "#     mse_dict = {'data': mse_data,\n",
    "#                 'target': mse_target\n",
    "#                 }\n",
    "\n",
    "#     return mse_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "id": "F74TAOtvhrbu"
   },
   "outputs": [],
   "source": [
    "def arrange_mses(all_mses):\n",
    "    count_mse = 0\n",
    "    mse_data = []\n",
    "    mse_target = []\n",
    "\n",
    "    for mse_l in all_mses:\n",
    "        count_mse += 1\n",
    "        if count_mse <= 10:\n",
    "            for mse in mse_l:\n",
    "                mse_data.append(mse)\n",
    "                mse_target.append(1)\n",
    "        else:\n",
    "            for mse in mse_l:\n",
    "                mse_data.append(mse)\n",
    "                mse_target.append(0)\n",
    "    \n",
    "    mse_dict = {'data': mse_data,\n",
    "                'target': mse_target\n",
    "                }\n",
    "\n",
    "    return mse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG1exT09_TxA",
    "outputId": "150d083c-ee10-4c84-b0c3-0fba6d7d46c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "#mse_losses_4_20\n",
    "all_mses1 = [mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses1 = arrange_mses(all_mses1)\n",
    "\n",
    "mse_df1 = pd.DataFrame(mses1, columns = ['data','target'], index=['mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40', \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df1 = mse_df1.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1kKcm2togwR",
    "outputId": "857df9ea-ef5b-4ab2-a320-59eb4136e7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "all_mses2 = [mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses2 = arrange_mses(all_mses2)\n",
    "\n",
    "mse_df2 = pd.DataFrame(mses2, columns = ['data','target'], index=['mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40', \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df2 = mse_df2.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df2.head(5))\n",
    "# print (mse_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LIGiO4P6pAv1",
    "outputId": "3266837f-c5fd-473e-b39b-b02fbfe7cb1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "all_mses3 = [mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_03_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses3 = arrange_mses(all_mses3)\n",
    "\n",
    "mse_df3 = pd.DataFrame(mses3, columns = ['data','target'], index=['mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30',  \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df3 = mse_df3.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df3.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0ZIJa1wpaSD",
    "outputId": "0bb05608-efe4-40de-8248-fd540039e918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "all_mses4 = [mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses4 = arrange_mses(all_mses4)\n",
    "\n",
    "mse_df4 = pd.DataFrame(mses4, columns = ['data','target'], index=['mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df4 = mse_df4.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df4.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "#mse_losses_4_20\n",
    "all_mses5 = [mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses5 = arrange_mses(all_mses5)\n",
    "\n",
    "mse_df5 = pd.DataFrame(mses5, columns = ['data','target'], index=['mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40', \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df5 = mse_df5.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df5.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       1\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "#mse_losses_4_20\n",
    "all_mses6 = [mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses6 = arrange_mses(all_mses6)\n",
    "\n",
    "mse_df6 = pd.DataFrame(mses6, columns = ['data','target'], index=['mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40', \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df6 = mse_df6.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df6.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       1\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "#mse_losses_4_20\n",
    "all_mses7 = [mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses7 = arrange_mses(all_mses7)\n",
    "\n",
    "mse_df7 = pd.DataFrame(mses7, columns = ['data','target'], index=['mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40', \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df7 = mse_df7.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df7.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "#mse_losses_4_20\n",
    "all_mses8 = [mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses8 = arrange_mses(all_mses8)\n",
    "\n",
    "mse_df8 = pd.DataFrame(mses8, columns = ['data','target'], index=['mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40', \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df8 = mse_df8.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df8.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       0\n",
      "mse_04_95   0.003072       1\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       1\n"
     ]
    }
   ],
   "source": [
    "#mse_losses_4_20\n",
    "all_mses9 = [mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110]\n",
    "\n",
    "mses9 = arrange_mses(all_mses9)\n",
    "\n",
    "mse_df9 = pd.DataFrame(mses9, columns = ['data','target'], index=['mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40', \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110'])\n",
    "\n",
    "mse_df9 = mse_df9.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df9.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                data  target\n",
      "mse_04_104  0.002902       1\n",
      "mse_04_95   0.003072       0\n",
      "mse_04_77   0.003135       0\n",
      "mse_04_68   0.003164       0\n",
      "mse_04_100  0.003193       0\n"
     ]
    }
   ],
   "source": [
    "#mse_losses_4_20\n",
    "all_mses10 = [mse_losses_04_101, mse_losses_04_102, mse_losses_04_103, mse_losses_04_104, mse_losses_04_105, mse_losses_04_106, mse_losses_04_107, mse_losses_04_108, mse_losses_04_109,\n",
    "             mse_losses_04_110,\n",
    "             mse_losses_04_11, mse_losses_04_12, mse_losses_04_13, mse_losses_04_14, mse_losses_04_15, mse_losses_04_16, mse_losses_04_17, mse_losses_04_18, mse_losses_04_19, mse_losses_04_20, \n",
    "             mse_losses_04_21, mse_losses_04_22, mse_losses_04_23, mse_losses_04_24, mse_losses_04_25, mse_losses_04_26, mse_losses_04_27, mse_losses_04_28, mse_losses_04_29, mse_losses_04_30, \n",
    "             mse_losses_04_31, mse_losses_04_32, mse_losses_04_33, mse_losses_04_34, mse_losses_04_35, mse_losses_04_36, mse_losses_04_37, mse_losses_04_38, mse_losses_04_39, mse_losses_04_40, \n",
    "             mse_losses_04_41, mse_losses_04_42, mse_losses_04_43, mse_losses_04_44, mse_losses_04_45, mse_losses_04_46, mse_losses_04_47, mse_losses_04_48, mse_losses_04_49, mse_losses_04_50,\n",
    "             mse_losses_04_51, mse_losses_04_52, mse_losses_04_53, mse_losses_04_54, mse_losses_04_55, mse_losses_04_56, mse_losses_04_57, mse_losses_04_58, mse_losses_04_59, mse_losses_04_60,\n",
    "             mse_losses_04_61, mse_losses_04_62, mse_losses_04_63, mse_losses_04_64, mse_losses_04_65, mse_losses_04_66, mse_losses_04_67, mse_losses_04_68, mse_losses_04_69, mse_losses_04_70,\n",
    "             mse_losses_04_71, mse_losses_04_72, mse_losses_04_73, mse_losses_04_74, mse_losses_04_75, mse_losses_04_76, mse_losses_04_77, mse_losses_04_78, mse_losses_04_79, mse_losses_04_80,\n",
    "             mse_losses_04_81, mse_losses_04_82, mse_losses_04_83, mse_losses_04_84, mse_losses_04_85, mse_losses_04_86, mse_losses_04_87, mse_losses_04_88, mse_losses_04_89, mse_losses_04_90,\n",
    "             mse_losses_04_90, mse_losses_04_92, mse_losses_04_93, mse_losses_04_94, mse_losses_04_95, mse_losses_04_96, mse_losses_04_97, mse_losses_04_98, mse_losses_04_99, mse_losses_04_100]\n",
    "\n",
    "mses10 = arrange_mses(all_mses10)\n",
    "\n",
    "mse_df10 = pd.DataFrame(mses10, columns = ['data','target'], index=['mse_04_101', 'mse_04_102', 'mse_04_103', 'mse_04_104', 'mse_04_105', 'mse_04_106', 'mse_04_107', 'mse_04_108', 'mse_04_109', 'mse_04_110',\n",
    "                                                                  'mse_04_11', 'mse_04_12', 'mse_04_13', 'mse_04_14', 'mse_04_15', 'mse_04_16', 'mse_04_17', 'mse_04_18', 'mse_04_19', 'mse_04_20', \n",
    "                                                                  'mse_04_21', 'mse_04_22', 'mse_04_23', 'mse_04_24', 'mse_04_25', 'mse_04_26', 'mse_04_27', 'mse_04_28', 'mse_04_29', 'mse_04_30', \n",
    "                                                                  'mse_04_31', 'mse_04_32', 'mse_04_33', 'mse_04_34', 'mse_04_35', 'mse_04_36', 'mse_04_37', 'mse_04_38', 'mse_04_39', 'mse_04_40', \n",
    "                                                                  'mse_04_41', 'mse_04_42', 'mse_04_43', 'mse_04_44', 'mse_04_45', 'mse_04_46', 'mse_04_47', 'mse_04_48', 'mse_04_49', 'mse_04_50',\n",
    "                                                                  'mse_04_51', 'mse_04_52', 'mse_04_53', 'mse_04_54', 'mse_04_55', 'mse_04_56', 'mse_04_57', 'mse_04_58', 'mse_04_59', 'mse_04_60',\n",
    "                                                                  'mse_04_61', 'mse_04_62', 'mse_04_63', 'mse_04_64', 'mse_04_65', 'mse_04_66', 'mse_04_67', 'mse_04_68', 'mse_04_69', 'mse_04_70',\n",
    "                                                                  'mse_04_71', 'mse_04_72', 'mse_04_73', 'mse_04_74', 'mse_04_75', 'mse_04_76', 'mse_04_77', 'mse_04_78', 'mse_04_79', 'mse_04_80',\n",
    "                                                                  'mse_04_81', 'mse_04_82', 'mse_04_83', 'mse_04_84', 'mse_04_85', 'mse_04_86', 'mse_04_87', 'mse_04_88', 'mse_04_89', 'mse_04_90',\n",
    "                                                                  'mse_04_91', 'mse_04_92', 'mse_04_93', 'mse_04_94', 'mse_04_95', 'mse_04_96', 'mse_04_97', 'mse_04_98', 'mse_04_99', 'mse_04_100'])\n",
    "\n",
    "mse_df10 = mse_df10.sort_values(by=['data'])\n",
    "\n",
    "#print the labeled mses\n",
    "print (mse_df10.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "id": "nR44RbWSmdqD"
   },
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc1 = auc(mse_df1.data, mse_df1.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74yG0WCt9Jn9",
    "outputId": "544b6846-9717-4d4d-c11e-a2e3930aa694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000191671890206635"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "id": "JD4tM-KSRzka"
   },
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc2 = auc(mse_df2.data, mse_df2.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQ1vAHJgR3h_",
    "outputId": "9deb55b1-de86-4225-ac79-fc9bc6574714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008979068719781935"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "id": "sWBGj2smSDQ4"
   },
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc3 = auc(mse_df3.data, mse_df3.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Q_GTaq9SE32",
    "outputId": "d446119f-37a3-452f-9ff3-6644e18e5f24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008873527869582176"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "id": "XczoRnvUSUTY"
   },
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc4 = auc(mse_df4.data, mse_df4.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilNrZiRXSYCf",
    "outputId": "1482a4ea-d17f-40ba-8a20-0707c5c208fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00027963146567344666"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc5 = auc(mse_df5.data, mse_df5.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010916683822870255"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc6 = auc(mse_df6.data, mse_df6.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016666133888065815"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc7 = auc(mse_df7.data, mse_df7.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016843678895384073"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc8 = auc(mse_df8.data, mse_df8.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000165733159519732"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc9 = auc(mse_df9.data, mse_df9.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00031710416078567505"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the auc\n",
    "\n",
    "mses_auc10 = auc(mse_df10.data, mse_df10.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00025820406153798103"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_auc10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "id": "NA1UqQrmrqXX"
   },
   "outputs": [],
   "source": [
    "MSE_AUC1 = 1 - mses_auc1\n",
    "MSE_AUC2 = 1 - mses_auc2\n",
    "MSE_AUC3 = 1 - mses_auc3\n",
    "MSE_AUC4 = 1 - mses_auc4\n",
    "MSE_AUC5 = 1 - mses_auc5\n",
    "MSE_AUC6 = 1 - mses_auc6\n",
    "MSE_AUC7 = 1 - mses_auc7\n",
    "MSE_AUC8 = 1 - mses_auc8\n",
    "MSE_AUC9 = 1 - mses_auc9\n",
    "MSE_AUC10 = 1 - mses_auc10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApnKiM91r-1y",
    "outputId": "3cd11b05-1d6e-4364-a6f2-7922f2fa6e99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_AUC1:  0.9998083281097934\n",
      "MSE_AUC2:  0.9910209312802181\n",
      "MSE_AUC3:  0.9911264721304178\n",
      "MSE_AUC4:  0.9997203685343266\n",
      "MSE_AUC5:  0.9998908331617713\n",
      "MSE_AUC6:  0.9998333386611193\n",
      "MSE_AUC7:  0.9998315632110462\n",
      "MSE_AUC8:  0.9998342668404803\n",
      "MSE_AUC9:  0.9996828958392143\n",
      "MSE_AUC10:  0.999741795938462\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE_AUC1: \", MSE_AUC1)\n",
    "print(\"MSE_AUC2: \", MSE_AUC2)\n",
    "print(\"MSE_AUC3: \", MSE_AUC3)\n",
    "print(\"MSE_AUC4: \", MSE_AUC4)\n",
    "print(\"MSE_AUC5: \", MSE_AUC5)\n",
    "print(\"MSE_AUC6: \", MSE_AUC6)\n",
    "print(\"MSE_AUC7: \", MSE_AUC7)\n",
    "print(\"MSE_AUC8: \", MSE_AUC8)\n",
    "print(\"MSE_AUC9: \", MSE_AUC9)\n",
    "print(\"MSE_AUC10: \", MSE_AUC10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "May_25_2021_thesis_proj_OnGoing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
